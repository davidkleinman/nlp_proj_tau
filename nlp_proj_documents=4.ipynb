{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbBDwI6cWAPZ","outputId":"97471c00-d940-49bf-aa27-5337c8f5ed5f","executionInfo":{"status":"ok","timestamp":1699278423867,"user_tz":-120,"elapsed":47496,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install langchain openai tiktoken faiss-gpu > /dev/null\n","!pip install huggingface_hub transformers sentence-transformers  > /dev/null\n","!pip install cohere accelerate bitsandbytes> /dev/null"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hc9JaRRx89iW","executionInfo":{"status":"ok","timestamp":1699278424746,"user_tz":-120,"elapsed":890,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}},"outputId":"a7dc7a0b-8e07-4404-9bbc-4e44e8b5c939"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","omrifahn\n"]}],"source":["!huggingface-cli login --token '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'\n","!huggingface-cli whoami"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"eaYEjgbgWnbO","executionInfo":{"status":"ok","timestamp":1699278446889,"user_tz":-120,"elapsed":22148,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}}},"outputs":[],"source":["import os\n","import sys\n","import json\n","import requests\n","import datetime\n","import json\n","import openai\n","from sklearn.model_selection import train_test_split\n","from huggingface_hub import notebook_login\n","from transformers import pipeline\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from langchain import HuggingFacePipeline\n","import textwrap\n","import time\n","\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import RetrievalQA\n","from langchain.prompts import PromptTemplate\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.docstore.document import Document\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.memory import ConversationBufferMemory\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.document_loaders import UnstructuredFileLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.chains import RetrievalQAWithSourcesChain"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"pazCpfXEWsTp","executionInfo":{"status":"ok","timestamp":1699278446890,"user_tz":-120,"elapsed":27,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}}},"outputs":[],"source":["OPENAI_API_KEY = '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'\n","os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n","openai.api_key = OPENAI_API_KEY"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"hCHA2jgLYv0_","colab":{"base_uri":"https://localhost:8080/","height":458,"referenced_widgets":["c01d0ab30f484bb7b397543aa2cb767f","99baf23dd4ce457a80ba8494056824e7","2af6bf870ebe4219825cbb288529bfb9","3a65088a04d6434baa869117d6a54824","f4bbff288c82495c96cc49f5bf869d7d","46b726bee2d44f0b8f7464504f164977","53d5d852e4b54ec1ab13cc92a115dfcb","ea4ba3912d6e4119aaf896d8af53fead","7f9d655ea9e14102ad288c73cd652ed0","f01681c44e464e41956a061994e685d3","384ce5efba3449e1b8e5a7c0def6a987","d56174aad2fa4bf28440d59ec1f0043e","1b85c95a435146008ef323fe605b407c","87835ce96f7b4745bdc7f1a3251de755","40e35bb6a1794234a8fe99418c3d5013","921bf95568d2497bbddd27f68e25903a","fd89a747bbaf4f918af01d51b9afa307","ec2f6328e10446e798636a954ae1183c","57602de6d3004c7093469d02cc27bf08","cd64e8e094ed46a1839f3f41f6d42ba2","98aebbda25ac4aa5ab383bcab7bc386f","e2da280ef7fd4e59bc5f3b49a0aa3c82","01db80512751403d95c4529022bf9223","bd405a3f8f184d50a9ae75bfee10ede8","6405a531d79449e3a327d2d7d00f3e96","7fa47a730a7d424ca16824c3aa0fad0f","aa1bf652c95b4362b6c59ad3a57ed55f","e968ea6701d34f8f8c653db1628060b1","d22a900d5ca4485a8f6c99b4176a1079","c79416bd6af143b29527e89ad28250aa","a783c4b1e70b49398b3b557520b25a04","b4ac908a079744d1bb6085250d7a345e","b5b0d110819645e984cd8beed0c339c9","db1d909dcce14863a18ec2783e3db7f6","cd80e9dddd0d4ac2aed3ce8b88616182","29c85ff0f75e4218baf3f3108ee9ae86","da661989f698413abaef66d152705e01","e8718496651347d69ef74dc496dca0c0","7fdc6520a77a48569f196de68fd7214e","0ca7c81f57f94ab1a0d579862cd4aee6","6e6c4fe363c345fca3998cdcfedec92c","7c1d790d8ec2417882fb30e1ecb42151","da9704893abb433d888e3897f3740d3b","31814c8b519f4288b41b90d1370b47da","50663fe62cab4958ace71d849bc60952","f5e862d394c74ae0b5a8d2bb7e2312ab","179523d834bf48d18522b7319802c488","e5d7fc6dd10449ff8abe6835b8a9fb35","98f49f506f1244919a45d4eb254e70f1","45e9753bd6f840c4bc3aa44271da0b35","a6abf6ea24744848ac770f27133b65b3","ce55cd4404af494e8e9f5601a7338a9c","12d497570651401a899778130729eb5e","f4711072a2364e719aa890972d6e6e33","db87640fc94f4897b37bcfcb62afefd3","6d1ce13887664542b54fadb51c958c4d","24b4f93c3b8f4dc18763f1caa0c428b0","556f2853e3504cbb8884ee948716020f","b8eb3163257949b3b83757c5dd9dd580","dab7031f82d74b4892ed2ead5e132a73","414a3d37574a46cf8e49ef3238a1935b","299427f6edbb49c585ba547f3cbb9a06","8dfa830dd3f04e6ca291791cacdee427","e88ffa3fad5d4bea87cbdc5487fd4808","9308a425e5e04fdc83e0eddcbdd66e6f","5d501ffe17234a2aaf12894a3069a07d","d880b70c33694da2947238f1f07fcf6a","99758a64420640e191e7f1cae3c3a886","ae82e0700ef74a26b214130adde26ba1","f73697a1871541099adb2ae703a04200","a440a4921a4645e99cd29df4d4c76c28","9a521b38e14f43b7bcda416c7a129ec3","38ddce78f9634a4f849b691117ee89f9","446be38f0f4a4597b4dd8623cd05deac","9b35aee9d8224933829c8f8512c0c5e5","d33b1f9e112d486e981decd5e6ee65b2","42b3fd138137428c86e5a5b9c472dad7","f89a7a57ea1e4d519fde466ad7e2e935","c561d15bff0f4506bbc40ae057fd7a2e","4dbca8d2a51a40d8abb3e6b340abd1c9","bcbce01cba45496a9e4573cc6cdd1002","6fdc80d7023b4c2b962b71f86ab9c761","b79893d5b810428d9acaed326042f7a2","157e394b4ea943fba8ae3fd73d72cac2","2139bdad93d7433ab55b1e26baf457b0","73508070de3d4ea0ba99322038603059","6d49e3565d77422a821e2e77808a3702","60044a02a2bf46d486a3700b915d2738","82e6060feb5c44ae92637799b4014d04","a68405317643473aa51fd1a30589d733","2eac502716284f2f898686d778af628d","e651c6a9f8b24f5aa4998246b3995025","89123b60e7094b9b8a793d15f79bb559","869f86a490254ac68b4d086a1a235a3b","efea0d249f2f4b3a9f2a55149cfb6754","e557a4a03c274976bcdf0a4d966b6c1e","667bb17e07f246e2b9a196eb9a04374b","99734ff902e5416584e7ab25bc7cf991","929f3d7d3bcc4fea9daaea73a8d271e4","cbc146df5e2943d181d494ce46ef38cc","d6160cada928450bb3a9af78ce25ee58","bc1f8854cf5e4375b53ec44e95e90d1b","8ff81e80ba284da6aa08cb7bfa71f982","f6c06e5fe5ff48be84bc316d6f2d8a6d","3bca5240e8364d16817a1d2592f012ca","d7673841aeda4a938d3911eb9d553a5a","b749c130215640c6a38b564042bff5cf","cd94b41cb76340f7a9c3574e59c88aa0","77ecb855ea184d9ea5f3d270d1ba63e7","f5b476c5a4bd42a388c798de76f884de","de2e2147e1b54c1f8f7e02084f480115","cc2f8559378945ffa9a19ab103776aab","6fc0b5acd8404d598331a4e03843df9f","1843bea0b05c47208492d4a5d57b0087","35675dd701e6485094828e252449e758","41d0b001392f42c9881eba76dc6e049a","a2e42f0ee69e433ea8c6191ec7e55c21","8db824f33234468b99af30f79c125512","1363c47ccf584d88a4b21f7f7b151ba5","fc59606ec5c14ba8b5b270bdeb381c8c","9a772472266240449702068661ec455b"]},"executionInfo":{"status":"ok","timestamp":1699278641093,"user_tz":-120,"elapsed":194228,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}},"outputId":"58192238-06c7-4501-9e2e-f1fea50c0ccd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c01d0ab30f484bb7b397543aa2cb767f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56174aad2fa4bf28440d59ec1f0043e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01db80512751403d95c4529022bf9223"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db1d909dcce14863a18ec2783e3db7f6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50663fe62cab4958ace71d849bc60952"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1ce13887664542b54fadb51c958c4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d880b70c33694da2947238f1f07fcf6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f89a7a57ea1e4d519fde466ad7e2e935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82e6060feb5c44ae92637799b4014d04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc146df5e2943d181d494ce46ef38cc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de2e2147e1b54c1f8f7e02084f480115"}},"metadata":{}}],"source":["#Call the LLM model(llama) from hugging face meta-ai\n","import torch\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n","model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n","                                             device_map='auto',\n","                                             torch_dtype=torch.float16,\n","                                             use_auth_token=True,\n","                                             load_in_4bit=True\n","                                              #load_in_8bit=True\n","                                             )\n","pipe = pipeline(\"text-generation\",\n","                model=model,\n","                tokenizer= tokenizer,\n","                torch_dtype=torch.bfloat16,\n","                device_map=\"auto\",\n","                max_new_tokens = 1024,\n","                do_sample=True,\n","                top_k=10,\n","                num_return_sequences=1,\n","                eos_token_id=tokenizer.eos_token_id,\n","                return_full_text=False\n","                )"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"zL0RnWu4FysJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699278641523,"user_tz":-120,"elapsed":439,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}},"outputId":"2aecd2f2-aeae-4acf-e28d-77f3f21e58f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["len(train_data)=100\n","len(test_data)=200\n"]}],"source":["# Fetch data from URL and embed it\n","response = requests.get('https://huggingface.co/datasets/voidful/StrategyQA/raw/main/strategyqa_train.json')\n","response.raise_for_status()\n","all_data = response.json()[:400]\n","\n","def rearrange_json(obj):\n","    answer = obj.pop('answer', None)\n","    obj['answer'] = answer\n","    return obj\n","all_rearranged_data = [rearrange_json(obj) for obj in all_data]\n","\n","train_data, test_data = train_test_split(all_rearranged_data, test_size=0.50, random_state=42)\n","train_data = train_data[:100] # TODO - remove\n","# test_data = test_data  # todo - this is test and prev is vectorDB\n","print(f'{len(train_data)=}')\n","print(f'{len(test_data)=}')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"oDzSdWUs-KfM","colab":{"base_uri":"https://localhost:8080/","height":465,"referenced_widgets":["4bc64f25f624444b92fc71d2f5d8e88d","29dc5c1b6d7644a3a122f19a6b619f81","8414e6a531ee45c0b4ea30cdb41abef4","36f3d9b38f9b47b698140e77287f3ebc","7f0a6b6ad8be4c168fdc31d20da79b18","4f91fdb8cd63425b8fc02463bf496fbb","80e3d1757ee64405a35896b540f79804","fad60ca30b7e430a98db8bab65fc8167","b99cc499af0b4f1e97238d742bc22e63","e20c9c2eb26545aab5335800031454e5","cdb8a2819fc847eb85e3c94c576bb550","5c15079df56445b3b79d33034a867458","b550fcfbb4664163bc0d3edc06e4edc2","25b8aa5a331349a6b7b3a320fef4bfdd","1623cfc020de4ec992d6134d160a0971","6242074f0fdf467aa6ca4462ee5780f5","a695a8ab02b64719b31b30e915f1c02f","d54b53c7fa304dfba602bbb41f730c71","6aac4a9cb31b4b50942ded8c8d339f6f","9e896dfc31eb4a439db4fe78b8d5128b","3fec560598aa4dbfa262e5428c2f7df3","87ae9f443bd547c2adeabdf8944af611","3535d656d63143d4a5ccdd051307adff","d8e11f12bc41467cbdc33d8bad469055","522b1bc6373c446f865cbac9cacd3676","7177611eeb074900b062b1a25eed6db8","3deaa5e8569a4ca6b37f738a45e3e511","68e546377d2d4363a1d19079bb9fa6c2","270191dae1fc438994ff2a5dbe41a466","77c97cc09f6d43ae88d0b9f0e6385709","c3fac855af5a4ba391be8a61bf082d59","ecdc8e75d3224eabbda81d2935d85130","a4729d53f60b433582a6320139f11bac","2cc806e11864499ab732f8b0c03a0973","1b980ae561a14856b478ae6980641628","24786a1c760d4a4b9a437f07a8f60383","a284798a790c48bf9dfc7c35e319805a","c435e6de23e44b03a96aa24b2b4f4c5c","bc5e4493e41c4f14a65063f56fc55dbc","5a7f9797bd9540eeb8c3409733287939","114465f9906749e087f7604e84df02f2","7a6c3444aacc4c93a6451adbc652f514","35350df0ae1041d1b88f579a02240ea2","765dcde89a254b408ec41d1381077a7d","46052f777c0845e58778ca2524e99aa5","70a90c765296473db44255d0c2c0c678","bf9880a56e0d4004949c3c3c7a4dc108","09185a9b149b44058b5dabd72c80d091","2b776fccadd6488a96919605f07f5fc4","5c423dcb4e314acfa6b8791fd4986d0d","bbfd862377554cdd947070068d82cc96","8c3e95a7fd474c80a17eb493a19b7e06","1663bf8ab8744edea59438b38d3f2665","65d3f0887f8c490b95aec45aad5e861d","0868850e16cc464084c7c39cb7cedc68","83292382f2f74ad5a7010c5652c0a983","5d429d3152f44b798e980c85d7f5eb7b","3e485347dc7645c5911747ba2d2bba75","f5945a2294c446e4883cf68449380a17","63e3711e3bff452dbbdd105d8143b8ee","a7d72427b5e642568cee2713bd7f1413","ab8ff475a874406e9935991fd7cea086","510244b18087490bbd7206d248f191fa","e7745d138f4f49bebab6601b396ab968","5380e6e656364da8af2fbf726071ce50","9e577bf6473e4ea0ba5944b45c16a9f1","b00bf01129ee40e8b8071c07f211c922","b0c7cfe1c6c543a797e303e383fc2e43","271c2e611bbe4f3dadad3280a7039289","3ae17005262542d3bee7d7ea4cfba214","0f20019daa3640229c03f52ac9f26f97","7c26aad75b554f3aa39662f260795826","8fa9f24979774452bac041037095b916","c7a154494c9b484bbe498e9586c1b4cf","3a618d2b94c94f0f8bd4a67b3202822a","f6bf434911fe418188e1550195c25957","39fce2dd4a9749bc9e847813d4426bf7","35ea0c22ba83412a9de390a1364c6d10","2f7120937daf43bba9a1f91e6073058c","e620b969bbbd472b97c111538fdc3695","d43e68afa3344c8cbd0b1d9de17d6519","8e69a7872752430b8098cf4dc2281def","3dceaa513c4d44f39023f3d19f0ad2c7","40bf332984fc42059ddc15046898bebb","5951d9de5c6a452aa25f98c57ee74187","ba3e6a8329c849fb9d40529d78d3e5f6","fb41e1cdc5504fed963ed70f410917e9","ccfe920ff2b34144a832b33caf0b4284","9bfb2703057d42b0bd2fa11f96c65b2d","d7aac820170c42ff99b180939ac2f4bf","ff7a058ec0564b3c90da979e740ceef4","1901185ece954615bb2d87eba33c79b2","05b1415b5f654fd5a02f3c8c9d3b4cef","088360720cb241ecbe277cdb1386225f","6d5c208211064169b7f9058568765209","cafd6cec0cbc45348b725b64d5d20e33","e71aac140b164b4e826c59a94b10ff63","681742da1e044e93a01633f0c4135c39","dea7f3dea1574d63b42c89f2a27cf6ed","0242e7274e874f00ad4f248a87918e42","a1b837b43f944471b9f35d755eac2e5d","d71e32cf5c9643188e521b8bb4b73cb1","d50caf94ee1345029dea69fffda28e5a","352c76bb646f42598ec9e968aeba2d1d","40689fcfac6d4765aa935bd867616cd9","8964861ada9047efbe0f91308c2d5439","825f4568a32649858bf1ccb210585e1f","037849438d5543fe875a64f74200541f","b60952d1390c48119d9409fa988021f2","4599588cd18c4033a52ed208b9b83a35","70139978676b43008e8961a1ed7cbc74","feaa10d44367460ea50c902c65b00080","35df66066b7649f38b117f73341a728e","e7f15ea8ad3548ce9498085df44dceb0","e6f74247184e4fe9bd1b57145229cacd","92dbfeab3b69426197a48841ec929e42","a6d26b15d307433696dd5f0b6d831218","61649588ffb0412dba8a9afe7100f42f","d04dd7cdf8fd49fc921642692ed5c762","8d895c3db70e49d9b64ce50f34c614c5","5c6065c7681f4233a1c13cd3fac57986","bbb16f33ef824b07b446606e39c45d86","a9347957e0fb43afb093a13b6f50902d","9e9234cd90464df38f0817c5ad2f0842","bb57e838336c4701957e832aaf793e5f","e50e9537e5c6405f8a9ea65b6a1b8de0","80aaa2558eaa476aa62a312895a84072","c018f51287d841e9ab2e4a54e75a764f","9e976d874b2843409cfbbd4f6b4a0076","66ed436b656d450d92ec2cf152dd6654","869247fb2201430386756b009fe47704","3bb64fc9762f4ca48707ca2b0301b22b","ef87716a2084448c987b69bb9c0ff594","913198da8a4d4798be467888131d0775","047c2a01687a49cb9abb8f75c1eba886","79de0cd65e50425e87607735cdf8fb99","14f539a808da4abba00e73499d03d5fe","9685864dc4cc40a3b10b189657f5064e","c3d763d1bfd04d1387692b5153cf1a49","f4f29b75396c46d98dae44c8e30d780f","c86a17643f0d4a0caee7494ea4218865","80b89b203b4f4ef1a99e68e7df80bf11","9902ca7e89bb4a1fac6a87394b25e2fb","98410f91241f4c1ba6255c9bb12d1467","b3d236473f07405fb41da58c240842b4","ff57a17d882e4308ae8431bdb5d1d3d0","c055d39213b340f9b68aaf26565ff8ef","45335251de604fac97d39281e6e2b043","762308f4484a41e6a43cf64c79f71898","f4fe1f77f2f3405187368c0eaaeeb6ac","ce8f3f667758478c82b8d9077482f556","43dfa7fc965c4c0bb42f5efe36ef2884","acbf3356a19c4bccbb9f6e0f35ca5a2b","0adb0e13120149439730f1a900a65106"]},"executionInfo":{"status":"ok","timestamp":1699278649360,"user_tz":-120,"elapsed":7844,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}},"outputId":"a889f74c-110f-4512-b89c-e69da7ebd478"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc64f25f624444b92fc71d2f5d8e88d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c15079df56445b3b79d33034a867458"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3535d656d63143d4a5ccdd051307adff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cc806e11864499ab732f8b0c03a0973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46052f777c0845e58778ca2524e99aa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83292382f2f74ad5a7010c5652c0a983"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00bf01129ee40e8b8071c07f211c922"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35ea0c22ba83412a9de390a1364c6d10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bfb2703057d42b0bd2fa11f96c65b2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0242e7274e874f00ad4f248a87918e42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70139978676b43008e8961a1ed7cbc74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbb16f33ef824b07b446606e39c45d86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef87716a2084448c987b69bb9c0ff594"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98410f91241f4c1ba6255c9bb12d1467"}},"metadata":{}}],"source":["train_docs = [Document(page_content=json.dumps(obj), metadata={\"source\": \"local\"}) for obj in train_data]\n","embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n","faiss_db = FAISS.from_documents(train_docs, embeddings)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"EvTFQtVLX7NH","executionInfo":{"status":"ok","timestamp":1699278649360,"user_tz":-120,"elapsed":23,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}}},"outputs":[],"source":["template = \"\"\"Below are some examples that demonstrate the desiered tought process in your answer.\n","If you dont have all of the facts, try estimate or skip steps, but follow the general way of thinking.\n","In the end of your tought process, YOU MUST GIVE 'True' / 'False' ANSWER!\n","\n","Examples:\n","{context}\n","\n","Question:\n","{question}\n","\n","Answer:\n","\"\"\"\n","\n","QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n","max_documents = 4 # TODO\n","\n","qa_chain_gpt = RetrievalQA.from_chain_type(\n","    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n","    retriever=faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":max_documents}),\n","    return_source_documents=True,\n","    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",")\n","qa_chain_llama = RetrievalQA.from_chain_type(\n","    llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0}),\n","    retriever=faiss_db.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":max_documents}),\n","    return_source_documents=True,\n","    chain_type_kwargs={\"prompt\":  QA_CHAIN_PROMPT}\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"eONrzrddZB5e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699278649361,"user_tz":-120,"elapsed":22,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}},"outputId":"0ea9c1e5-43f6-423d-ee46-ed6f9ab96207"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'dict'>\n","{'qid': 'c6678ced9e10fc1c03f1', 'term': 'Second Amendment to the United States Constitution', 'description': 'Part of the Bill of Rights, regarding the right to bear arms', 'question': 'Was the Second Amendment to the United States Constitution written without consideration for black Americans?', 'facts': ['The writers of the Constitutional Amendments did not view black people as legitimate human beings.', 'The writers of the Constitutional Amendments believed that slavery benefited black slaves.', 'The Constitutional Amendments were written for people that the writers considered human.'], 'decomposition': ['Who were the writers of the Constitutional Amendments?', 'Who was the the Constitutional Amendments written for?', 'Did #1 fail to view black Americans as #2?'], 'evidence': [[[['Constitution of the United States-63'], 'no_evidence'], [['Constitution of the United States-51'], 'no_evidence'], [['African Americans-20'], 'operation']], [[['United States Bill of Rights-2'], 'no_evidence'], [['Constitution of the United States-132'], 'no_evidence'], [['Reconstruction Amendments-2'], 'no_evidence', 'operation']], [[['Ratification-18']], [['Constitution of the United States-3']], ['no_evidence']]], 'answer': True}\n"]}],"source":["# monitoring\n","print(type(test_data[0]))\n","print(test_data[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Ht-QdJjW42uM","executionInfo":{"status":"ok","timestamp":1699278649361,"user_tz":-120,"elapsed":5,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}}},"outputs":[],"source":["def get_one_word_answer(answer):\n","  one_word_answer = openai.ChatCompletion.create(\n","      model=\"gpt-3.5-turbo\",\n","      messages=[\n","          {\"role\": \"system\", \"content\": \"You are an assistant which summarizes a given ANSWER to a question into EXACTLY ONE of the following words: 'True', 'False' or 'None'. The prompts lengths may vary in length and may also be as JSON.\"},\n","          {\"role\": \"user\", \"content\": f\"ANSWER: {answer}\"}\n","      ]\n","  )\n","\n","  one_word = one_word_answer['choices'][0]['message']['content'].strip()\n","  if one_word == \"None\":\n","    return \"Other\"\n","  return one_word\n","\n","\n","def is_llm_correct(target_answer, llm_answer):\n","    return str(target_answer).lower() == str(llm_answer).lower()\n","\n","\n","def get_last_processed_index():\n","    try:\n","        with open('progress.txt', 'r') as f:\n","            return int(f.read().strip())\n","    except FileNotFoundError:\n","        return 0\n","\n","\n","def update_progress(index):\n","    with open('progress.txt', 'w') as f:\n","        f.write(str(index))\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3G5b7dNZCjp","executionInfo":{"status":"ok","timestamp":1699291888023,"user_tz":-120,"elapsed":4419246,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}},"outputId":"71e8af90-6b92-4056-ecc6-6ecb9eb594c3"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 0 __\n","__ Time: 2023-11-06 13:50:48 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n","  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 1 __\n","__ Time: 2023-11-06 13:50:58 __\n","\n","__ Starting iteration 2 __\n","__ Time: 2023-11-06 13:51:29 __\n","\n","__ Starting iteration 3 __\n","__ Time: 2023-11-06 13:51:47 __\n","\n","__ Starting iteration 4 __\n","__ Time: 2023-11-06 13:52:09 __\n","\n","__ Starting iteration 5 __\n","__ Time: 2023-11-06 13:52:42 __\n","\n","__ Starting iteration 6 __\n","__ Time: 2023-11-06 13:52:55 __\n","\n","__ Starting iteration 7 __\n","__ Time: 2023-11-06 13:53:07 __\n","\n","__ Starting iteration 8 __\n","__ Time: 2023-11-06 13:53:13 __\n","\n","__ Starting iteration 9 __\n","__ Time: 2023-11-06 13:53:28 __\n","\n","__ Starting iteration 10 __\n","__ Time: 2023-11-06 13:53:59 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 11 __\n","__ Time: 2023-11-06 13:54:13 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 12 __\n","__ Time: 2023-11-06 13:54:30 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 13 __\n","__ Time: 2023-11-06 13:54:36 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 14 __\n","__ Time: 2023-11-06 13:54:44 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 15 __\n","__ Time: 2023-11-06 13:55:06 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 16 __\n","__ Time: 2023-11-06 13:55:28 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 17 __\n","__ Time: 2023-11-06 13:55:34 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 18 __\n","__ Time: 2023-11-06 13:55:51 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 19 __\n","__ Time: 2023-11-06 13:56:14 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 20 __\n","__ Time: 2023-11-06 13:56:22 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 21 __\n","__ Time: 2023-11-06 13:56:30 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 22 __\n","__ Time: 2023-11-06 13:56:48 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 23 __\n","__ Time: 2023-11-06 13:57:02 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 24 __\n","__ Time: 2023-11-06 13:57:55 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 25 __\n","__ Time: 2023-11-06 13:58:22 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 26 __\n","__ Time: 2023-11-06 13:58:52 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 27 __\n","__ Time: 2023-11-06 13:59:06 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 28 __\n","__ Time: 2023-11-06 13:59:37 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 29 __\n","__ Time: 2023-11-06 14:00:07 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 30 __\n","__ Time: 2023-11-06 14:00:12 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 31 __\n","__ Time: 2023-11-06 14:00:36 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 32 __\n","__ Time: 2023-11-06 14:00:44 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 33 __\n","__ Time: 2023-11-06 14:01:00 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 34 __\n","__ Time: 2023-11-06 14:01:15 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 35 __\n","__ Time: 2023-11-06 14:01:37 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 36 __\n","__ Time: 2023-11-06 14:01:45 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 37 __\n","__ Time: 2023-11-06 14:02:03 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 38 __\n","__ Time: 2023-11-06 14:02:30 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 39 __\n","__ Time: 2023-11-06 14:02:35 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 40 __\n","__ Time: 2023-11-06 14:02:53 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 41 __\n","__ Time: 2023-11-06 14:03:07 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 42 __\n","__ Time: 2023-11-06 14:03:14 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 43 __\n","__ Time: 2023-11-06 14:03:34 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 44 __\n","__ Time: 2023-11-06 14:03:47 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 45 __\n","__ Time: 2023-11-06 14:04:00 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 46 __\n","__ Time: 2023-11-06 14:04:06 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 47 __\n","__ Time: 2023-11-06 14:04:39 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 48 __\n","__ Time: 2023-11-06 14:04:54 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 49 __\n","__ Time: 2023-11-06 14:05:00 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 14:15:00 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821de38d2b601049-ORD', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 50 __\n","__ Time: 2023-11-06 14:15:19 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 51 __\n","__ Time: 2023-11-06 14:15:25 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 52 __\n","__ Time: 2023-11-06 14:15:31 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 53 __\n","__ Time: 2023-11-06 14:15:51 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 54 __\n","__ Time: 2023-11-06 14:16:17 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 55 __\n","__ Time: 2023-11-06 14:16:33 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 56 __\n","__ Time: 2023-11-06 14:16:40 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 57 __\n","__ Time: 2023-11-06 14:16:56 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 58 __\n","__ Time: 2023-11-06 14:17:12 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 59 __\n","__ Time: 2023-11-06 14:17:29 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 60 __\n","__ Time: 2023-11-06 14:17:50 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 61 __\n","__ Time: 2023-11-06 14:18:12 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 62 __\n","__ Time: 2023-11-06 14:18:20 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 63 __\n","__ Time: 2023-11-06 14:18:27 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 64 __\n","__ Time: 2023-11-06 14:18:42 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 65 __\n","__ Time: 2023-11-06 14:19:06 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 66 __\n","__ Time: 2023-11-06 14:19:13 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 67 __\n","__ Time: 2023-11-06 14:19:20 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 68 __\n","__ Time: 2023-11-06 14:19:40 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 69 __\n","__ Time: 2023-11-06 14:19:58 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 70 __\n","__ Time: 2023-11-06 14:20:14 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 71 __\n","__ Time: 2023-11-06 14:20:22 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 72 __\n","__ Time: 2023-11-06 14:20:42 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 73 __\n","__ Time: 2023-11-06 14:20:48 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 74 __\n","__ Time: 2023-11-06 14:20:59 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 75 __\n","__ Time: 2023-11-06 14:21:12 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 76 __\n","__ Time: 2023-11-06 14:21:48 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 77 __\n","__ Time: 2023-11-06 14:22:24 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 78 __\n","__ Time: 2023-11-06 14:22:31 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 79 __\n","__ Time: 2023-11-06 14:22:38 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 80 __\n","__ Time: 2023-11-06 14:23:15 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 81 __\n","__ Time: 2023-11-06 14:23:28 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 82 __\n","__ Time: 2023-11-06 14:23:45 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 83 __\n","__ Time: 2023-11-06 14:24:09 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 84 __\n","__ Time: 2023-11-06 14:24:18 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 85 __\n","__ Time: 2023-11-06 14:24:32 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 86 __\n","__ Time: 2023-11-06 14:24:40 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error processing item 86: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n","\n","__ Starting iteration 87 __\n","__ Time: 2023-11-06 14:35:55 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 88 __\n","__ Time: 2023-11-06 14:36:14 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error processing item 88: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n","\n","__ Starting iteration 89 __\n","__ Time: 2023-11-06 14:47:26 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 90 __\n","__ Time: 2023-11-06 14:47:38 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 91 __\n","__ Time: 2023-11-06 14:47:57 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error processing item 91: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n","\n","__ Starting iteration 92 __\n","__ Time: 2023-11-06 14:59:11 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 93 __\n","__ Time: 2023-11-06 14:59:28 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 94 __\n","__ Time: 2023-11-06 14:59:49 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 95 __\n","__ Time: 2023-11-06 15:00:21 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 96 __\n","__ Time: 2023-11-06 15:00:32 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 97 __\n","__ Time: 2023-11-06 15:00:53 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 98 __\n","__ Time: 2023-11-06 15:01:25 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 99 __\n","__ Time: 2023-11-06 15:01:37 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 100 __\n","__ Time: 2023-11-06 15:01:45 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 101 __\n","__ Time: 2023-11-06 15:02:18 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 102 __\n","__ Time: 2023-11-06 15:02:58 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error processing item 102: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 15:13:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821e38d7a9fb6354-ORD', 'alt-svc': 'h3=\":443\"; ma=86400'}\n","\n","__ Starting iteration 103 __\n","__ Time: 2023-11-06 15:14:14 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 104 __\n","__ Time: 2023-11-06 15:14:49 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 105 __\n","__ Time: 2023-11-06 15:15:09 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 106 __\n","__ Time: 2023-11-06 15:15:35 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 107 __\n","__ Time: 2023-11-06 15:16:20 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 108 __\n","__ Time: 2023-11-06 15:16:32 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 109 __\n","__ Time: 2023-11-06 15:16:55 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 110 __\n","__ Time: 2023-11-06 15:17:11 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error processing item 110: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n","\n","__ Starting iteration 111 __\n","__ Time: 2023-11-06 15:28:22 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 112 __\n","__ Time: 2023-11-06 15:28:33 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 113 __\n","__ Time: 2023-11-06 15:29:09 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 114 __\n","__ Time: 2023-11-06 15:29:34 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 115 __\n","__ Time: 2023-11-06 15:30:01 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 116 __\n","__ Time: 2023-11-06 15:30:49 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 117 __\n","__ Time: 2023-11-06 15:30:58 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 118 __\n","__ Time: 2023-11-06 15:31:20 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 119 __\n","__ Time: 2023-11-06 15:31:43 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 120 __\n","__ Time: 2023-11-06 15:31:50 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 121 __\n","__ Time: 2023-11-06 15:32:42 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 122 __\n","__ Time: 2023-11-06 15:33:00 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 123 __\n","__ Time: 2023-11-06 15:33:21 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 124 __\n","__ Time: 2023-11-06 15:33:44 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error processing item 124: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n","\n","__ Starting iteration 125 __\n","__ Time: 2023-11-06 15:44:50 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 126 __\n","__ Time: 2023-11-06 15:45:25 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 127 __\n","__ Time: 2023-11-06 15:45:34 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error processing item 127: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n","\n","__ Starting iteration 128 __\n","__ Time: 2023-11-06 15:56:40 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 129 __\n","__ Time: 2023-11-06 15:56:58 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 130 __\n","__ Time: 2023-11-06 15:57:10 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 131 __\n","__ Time: 2023-11-06 15:57:23 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 132 __\n","__ Time: 2023-11-06 15:57:30 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 133 __\n","__ Time: 2023-11-06 15:57:47 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 134 __\n","__ Time: 2023-11-06 15:57:54 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 135 __\n","__ Time: 2023-11-06 15:58:00 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 136 __\n","__ Time: 2023-11-06 15:58:07 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Error processing item 136: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n","\n","__ Starting iteration 137 __\n","__ Time: 2023-11-06 16:09:41 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 138 __\n","__ Time: 2023-11-06 16:09:48 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 139 __\n","__ Time: 2023-11-06 16:10:01 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 140 __\n","__ Time: 2023-11-06 16:10:11 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 141 __\n","__ Time: 2023-11-06 16:10:30 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 142 __\n","__ Time: 2023-11-06 16:10:45 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 143 __\n","__ Time: 2023-11-06 16:10:52 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 144 __\n","__ Time: 2023-11-06 16:10:58 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 145 __\n","__ Time: 2023-11-06 16:11:20 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 146 __\n","__ Time: 2023-11-06 16:11:38 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 147 __\n","__ Time: 2023-11-06 16:11:51 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 148 __\n","__ Time: 2023-11-06 16:12:19 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 149 __\n","__ Time: 2023-11-06 16:12:26 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 150 __\n","__ Time: 2023-11-06 16:12:34 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 151 __\n","__ Time: 2023-11-06 16:12:57 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 152 __\n","__ Time: 2023-11-06 16:13:14 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","__ Starting iteration 153 __\n","__ Time: 2023-11-06 16:13:21 __\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Error processing item 153: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 16:23:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821e9fe7da4c8119-ORD', 'alt-svc': 'h3=\":443\"; ma=86400'}\n","\n","__ Starting iteration 154 __\n","__ Time: 2023-11-06 16:24:35 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 155 __\n","__ Time: 2023-11-06 16:24:43 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 156 __\n","__ Time: 2023-11-06 16:25:15 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 157 __\n","__ Time: 2023-11-06 16:25:35 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 158 __\n","__ Time: 2023-11-06 16:25:43 __\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 159 __\n","__ Time: 2023-11-06 16:36:09 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Error processing item 159: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 16:46:16 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821ec123bc63232f-ORD', 'alt-svc': 'h3=\":443\"; ma=86400'}\n","\n","__ Starting iteration 160 __\n","__ Time: 2023-11-06 16:47:16 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 161 __\n","__ Time: 2023-11-06 16:47:30 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 162 __\n","__ Time: 2023-11-06 16:47:52 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 163 __\n","__ Time: 2023-11-06 16:48:11 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 164 __\n","__ Time: 2023-11-06 16:49:02 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 165 __\n","__ Time: 2023-11-06 16:49:37 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 166 __\n","__ Time: 2023-11-06 16:50:02 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Error processing item 166: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 06 Nov 2023 17:00:08 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '821ed56f8c4e61b6-ORD', 'alt-svc': 'h3=\":443\"; ma=86400'}\n","\n","__ Starting iteration 167 __\n","__ Time: 2023-11-06 17:01:08 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 168 __\n","__ Time: 2023-11-06 17:01:14 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Error processing item 168: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n","\n","__ Starting iteration 169 __\n","__ Time: 2023-11-06 17:12:25 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 170 __\n","__ Time: 2023-11-06 17:12:31 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 171 __\n","__ Time: 2023-11-06 17:13:06 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 172 __\n","__ Time: 2023-11-06 17:13:39 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 173 __\n","__ Time: 2023-11-06 17:13:59 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 174 __\n","__ Time: 2023-11-06 17:14:16 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 175 __\n","__ Time: 2023-11-06 17:14:23 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 176 __\n","__ Time: 2023-11-06 17:14:36 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 177 __\n","__ Time: 2023-11-06 17:15:07 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 178 __\n","__ Time: 2023-11-06 17:15:36 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 179 __\n","__ Time: 2023-11-06 17:15:42 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 180 __\n","__ Time: 2023-11-06 17:15:54 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 181 __\n","__ Time: 2023-11-06 17:16:04 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 182 __\n","__ Time: 2023-11-06 17:16:17 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 183 __\n","__ Time: 2023-11-06 17:16:33 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 184 __\n","__ Time: 2023-11-06 17:16:54 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 185 __\n","__ Time: 2023-11-06 17:17:08 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 186 __\n","__ Time: 2023-11-06 17:17:28 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 187 __\n","__ Time: 2023-11-06 17:17:34 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 188 __\n","__ Time: 2023-11-06 17:17:51 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 189 __\n","__ Time: 2023-11-06 17:18:07 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 190 __\n","__ Time: 2023-11-06 17:18:14 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 191 __\n","__ Time: 2023-11-06 17:18:46 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 192 __\n","__ Time: 2023-11-06 17:19:05 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 193 __\n","__ Time: 2023-11-06 17:19:29 __\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:langchain.llms.base:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n","/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 194 __\n","__ Time: 2023-11-06 17:29:39 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 195 __\n","__ Time: 2023-11-06 17:29:53 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 196 __\n","__ Time: 2023-11-06 17:29:59 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 197 __\n","__ Time: 2023-11-06 17:30:16 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 198 __\n","__ Time: 2023-11-06 17:30:22 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","__ Starting iteration 199 __\n","__ Time: 2023-11-06 17:31:08 __\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  warnings.warn(\n"]}],"source":["# List to hold the new objects with LLM responses\n","answered_data = []\n","last_processed_index = get_last_processed_index()\n","for i, obj in enumerate(test_data[last_processed_index:], start=last_processed_index):\n","    try:\n","        current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","        print(f'\\n__ Starting iteration {i} __')\n","        print(f'__ Time: {current_time} __')\n","\n","        # Get LMMs responses and runtime\n","        question_text = obj['question']\n","        t0 = time.time()\n","        gpt_response = qa_chain_gpt({\"query\": question_text})\n","        t1 = time.time()\n","        llama_response = qa_chain_llama({\"query\": question_text})\n","        t2 = time.time()\n","\n","        # Strip\n","        gpt_response['result'] = gpt_response['result'].strip()\n","        llama_response['result'] = llama_response['result'].strip()\n","\n","        # This filed make problems to save as json, lets save just the number for now\n","        obj['gpt_source_documents_number'] = len(gpt_response.pop('source_documents') )\n","        obj['llama_source_documents_number'] = len(llama_response.pop('source_documents') )\n","\n","        # Save results\n","        obj['gpt_response'] = gpt_response\n","        obj['llama_response'] = llama_response\n","\n","        # Save runtimes\n","        obj['gpt_run_time'] = t1 - t0\n","        obj['llama_run_time'] = t2 - t1\n","\n","        # Get 1 word answers\n","        obj['gpt_one_word_answer'] = get_one_word_answer(gpt_response['result'])\n","        obj['llama_one_word_answer'] = get_one_word_answer(llama_response['result'])\n","\n","        # Check correctness\n","        obj['is_gpt_correct'] = is_llm_correct(obj['answer'], obj['gpt_one_word_answer'])\n","        obj['is_llama_correct'] = is_llm_correct(obj['answer'], obj['llama_one_word_answer'])\n","\n","        answered_data.append(obj)\n","\n","        # Save updated object with the LLM answers as a JSON file after each iteration\n","        with open('answered_data.json', 'w') as f:\n","            json.dump(answered_data, f, indent=4)\n","        update_progress(i + 1)\n","\n","    except Exception as e:\n","        print(f\"Error processing item {i}: {e}\")\n","        time.sleep(60)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s8W0_N7JbWKu","executionInfo":{"status":"ok","timestamp":1699291889255,"user_tz":-120,"elapsed":1231,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}},"outputId":"e1a26e58-f36d-4b3a-96a5-0f2aa40e28ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did the Wehrmacht affect the outcome of the War to End All Wars?', 'result': \"To answer this question, we need to determine if the Wehrmacht, the German armed forces during World War I, had an impact on the outcome of the war.\\n\\n1. What notable events in which the Wehrmacht was of primary importance took place during the war?\\n   - The Wehrmacht played a significant role in various battles and offensives during World War I, such as the Battle of Tannenberg and the Spring Offensive.\\n\\n2. Did any of these events give a side an advantage during the war?\\n   - The Wehrmacht's successes in battles and offensives provided the German Empire with advantages and territorial gains during the early stages of the war.\\n\\nBased on the facts provided, it can be inferred that the Wehrmacht did affect the outcome of the War to End All Wars. Therefore, the answer is True.\"}\n","\n","__ llama_response __\n","{'query': 'Did the Wehrmacht affect the outcome of the War to End All Wars?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","5.575541257858276\n","\n","__ llama_run_time __\n","5.1281208992004395\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","f3d045e08844bf0d4e53\n","\n","__ term __\n","Creative Commons license\n","\n","__ description __\n","license allowing free use of a work\n","\n","__ question __\n","Was a person sold a Creative Commons License for Boticelli's The Birth of Venus ripped off?\n","\n","__ facts __\n","['A Creative Commons license allows for the free distribution of an otherwise copyrighted piece of work.', 'Works that are deemed in the public domain do not require a copyright or permission to use.', 'Any work created before 1923 is in the public domain.', \"Sandro Boticelli's The Birth of Venus painting was from 1486.\"]\n","\n","__ decomposition __\n","['What is the purpose of a Creative Commons license?', 'Do works in the public domain need #1?', 'Works created before what year are presently in the public domain?', \"Was Boticelli's The Birth of Venus created before #3?\", \"Considering #2 and #4, is #1 unnecessary for Boticelli's The Birth of Venus?\"]\n","\n","__ evidence __\n","[[[['Creative Commons license-1']], [['Public domain-1']], [['Public domain-10'], 'no_evidence'], [['The Birth of Venus-1'], 'operation'], ['operation']], [[['Creative Commons license-1']], [['Public domain-1']], [['Public domain-2']], [['The Birth of Venus-17']], ['operation']], [[['Creative Commons license-1']], [['Public domain-1']], [['Copyright term-2', 'Public domain-6'], 'no_evidence'], [['The Birth of Venus-1']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Was a person sold a Creative Commons License for Boticelli's The Birth of Venus ripped off?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"Was a person sold a Creative Commons License for Boticelli's The Birth of Venus ripped off?\", 'result': 'True'}\n","\n","__ gpt_run_time __\n","1.143070936203003\n","\n","__ llama_run_time __\n","5.842823028564453\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","91ec6f3b34115feccada\n","\n","__ term __\n","Ham\n","\n","__ description __\n","Pork from a leg cut that has been preserved by wet or dry curing, with or without smoking\n","\n","__ question __\n","Will parma ham be ready for New Year's if the pig is slaughtered in December?\n","\n","__ facts __\n","['Parma ham requires two months to cure', \"New Year's is at most one month away from December\"]\n","\n","__ decomposition __\n","['What is the minimum period of time required for parma ham to cure?', \"How long is New Year's Day from December?\", 'Is #2 greater than or equal to #1?']\n","\n","__ evidence __\n","[[[['Prosciutto-5']], [[\"New Year's Day-1\"]], ['operation']], [[['Prosciutto-5']], [[\"New Year's Day-1\"]], ['operation']], [[['Ham-10']], [[\"New Year's Day-8\"], 'operation'], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Will parma ham be ready for New Year's if the pig is slaughtered in December?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"Will parma ham be ready for New Year's if the pig is slaughtered in December?\", 'result': \"True\\n\\nExplanation:\\nThe question is asking about the readiness of Parma ham for New Year's, which is a holiday that takes place in December. Since the pig is slaughtered in December, it means that the ham will be ready for New Year's. Therefore, the answer is True.\"}\n","\n","__ gpt_run_time __\n","1.4556965827941895\n","\n","__ llama_run_time __\n","11.284294843673706\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","4e4b9fc379547c40adf5\n","\n","__ term __\n","Eddie Murphy\n","\n","__ description __\n","American stand-up comedian and actor\n","\n","__ question __\n","Did Eddie Murphy's father see his first stand up show?\n","\n","__ facts __\n","[\"Eddie Murphy's father died when Eddie Murphy was 8 years old.\", \"Eddie Murphy's stand up career began when he was 15 years old.\"]\n","\n","__ decomposition __\n","['How old was Eddie Murphy when he released his first stand up show?', 'How old was Eddie Murphy when his father died?', 'Is #2 greater than #1?']\n","\n","__ evidence __\n","[[[['Eddie Murphy-9'], 'no_evidence'], [['Eddie Murphy-7']], [['Eddie Murphy-1']]], [[['Eddie Murphy-9']], [['Eddie Murphy-7']], ['operation']], [[['Eddie Murphy-8']], [['Eddie Murphy-7']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Did Eddie Murphy's father see his first stand up show?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"Did Eddie Murphy's father see his first stand up show?\", 'result': 'True\\n\\nExplanation:\\nEddie Murphy\\'s father was alive when Eddie Murphy had his first stand-up show in 1982. Eddie Murphy\\'s father passed away in 2019.\\n\\nFacts:\\n• Eddie Murphy\\'s first stand-up show was in 1982.\\n• Eddie Murphy\\'s father, Charlie Murphy, was alive in 1982.\\n• Charlie Murphy passed away in 2019.\\n\\nDecomposition:\\n• Did Eddie Murphy\\'s father see his first stand-up show?\\n• When did Eddie Murphy have his first stand-up show?\\n• When did Eddie Murphy\\'s father pass away?\\n\\nEvidence:\\n• [[\"Eddie Murphy-1\", \"Eddie Murphy-2\"]], [[\"Charlie Murphy-1\"]], [[\"Eddie Murphy-1\", \"Charlie Murphy-2\"]], [\"operation\"]\\n\\nNote: The evidence is a list of two facts, where the first fact is \"Eddie Murphy\\'s first stand-up show was in 1982\" and the second fact is \"Charlie Murphy was alive in 1982\". The decomposition is asking if Eddie Murphy\\'s father saw his first stand-up show, and the answer is true because Charlie Murphy was alive in 1982 when Eddie Murphy had his first stand-up show.'}\n","\n","__ gpt_run_time __\n","1.2502655982971191\n","\n","__ llama_run_time __\n","37.61676526069641\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","97d147b2e3e29fa85a71\n","\n","__ term __\n","Ukrainian Greek Catholic Church\n","\n","__ description __\n","Byzantine Rite Eastern Catholic Church\n","\n","__ question __\n","Does Ukrainian Greek Catholic Church recognize Alexander Nevsky as a saint?\n","\n","__ facts __\n","['Alexander Nevsky was a Prince of Novgorod that fought against German and Swiss Invaders.', 'The Russian Orthodox Church named Alexander Nevsky.a saint in 1547.', 'The Russian Orthodox Church is a member of the Eastern Orthodox Church and has their own list of saints.', 'The Catholic Church and the Eastern Orthodox Church have been in a state of official schism since the East–West Schism of 1054.', 'The Ukrainian Greek Catholic Church is a branch of the Catholic Church.']\n","\n","__ decomposition __\n","['In which religion is Alexander Nevsky considered a saint?', 'What religion is the Ukrainian Greek Catholic Church a part of?', 'Is #1 and #2 the same?']\n","\n","__ evidence __\n","[[[['Alexander Nevsky-2']], [['Ukrainian Greek Catholic Church-1']], [['Russian Orthodox Church-73'], 'operation']], [[['Alexander Nevsky-2']], [['Ukrainian Greek Catholic Church-1']], ['operation']], [[['Alexander Nevsky-2']], [['Ukrainian Greek Catholic Church-31']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Does Ukrainian Greek Catholic Church recognize Alexander Nevsky as a saint?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Does Ukrainian Greek Catholic Church recognize Alexander Nevsky as a saint?', 'result': 'True\\n\\nExplanation:\\nThe question asks if Ukrainian Greek Catholic Church recognizes Alexander Nevsky as a saint. The church\\'s official website lists Alexander Nevsky as a saint, so the answer is true.\\n\\nFacts:\\n• Alexander Nevsky was a Russian prince and military leader.\\n• He defeated the Teutonic Knights in 1240 and saved Novgorod from their invasion.\\n• The Ukrainian Greek Catholic Church is a Eastern Catholic Church in full communion with the Pope and the worldwide Catholic Church.\\n\\nDecomposition:\\n• Who did Alexander Nevsky defeat in 1240?\\n• What did Alexander Nevsky save from invasion in 1240?\\n• Is #1 a part of #2?\\n\\nEvidence:\\n[[\"Alexander Nevsky-1\"], [\"no_evidence\"], [\"no_evidence\"]], [[\"Alexander Nevsky-1\"], [\"no_evidence\"], [\"no_evidence\"]], [[\"Alexander Nevsky-1\"], [\"Ukrainian Greek Catholic Church-1\"], [\"operation\"]]\\n\\nNote: The evidence provided is a simple list of facts, and the decomposition is a more detailed explanation of the question, breaking it down into smaller parts and providing additional information to help solve the problem. The answer is then given based on the evidence provided.'}\n","\n","__ gpt_run_time __\n","0.7844846248626709\n","\n","__ llama_run_time __\n","33.19006633758545\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","684d4c03be354635b80f\n","\n","__ term __\n","Christians\n","\n","__ description __\n","people who adhere to Christianity\n","\n","__ question __\n","Do Christians anticipate an existence in Sheol after death?\n","\n","__ facts __\n","['Sheol appears in the Christian Bible, in the Old Testament.', 'Christians do not recognize Sheol as part of their afterlife.']\n","\n","__ decomposition __\n","['Which Testament of the Bible makes reference to Sheol?', 'Is #1 the New Testament?', \"Is Sheol included in Christians' concept of afterlife as expressed in the New Testament?\", 'Is #2 or #3 positive?']\n","\n","__ evidence __\n","[[[['Sheol-2']], ['operation'], [['Heaven-15', 'Hell-34'], 'no_evidence'], ['operation']], [[['Sheol-1']], [['New Testament-1'], 'operation'], [['New Testament-11'], 'no_evidence'], ['operation']], [[['Sheol-2']], [['Sheol-1']], [['Afterlife-44']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Do Christians anticipate an existence in Sheol after death?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Do Christians anticipate an existence in Sheol after death?', 'result': 'True\\n\\nExplanation:\\nThe Bible teaches that Christians will be resurrected and transformed into immortal, imperishable bodies at the end of the age (1 Corinthians 15:52-53). While in Sheol, the souls of believers will be with God and will experience joy and happiness (Psalm 16:11).\\n\\nReferences:\\n1 Corinthians 15:52-53, Psalm 16:11\\n\\nPlease let me know if you need further assistance.'}\n","\n","__ gpt_run_time __\n","1.5495014190673828\n","\n","__ llama_run_time __\n","17.289608478546143\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","29bf9aa61ed4124cd84c\n","\n","__ term __\n","Albany, Georgia\n","\n","__ description __\n","City in Georgia, United States\n","\n","__ question __\n","Will the Albany in Georgia reach a hundred thousand occupants before the one in New York?\n","\n","__ facts __\n","['Albany, GA has around 75,000 people', 'Albany, NY has almost 100,000 people']\n","\n","__ decomposition __\n","['What is the population of Albany, Georgia?', 'What is the population of Albany, New York?', 'What is the difference between 100,000 and #1?', 'What is the difference between 100,000 and #2?', 'Is #3 smaller than #4?']\n","\n","__ evidence __\n","[[[['Albany, Georgia-1']], [['Albany, New York-2']], ['operation'], ['operation'], ['operation']], [[['Albany, Georgia-35']], [['Albany, New York-2']], ['operation'], ['operation'], ['operation']], [[['Albany, Georgia-1']], [['Albany, New York-2']], ['operation'], ['operation'], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Will the Albany in Georgia reach a hundred thousand occupants before the one in New York?', 'result': '{\"qid\": \"e3e8e8e8e8e8e8e8e8e8\", \"term\": \"Albany\", \"description\": \"Name of multiple cities in the United States\", \"question\": \"Will the Albany in Georgia reach a hundred thousand occupants before the one in New York?\", \"facts\": [\"The Albany in Georgia currently has a population of 77,434.\", \"The Albany in New York currently has a population of 97,856.\"], \"decomposition\": [\"What is the current population of the Albany in Georgia?\", \"What is the current population of the Albany in New York?\", \"Is the population of the Albany in Georgia less than 100,000?\", \"Is the population of the Albany in New York less than 100,000?\", \"Is the population of the Albany in Georgia less than the population of the Albany in New York?\"], \"evidence\": [[[[\"Albany, Georgia-1\"]], [[\"Albany, New York-1\"]], [[\"Albany, Georgia-1\"]], [[\"Albany, New York-1\"]], [\"operation\"]], [[[\"Albany, Georgia-1\"]], [[\"Albany, New York-1\"]], [[\"Albany, Georgia-1\"]], [[\"Albany, New York-1\"]], [\"operation\"]], [[[\"Albany, Georgia-1\"]], [[\"Albany, New York-1\"]], [[\"Albany, Georgia-1\"]], [[\"Albany, New York-1\"]], [\"operation\"]]], \"answer\": false}'}\n","\n","__ llama_response __\n","{'query': 'Will the Albany in Georgia reach a hundred thousand occupants before the one in New York?', 'result': 'True\\n\\nExplanation:\\nThe Albany in Georgia has a capacity of 80,000 people, while the Albany in New York has a capacity of 100,000 people. Therefore, the Albany in Georgia will reach a hundred thousand occupants before the one in New York.\\n\\nNote: The question is asking about the capacity of the Albany in Georgia and New York, and the answer is based on the information provided in the question.'}\n","\n","__ gpt_run_time __\n","8.362484693527222\n","\n","__ llama_run_time __\n","15.840745210647583\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","d8649d55a6e1a22b92d9\n","\n","__ term __\n","Psychic\n","\n","__ description __\n","person who claims to use extrasensory perception to identify information hidden from the normal senses\n","\n","__ question __\n","Would a psychic who admits to hot reading be trustworthy?\n","\n","__ facts __\n","['Hot reading is a technique used by people presenting themselves as psychics to acquire information about a subject prior to the psychic session.', 'Hot reading is considered deception in the psychic community.']\n","\n","__ decomposition __\n","['What do people pretend to be in order to successfully carry out hot reading?', \"Do the 'real' #1 consider hot reading to be genuine?\"]\n","\n","__ evidence __\n","[[[['Hot reading-1', 'Hot reading-2']], ['operation']], [[['Hot reading-1']], [['Hot reading-1', 'Hot reading-2']]], [[['Hot reading-1']], [['Psychic-1'], 'no_evidence', 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would a psychic who admits to hot reading be trustworthy?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Would a psychic who admits to hot reading be trustworthy?', 'result': 'True\\n\\nExplanation:\\nHot reading is a technique used by psychics to gather information about a person without their knowledge or consent. Since the psychic is not actually psychic, they are not able to provide any accurate information. Therefore, it is not possible for a psychic who admits to hot reading to be trustworthy.\\n\\nFacts:\\n• Psychic readings are a form of entertainment.\\n• Hot reading is a technique used by psychics to gather information about a person without their knowledge or consent.\\n• Psychics use various techniques to gather information, including cold reading, hot reading, and pre-show research.\\n\\nDecomposition:\\nWhat is hot reading?\\nCan a psychic who admits to hot reading be trustworthy?\\n\\nEvidence:\\n[[\"Hot reading-2\"], [[\"Psychic readings-2\"], \"operation\"]]\\n\\nIn this example, the decomposition process is used to break down the question into smaller parts, and then the answer is determined based on the facts provided. The evidence provided is a list of facts that are relevant to the question, and the decomposition process helps to identify the key points that are relevant to the answer.\\n\\nIn this case, the answer is determined to be true because hot reading is a technique used by psychics to gather information about a person without their knowledge or consent, and since the psychic is not actually psychic, they are not able to provide any accurate information. Therefore, it is not possible for a psychic who admits to hot reading to be trustworthy.\\n\\nIn general, the decomposition process is a useful tool for breaking down complex questions into smaller parts, and for identifying the key points that are relevant to the answer. By using the decomposition process, you can determine the answer to a question by analyzing the facts provided and identifying the relevant information.'}\n","\n","__ gpt_run_time __\n","0.8001065254211426\n","\n","__ llama_run_time __\n","43.09305787086487\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","d00ae50a07a5dd8b726c\n","\n","__ term __\n","Rede Globo\n","\n","__ description __\n","Brazilian commercial television network\n","\n","__ question __\n","Would it be typical for a Rede Globo anchor to say Konnichiwa to the viewers?\n","\n","__ facts __\n","['Konnichiwa is a greeting in the Japanese language.', 'The national language of Brazil is Portuguese.']\n","\n","__ decomposition __\n","['In which country is Rede Globo based?', 'What is the official language in #1?', 'What language is Konnichiwa?', 'Are #2 and #3 the same?']\n","\n","__ evidence __\n","[[[['Rede Globo-1']], [['Portuguese language-1']], [['Konnichi wa-1']], ['operation']], [[['Rede Globo-1']], [['Portuguese language-1']], [['Konnichi wa-1']], ['operation']], [[['Rede Globo-1']], [['Rede Globo-1']], [['Konnichi wa-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would it be typical for a Rede Globo anchor to say Konnichiwa to the viewers?', 'result': '{\"qid\": \"e8e8e8e8e8e8e8e8e8e8\", \"term\": \"Rede Globo\", \"description\": \"Brazilian television network\", \"question\": \"Would it be typical for a Rede Globo anchor to say Konnichiwa to the viewers?\", \"facts\": [\"Rede Globo is a Brazilian television network.\", \"Konnichiwa is a Japanese greeting meaning \\'good day\\' or \\'hello\\'.\"], \"decomposition\": [\"What is Rede Globo?\", \"What does Konnichiwa mean?\", \"Would it be typical for a #1 anchor to say #2 to the viewers?\"], \"evidence\": [[[[\"Rede Globo-1\"]], [[\"Konnichiwa-1\"]], [\"operation\"]], [[[\"Rede Globo-1\"]], [[\"Konnichiwa-1\"]], [\"operation\"]], [[[\"Rede Globo-1\"]], [[\"Konnichiwa-1\"]], [\"operation\"]]], \"answer\": false}'}\n","\n","__ llama_response __\n","{'query': 'Would it be typical for a Rede Globo anchor to say Konnichiwa to the viewers?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","5.915274620056152\n","\n","__ llama_run_time __\n","5.311005115509033\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","b15c390b221b7e0f9b1e\n","\n","__ term __\n","Legend\n","\n","__ description __\n","Traditional story of heroic humans.\n","\n","__ question __\n","Are all characters in Legend of Robin Hood fictional?\n","\n","__ facts __\n","['The Legend of Robin Hood tells of an archer that stole from the rich and gave to the poor.', \"Robin Hood's main antagonist is the Sheriff of Nottingham.\", 'The Sheriff of Nottingham is an agent for Prince John who has usurped the throne from his brother Richard.', 'Richard I was King of England from 1189-1199.', 'Prince John became John, King of England and reigned from 1199-1216.']\n","\n","__ decomposition __\n","[\"Who is Robin Hood's main antagonist in the Legend of Robin Hood?\", \"Who is #1's employer?\", \"Who is #2's brother who was usurped from the throne by him?\", 'Are #2 and #3 completely fictional characters?']\n","\n","__ evidence __\n","[[[['Robin Hood-2']], [['Sheriff of Nottingham-3']], [['The Legend of Robin Hood-2']], [['John, King of England-1'], 'operation']], [[['Sheriff of Nottingham-1']], [['Sheriff of Nottingham-5']], [['John, King of England-67']], [['John, King of England-1', 'Sheriff of Nottingham-2']]], [[['Sheriff of Nottingham-1']], [['Sheriff of Nottingham-5']], [['The Legend of Robin Hood-2']], [['Richard I of England-1'], 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Are all characters in Legend of Robin Hood fictional?', 'result': '{\"qid\": \"e7e8e8e8e8e8e8e8e8e8\", \"term\": \"Legend of Robin Hood\", \"description\": \"a legendary figure in English folklore\", \"question\": \"Are all characters in Legend of Robin Hood fictional?\", \"facts\": [\"The Legend of Robin Hood is a collection of stories and ballads that have been passed down through generations.\", \"Robin Hood is a legendary figure who is said to have lived during the reign of King Richard I in the 12th century.\", \"Many of the characters in the Legend of Robin Hood, such as Maid Marian, Little John, and Friar Tuck, are fictional characters created for the stories.\"], \"decomposition\": [\"Who are some of the characters in the Legend of Robin Hood?\", \"Are any of the characters in #1 based on real historical figures?\"], \"evidence\": [[[[\"Maid Marian-1\"], [\"Little John-2\"], [\"Friar Tuck-3\"]], [[\"Maid Marian-1\"], [\"Little John-2\"], [\"Friar Tuck-3\"]]], [[[\"Maid Marian-1\"], [\"Little John-2\"], [\"Friar Tuck-3\"]], [[\"Maid Marian-1\"], [\"Little John-2\"], [\"Friar Tuck-3\"]]]], \"answer\": true}'}\n","\n","__ llama_response __\n","{'query': 'Are all characters in Legend of Robin Hood fictional?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","9.070207595825195\n","\n","__ llama_run_time __\n","5.65320086479187\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","e7fec4d0e4350a2702c7\n","\n","__ term __\n","Japanese people\n","\n","__ description __\n","Ethnic group native to Japan\n","\n","__ question __\n","Did Pedubastis I know Japanese people?\n","\n","__ facts __\n","['Pedubastis I was a pharaoh that died in 800 BC', \"Japan's origins are in 600 BC according to a letter of the Sui dynasty.\", 'Pedubastis I ruled over the country of Egypt.']\n","\n","__ decomposition __\n","['When did Pedubastis I die?', 'When did the nation of Japan form?', 'Is #2 before #1?']\n","\n","__ evidence __\n","[[[['Pedubastis-2']], [['Graphic pejoratives in written Chinese-14']], [['Graphic pejoratives in written Chinese-14', 'Pedubastis-2'], 'operation']], [[['Pedubastis-2']], [['Graphic pejoratives in written Chinese-14']], ['operation']], [[['Pedubast I-1'], 'no_evidence'], [['Japan-9']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did Pedubastis I know Japanese people?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Did Pedubastis I know Japanese people?', 'result': 'True\\n\\nExplanation:\\nThe question is asking if Pedubastis I, who lived in the 4th century BC, knew any Japanese people. Since Pedubastis I lived in the ancient Near East, he could not have known any Japanese people, as Japan did not exist as a country at that time. Therefore, the answer is true.'}\n","\n","__ gpt_run_time __\n","0.5781092643737793\n","\n","__ llama_run_time __\n","13.66066312789917\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","d3c99400a786bc11c1fb\n","\n","__ term __\n","Ginger\n","\n","__ description __\n","Species of plant\n","\n","__ question __\n","Does a Starbucks passion tea have ginger in it?\n","\n","__ facts __\n","['Starbucks Passion tea features cinnamon, apple, licorice root, and lemongrass flavors.', 'Ginger is a spicy flavored plant.', 'Starbucks Passion tea is a sweet drink.']\n","\n","__ decomposition __\n","['What ingredients are in the Starbucks Passion Tea?', 'Is ginger part of #1?']\n","\n","__ evidence __\n","[[[['Starbucks-19'], 'no_evidence'], ['operation']], [['no_evidence'], ['no_evidence']], [['no_evidence'], ['no_evidence', 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Does a Starbucks passion tea have ginger in it?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Does a Starbucks passion tea have ginger in it?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","3.0299057960510254\n","\n","__ llama_run_time __\n","6.093793153762817\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","9224ee338a77834434c9\n","\n","__ term __\n","Kidney\n","\n","__ description __\n","internal organ in most animals, including vertebrates and some invertebrates\n","\n","__ question __\n","Can a quarter fit inside of a human kidney?\n","\n","__ facts __\n","['Kidney stones are hard mineral deposits that can form in the kidneys.', 'The largest kidney stone ever recorded was 13 cm wide.', 'The diameter of a quarter is 2.4 cm.']\n","\n","__ decomposition __\n","['How big is the largest kidney stone ever recorded?', 'How wide is a quarter?', 'Is #1 larger than #2?']\n","\n","__ evidence __\n","[[[['Kidney stone disease-46'], 'no_evidence'], [['Quarter (United States coin)-1']], ['operation']], [['no_evidence'], [['Quarter (United States coin)-3']], ['operation']], [[['Kidney-1']], [['Quarter (United States coin)-1']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can a quarter fit inside of a human kidney?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can a quarter fit inside of a human kidney?', 'result': \"True\\n\\nExplanation:\\nThis question is asking about the size of a human kidney, which is not something that can be easily measured or observed. However, we can estimate the size of a human kidney based on the size of other organs in the body.\\n\\nAccording to medical sources, the size of a human kidney can range from 4 to 6 inches (10 to 15 cm) in length and 2 to 3 inches (5 to 7.5 cm) in width. Using these dimensions, we can estimate the volume of a human kidney to be around 0.5 to 0.8 liters.\\n\\nNow, let's compare this volume to the size of a quarter. A quarter is 0.25 inches (6.35 mm) thick and 2.5 inches (6.35 cm) in diameter. Using these dimensions, we can calculate the volume of a quarter to be around 0.04 liters.\\n\\nAs we can see, the volume of a quarter is much smaller than the volume of a human kidney. Therefore, we can conclude that a quarter cannot fit inside of a human kidney.\\n\\nSo, the answer to the question is True.\"}\n","\n","__ gpt_run_time __\n","0.6125609874725342\n","\n","__ llama_run_time __\n","32.29679560661316\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","aef16532a9009fd318e2\n","\n","__ term __\n","The Jackson 5\n","\n","__ description __\n","American pop music family group\n","\n","__ question __\n","Was The Jackson 5 bigger family band than The Isley Brothers?\n","\n","__ facts __\n","['The Jackson 5 has sold over 100 million albums worldwide.', 'The Eisley Brothers have sold over 18 million albums.', 'The Jackson 5 consisted of Jackie, Tito, Jermaine, Marlon and Michael.', \"The Isley Brothers consisted of brothers O'Kelly, Rudolph. Ronald, and Vernon.\"]\n","\n","__ decomposition __\n","['How many albums has the Jackson 5 sold?', 'How many albums has the Eisley Brothers sold?', 'How many people were in the Jackson 5?', 'How many people made up the Eisley Brothers?', 'Is #1 greater than #2 and is #3 greater than #4?']\n","\n","__ evidence __\n","[[[['The Jackson 5-4']], [['The Isley Brothers-5']], [['Ronnie Rancifer-1']], [['The Isley Brothers-4']], ['operation']], [[['The Jackson 5-4']], [['The Isley Brothers-5']], [['The Jackson 5-1']], [['The Isley Brothers-1']], ['operation']], [[['The Jackson 5-4']], [['The Isley Brothers-5']], [['The Jackson 5-1']], [['The Isley Brothers-4']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Was The Jackson 5 bigger family band than The Isley Brothers?', 'result': '{\"qid\": \"e3e8e8e8e8e8e8e8e8e8\", \"term\": \"The Jackson 5\", \"description\": \"American family band\", \"question\": \"Was The Jackson 5 bigger family band than The Isley Brothers?\", \"facts\": [\"The Jackson 5 was formed in 1964 and consisted of five brothers: Jackie, Tito, Jermaine, Marlon, and Michael Jackson.\", \"The Jackson 5 achieved significant success in the 1970s with hits like \\'I Want You Back\\' and \\'ABC\\'.\", \"The Isley Brothers is an American musical group consisting of brothers Ronald, Rudolph, and O\\'Kelly Isley.\", \"The Isley Brothers have been active since the 1950s and have had several successful songs and albums.\"], \"decomposition\": [\"When was The Jackson 5 formed?\", \"What are some of The Jackson 5\\'s notable hits?\", \"Who are the members of The Isley Brothers?\", \"Which band has been active for a longer period of time?\", \"Which band has had more success in terms of hits and albums?\"], \"evidence\": [[[[\"The Jackson 5-1\"]], [\"no_evidence\"], [\"no_evidence\", \"operation\"]], [[[\"The Jackson 5-1\"]], [\"no_evidence\"], [\"no_evidence\", \"operation\"]], [[[\"The Isley Brothers-1\"]], [\"no_evidence\"], [\"no_evidence\", \"operation\"]], [[\"The Jackson 5-1\"], [\"The Isley Brothers-1\"], [\"no_evidence\", \"operation\"]], [[\"The Jackson 5-1\"], [\"The Isley Brothers-1\"], [\"no_evidence\", \"operation\"]]], \"answer\": true}'}\n","\n","__ llama_response __\n","{'query': 'Was The Jackson 5 bigger family band than The Isley Brothers?', 'result': \"True\\n\\nExplanation:\\nThe Jackson 5 consisted of 5 members: Jackie, Tito, Jermaine, Marlon, and Michael. The Isley Brothers consists of 3 members: Ronald, Rudolph, and O'Kelly Isley. Therefore, The Jackson 5 is a bigger family band than The Isley Brothers.\"}\n","\n","__ gpt_run_time __\n","10.149067640304565\n","\n","__ llama_run_time __\n","12.885270833969116\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","f9d0edee44a2e73f9765\n","\n","__ term __\n","Lolcat\n","\n","__ description __\n","image combining a photograph of a cat with text intended to contribute humour\n","\n","__ question __\n","Could a hundred thousand lolcats fit on a first generation iPhone?\n","\n","__ facts __\n","['Lolcat memes are often in jpeg form', 'The average size of a jpeg is 10 to 30 kb', 'One gigabyte is 1000000 kb', 'The first iPhone had 4GB to 16GB of storage ']\n","\n","__ decomposition __\n","['What file formats are lolcats usually saved in?', 'What is the typical size of #1?', 'What was the storage size range of first generation iPhones?', 'What is 100000 multiplied by #2 expressed in gigabytes?', 'Is #4 less than or equal to the minimum value of #3?']\n","\n","__ evidence __\n","[[[['Cats and the Internet-1', 'Image macro-2']], ['no_evidence'], [['IPhone (1st generation)-11', 'IPhone (1st generation)-7']], ['operation'], ['operation']], [[['Lolcat-1']], ['no_evidence'], [['IPhone (1st generation)-7']], [['Gigabyte-1'], 'operation'], ['operation']], [[['Image macro-1', 'Lolcat-1']], ['no_evidence'], [['IPhone (1st generation)-10']], ['no_evidence', 'operation'], ['no_evidence', 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Could a hundred thousand lolcats fit on a first generation iPhone?', 'result': \"To answer this question, we need to consider the size of a lolcat and the storage capacity of a first generation iPhone.\\n\\n1. What is the size of a lolcat?\\n   - We don't have this information, so we will estimate. Let's assume the average size of a lolcat image is 1 MB.\\n\\n2. What is the storage capacity of a first generation iPhone?\\n   - We don't have this information, so we will estimate. Let's assume the storage capacity of a first generation iPhone is 8 GB.\\n\\n3. How many lolcats can fit in 8 GB?\\n   - 1 GB is equal to 1024 MB, so 8 GB is equal to 8192 MB.\\n   - Therefore, 8192 lolcats can fit in 8 GB.\\n\\n4. Can a hundred thousand lolcats fit on a first generation iPhone?\\n   - Since 8192 lolcats can fit in 8 GB, it is clear that a hundred thousand lolcats cannot fit on a first generation iPhone.\\n   - Therefore, the answer is False.\"}\n","\n","__ llama_response __\n","{'query': 'Could a hundred thousand lolcats fit on a first generation iPhone?', 'result': 'True\\n\\nExplanation:\\n\\nThe first generation iPhone was released in 2007 and had a screen size of 3.5 inches. Therefore, we can estimate that the screen size of a hundred thousand lolcats would be around 350,000 inches.\\n\\nHowever, we know that the iPhone\\'s screen size is 3.5 inches, so we can skip steps 1 and 2 of the decomposition process.\\n\\nIn step 3, we are asked to determine whether #1 or #2 is true. Since #1 is true, we can answer the question with \"True\".\\n\\nTherefore, the answer to the question is True.'}\n","\n","__ gpt_run_time __\n","5.596590995788574\n","\n","__ llama_run_time __\n","19.285269737243652\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","4a915ea5d025292cd7ec\n","\n","__ term __\n","Serfdom\n","\n","__ description __\n","status of peasants under feudalism\n","\n","__ question __\n","Did Japanese serfdom have higher status than English counterpart?\n","\n","__ facts __\n","['Serfs in Medieval England were peasants that were indentured servants to their lords.', 'Serfs were often harshly treated and had little legal redress against the actions of their lords.', 'Japanese serfs were farmers and fishermen.', 'Japanese believed that serfs produced food, which was depended on by all classes, therefore, they worked harder.']\n","\n","__ decomposition __\n","['How did English lords treat their serfs?', 'What did the Japanese recognize serfs as?', 'Is #2 higher in importance than #1?']\n","\n","__ evidence __\n","[[[['Serfdom-2']], [['Serfdom-5']], ['operation']], [[['Serfdom-2']], [['Manorialism-17']], ['operation']], [[['Serfdom-2'], 'no_evidence'], [['Shōen-8', 'Shōen-9'], 'no_evidence'], ['no_evidence', 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did Japanese serfdom have higher status than English counterpart?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Did Japanese serfdom have higher status than English counterpart?', 'result': 'True\\n\\nExplanation:\\nThe question asks whether Japanese serfdom had higher status than its English counterpart. To answer this question, we must first define what we mean by \"status.\" Status can refer to various factors such as social standing, economic power, political influence, and cultural prestige.\\n\\nTo determine the status of Japanese serfdom compared to its English counterpart, we need to examine the historical context and the specific circumstances of each society.\\n\\nIn Japan, serfdom was a centralized system where the ruling samurai class controlled the land and the peasants who worked it. The peasants were required to provide labor and produce goods for the samurai, who in turn provided protection and governance. While serfdom was not unique to Japan, the system was particularly rigid and oppressive in Japan, where the peasants had limited rights and were subject to harsh punishments for disobedience.\\n\\nIn England, serfdom was more decentralized and less oppressive than in Japan. Serfs in England were required to provide labor and produce goods for their lord in exchange for protection and governance. However, they also had some rights and protections under the common law, such as the right to appeal to the king or to the church for relief from oppressive treatment.\\n\\nBased on these historical facts, we can say that the status of Japanese serfdom was generally lower than that of English serfs. Japanese serfs were subject to more rigid control and had fewer rights and protections than their English counterparts. Therefore, the answer to the question is True.\\n\\nIt is important to note that this answer is based on a simplified comparison of two complex societies at different points in history. There are many factors that could be taken into account when evaluating the status of serfs in these societies, such as the specific economic and social conditions, the role of religion and culture, and the political and social structures in place at the time.'}\n","\n","__ gpt_run_time __\n","1.1466937065124512\n","\n","__ llama_run_time __\n","45.794100522994995\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","7b84d2bc643ddc2085f0\n","\n","__ term __\n","Noah's Ark\n","\n","__ description __\n","the vessel in the Genesis flood narrative\n","\n","__ question __\n","WIll Noah's Ark hypothetically sail through flooded Lincoln Tunnel?\n","\n","__ facts __\n","[\"Scholars have determined Noah's Ark to be 75 feet wide.\", 'Each lane of the Lincoln Tunnel is 21 feet wide.']\n","\n","__ decomposition __\n","['What is the width of the Lincoln tunnel?', \"What is the width of the Noah's ark?\", 'Is #1 greater than #2?']\n","\n","__ evidence __\n","[[[['Lincoln Tunnel-5']], [['Cubit-1', \"Noah's Ark-3\"]], ['operation']], [[['Lincoln Tunnel-5']], [['Cubit-13', \"Noah's Ark-3\"]], ['operation']], [[['Lincoln Tunnel-5']], [[\"Noah's Ark-3\"], 'no_evidence'], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"WIll Noah's Ark hypothetically sail through flooded Lincoln Tunnel?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"WIll Noah's Ark hypothetically sail through flooded Lincoln Tunnel?\", 'result': 'False'}\n","\n","__ gpt_run_time __\n","0.5383846759796143\n","\n","__ llama_run_time __\n","6.07021427154541\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","False\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","3f726a8aa808d26ab076\n","\n","__ term __\n","Anchor\n","\n","__ description __\n","Device used to connect a vessel to the bed of a body of water to prevent the craft from drifting\n","\n","__ question __\n","Does a Trek 9000 require an anchor in order to park?\n","\n","__ facts __\n","['A Trek 9000 is a mountain bike', 'An anchor is used on water borne vehicles like boats']\n","\n","__ decomposition __\n","['What kind of vehicle is the Trek 9000?', 'Does #1 need an anchor to park?']\n","\n","__ evidence __\n","[[[['Trek Bicycle Corporation-7']], ['operation']], [[['International 9000-6'], 'operation'], ['no_evidence']], [[['Klein Bicycle Corporation-7']], [['Bicycle-30'], 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Does a Trek 9000 require an anchor in order to park?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Does a Trek 9000 require an anchor in order to park?', 'result': 'True\\n\\nExplanation:\\nThe question asks if a Trek 9000 requires an anchor in order to park. Since the Trek 9000 is a bicycle, it does not require an anchor to park. Therefore, the answer is True.\\n\\nIn this example, the decomposition process helps to identify the key information needed to answer the question. By breaking down the question into smaller parts, we can determine that the question is asking about the requirements of a Trek 9000 for parking. The evidence provided in the decomposition process includes the fact that the Trek 9000 is a bicycle, which does not require an anchor to park. Therefore, the answer is True.'}\n","\n","__ gpt_run_time __\n","0.6048080921173096\n","\n","__ llama_run_time __\n","19.78415322303772\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","1e97ab50309873ca1789\n","\n","__ term __\n","Bengal cat\n","\n","__ description __\n","Breed of cat\n","\n","__ question __\n","Could a Bengal cat hypothetically best Javier Sotomayor's record?\n","\n","__ facts __\n","[\"Javier Sotomayor is an athlete that holds the men's high jump world record of slightly over 8 feet.\", 'The average cat can jump from 7.5 to 9 feet.', 'Bengal cats have powerful hind legs which make them jump higher than other breeds.']\n","\n","__ decomposition __\n","[\"How high is Javier Sotomayor's world record high jump?\", 'Which breed of cat can jump the highest?', 'If the average cat can jump up to 9 feet, then #2 can jump higher than what number?', 'Is #3 greater than #1?']\n","\n","__ evidence __\n","[[[['Javier Sotomayor-1']], [['Bengal cat-21'], 'no_evidence'], ['operation'], ['operation']], [[['High jump-3']], [['Savannah cat-1', 'Savannah cat-21']], ['operation'], ['operation']], [[['Javier Sotomayor-1']], [['Caracal-2'], 'no_evidence'], [['Bengal cat-21'], 'no_evidence', 'operation'], ['no_evidence', 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Could a Bengal cat hypothetically best Javier Sotomayor's record?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"Could a Bengal cat hypothetically best Javier Sotomayor's record?\", 'result': \"True\\n\\nExplanation:\\nJavier Sotomayor is a Cuban former athlete, who won 18 Olympic medals, including 10 gold medals. Bengal cats are known to be agile and fast, but they are not athletes. Therefore, it is unlikely that a Bengal cat could best Javier Sotomayor's record in any Olympic event.\\n\\nNote: This answer is based on the information provided in the question and does not take into account any additional information that might be relevant.\"}\n","\n","__ gpt_run_time __\n","3.074854850769043\n","\n","__ llama_run_time __\n","17.381927728652954\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","a8f96cb3309095eeadc6\n","\n","__ term __\n","All Nippon Airways\n","\n","__ description __\n","Japanese Airline\n","\n","__ question __\n","Are the headquarters of All Nippon Airways near a beach?\n","\n","__ facts __\n","['The headquarters of All Nippon Airways are located in Shiodome City Center in the Shiodome area of the Minato ward of Tokyo.', 'Tokyo is a metropolitan area.', 'A beach is a landform alongside a body of water.', 'Metropolitan areas typically do not have bodies of water in the surrounding area.']\n","\n","__ decomposition __\n","['Where city are the headquarters of All Nippon Airways?', 'What kind of development area is #1?', 'What is a beach characterized as?', 'Do #2 areas typically have #3?']\n","\n","__ evidence __\n","[[[['All Nippon Airways-1']], [['Shiodome-2']], [['Beach-1']], ['operation']], [[['All Nippon Airways-1']], [['Shiodome-7']], [['Beach-1']], ['operation']], [[['All Nippon Airways-1']], [['Shiodome-1']], [['Beach-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Are the headquarters of All Nippon Airways near a beach?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Are the headquarters of All Nippon Airways near a beach?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.8173925876617432\n","\n","__ llama_run_time __\n","4.906672716140747\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","72d9416ee7093deb9eab\n","\n","__ term __\n","Alice's Adventures in Wonderland\n","\n","__ description __\n","book by Lewis Carroll\n","\n","__ question __\n","Could the main character of \"Alice's Adventures in Wonderland\" join a Masonic Lodge?\n","\n","__ facts __\n","['The main character of \"Alice\\'s Adventures in Wonderland\" is Alice, a young girl.', 'Masonic Lodge membership is restricted to men over the age of either 18 or 21, depending on jurisdiction.']\n","\n","__ decomposition __\n","['Who is the main character of \"Alice\\'s Adventures in Wonderland\"?', 'Does #1 meet the age and gender requirements for Masonic Lodge membership?']\n","\n","__ evidence __\n","[[[[\"Alice's Adventures in Wonderland-1\"]], [['Masonic lodge-11'], 'operation']], [[[\"Alice's Adventures in Wonderland-1\"]], [['Freemasonry-3'], 'no_evidence', 'operation']], [[[\"Alice's Adventures in Wonderland-1\"]], [['Freemasonry-14', 'Girl-1']]]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Could the main character of \"Alice\\'s Adventures in Wonderland\" join a Masonic Lodge?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Could the main character of \"Alice\\'s Adventures in Wonderland\" join a Masonic Lodge?', 'result': 'True\\n\\nExplanation:\\nThe main character of \"Alice\\'s Adventures in Wonderland\" is Alice. According to the book, Alice is a young girl who falls down a rabbit hole and enters a fantastical world called Wonderland. Wonderland is ruled by the tyrannical Queen of Hearts, who is obsessed with beheading anyone who disobeys her. Alice is a curious and adventurous young girl who is not afraid to challenge the Queen of Hearts and her illogical rules.\\n\\nMasonic lodges are secret societies that have been around for centuries. They are known for their elaborate rituals and codes, and their members are sworn to keep their activities and beliefs hidden from outsiders. While it is possible that Alice could have joined a Masonic lodge if she had lived during the time when Masonry was popular, it is unlikely that she would have been accepted as a member.\\n\\nIn the story, Alice is a curious and adventurous young girl who is always looking for new experiences. She is not afraid to challenge the Queen of Hearts and her illogical rules, and she is willing to take risks to achieve her goals. These traits make her a good candidate for joining a secret society like a Masonic lodge, where members are expected to be brave and loyal.\\n\\nHowever, there are also several reasons why Alice would not be accepted as a member of a Masonic lodge. First, Alice is not old enough to join a Masonic lodge, which is typically open only to adult men. Second, Alice is not from the same social class as the members of a Masonic lodge, who are usually wealthy and well-connected. Finally, Alice\\'s adventures in Wonderland are not focused on the kind of philosophical and spiritual pursuits that are central to Masonry.\\n\\nOverall, while it is possible that Alice could have joined a Masonic lodge if she had lived during the time when Masonry was popular, it is unlikely that she would have been accepted as a member due to her age, social class, and lack of focus on Masonic pursuits. Therefore, the answer to the question is True.'}\n","\n","__ gpt_run_time __\n","1.4378960132598877\n","\n","__ llama_run_time __\n","49.13911294937134\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","ee95615e3dafa5e19020\n","\n","__ term __\n","Darth Vader\n","\n","__ description __\n","fictional character in the Star Wars franchise\n","\n","__ question __\n","Is watching  Star Wars necessary to know who Darth Vader is?\n","\n","__ facts __\n","['Star Wars is one of the most widely parodied film series to be produced.', 'Star Wars merchandise, from tees to Halloween costumes, is widely available and is plentiful. ']\n","\n","__ decomposition __\n","['Has Star Wars inspired many parody films?', 'Are Star Wars merchandise depicting characters from the movie available?', 'Considering #1 and #2, are there no depictions of characters outside the movie?']\n","\n","__ evidence __\n","[[[['Robot Chicken: Star Wars-8']], [['Lego Star Wars-1']], [['Lego Star Wars-1', 'Robot Chicken: Star Wars-8']]], [[['Cultural impact of Star Wars-1', 'Star Wars: The Vintage Collection-1'], 'no_evidence'], [['Star Wars-1'], 'no_evidence'], ['operation']], [[['Lego Star Wars-9', 'Spaceballs-2']], [['Walker (Star Wars)-33']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is watching  Star Wars necessary to know who Darth Vader is?', 'result': \"To answer this question, we need to consider whether knowing who Darth Vader is requires watching Star Wars. \\n\\nFirst, let's break down the question:\\n- Is watching Star Wars necessary to know who Darth Vader is?\\n\\nNow, let's analyze the facts:\\n- Darth Vader is a character from Star Wars.\\n- Star Wars is a popular film franchise.\\n\\nBased on these facts, we can conclude that watching Star Wars is necessary to know who Darth Vader is. Therefore, the answer is True.\"}\n","\n","__ llama_response __\n","{'query': 'Is watching  Star Wars necessary to know who Darth Vader is?', 'result': 'true\\n\\nExplanation:\\nThis question is asking about the relationship between two things: watching Star Wars and knowing who Darth Vader is. Since Star Wars is a movie franchise and Darth Vader is a character from that franchise, it is reasonable to assume that someone who has watched Star Wars would know who Darth Vader is. Therefore, the answer is true.'}\n","\n","__ gpt_run_time __\n","3.0870883464813232\n","\n","__ llama_run_time __\n","13.259188175201416\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","58fd5574f3447c8f590f\n","\n","__ term __\n","Amnesia\n","\n","__ description __\n","Cognitive disorder where the memory is disturbed or lost\n","\n","__ question __\n","Would a student of the class of 2017 have amnesia about 9/11?\n","\n","__ facts __\n","['Childhood amnesia is common, with most adults not remembering their lives before 2 or 3 years of age', '9/11 occurred in 2001', 'Students graduating high-school in 2017 would have been born in 1999']\n","\n","__ decomposition __\n","['What year did 9/11 occur?', 'In what year would students graduating high-school in 2017 have been born in?', 'What age is childhood amnesia most common in?', 'If someone was born in #2, how old would they have been in #1?', 'Does #3 overlap with #4?']\n","\n","__ evidence __\n","[[[['September 11 attacks-1']], [['Yara Shahidi-1'], 'no_evidence'], [['Childhood amnesia-1']], ['operation'], ['operation']], [[['September 11 attacks-1']], [['Secondary school-1'], 'no_evidence'], [['Childhood amnesia-1']], ['no_evidence', 'operation'], ['no_evidence', 'operation']], [[['Inside 9/11-1']], [['Twelfth grade-54']], [['Childhood amnesia-3']], [['Infant-2']], [['Childhood amnesia-3', 'Infant-2'], 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would a student of the class of 2017 have amnesia about 9/11?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Would a student of the class of 2017 have amnesia about 9/11?', 'result': 'True\\n\\nExplanation:\\nThe student was born in 2000, which means they were 17 years old in 2017. Therefore, they would not have experienced 9/11 as they were not yet born.\\n\\nNote: The question is nonsensical because 9/11 occurred in 2001, and the student was not born until 2000. Therefore, the question is based on a false premise.'}\n","\n","__ gpt_run_time __\n","3.2430906295776367\n","\n","__ llama_run_time __\n","15.173624992370605\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","a6bf045651f7b6b64035\n","\n","__ term __\n","Macaque\n","\n","__ description __\n","genus of Old World monkeys\n","\n","__ question __\n","Could an elephant easily defeat a male macaque?\n","\n","__ facts __\n","['Male macaques range from 16 to 28 inches tall with a weight between 12.13 to 39.7 pounds.', 'Elephants are between 7 to 11 feet tall and weigh several thousand pounds.', 'Elephants contain large, sharp tusks that can injure or kill other animals.']\n","\n","__ decomposition __\n","['How much does a male macaques weigh?', 'How much can an elephant weigh?', 'How tall is a male macaque?', 'How tall is an elephant?', 'Is #2 more than #1 and is #4 more than #3?']\n","\n","__ evidence __\n","[[[['Macaque-4']], [['Elephant-14']], [['Macaque-4']], [['Elephant-12']], ['operation']], [[['Macaque-4']], [['Elephant-15']], [['Macaque-4']], [['Elephant-15']], ['operation']], [[['Macaque-4']], [['Elephant-15', 'Elephantidae-1'], 'no_evidence'], [['Macaque-4']], [['Elephant-15']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Could an elephant easily defeat a male macaque?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Could an elephant easily defeat a male macaque?', 'result': 'True\\n\\nExplanation:\\nWe don\\'t have all the facts, but we can estimate. We know that elephants are much larger and stronger than macaques. According to the decomposition, we can see that the macaque is not well-defended against physical attacks, and the evidence shows that elephants have a hard outer shell made of bony plates called osteoderms, which can withstand some force, but not a bullet. Based on these facts, it is likely that an elephant could defeat a male macaque in a physical confrontation. Therefore, we answer the question with \"True\".'}\n","\n","__ gpt_run_time __\n","2.7196202278137207\n","\n","__ llama_run_time __\n","18.221487998962402\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","2cc59f4d25398d251fd6\n","\n","__ term __\n","Olympia, Washington\n","\n","__ description __\n","State capital and city in Washington, United States\n","\n","__ question __\n","Is Olympia, Washington part of \"Ish river country\"?\n","\n","__ facts __\n","['Poet Robert Sund called the Puget Sound region \"Ish River country\".', 'Olympia is in the Puget Sound region.']\n","\n","__ decomposition __\n","['Where is Ish river country? ', 'What cities are located in #1?', 'Is Olympia included in the list in #2?']\n","\n","__ evidence __\n","[[[['Puget Sound region-1', 'Puget Sound region-2']], [['Washington (state)-79']], ['operation']], [[['Puget Sound region-1', 'Puget Sound region-2']], [['Puget Sound region-1'], 'no_evidence'], [['Washington (state)-1'], 'operation']], [[['Puget Sound region-2']], [['Puget Sound-4']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is Olympia, Washington part of \"Ish river country\"?', 'result': 'To determine if Olympia, Washington is part of \"Ish river country,\" we need to gather some information. \\n\\n1. What is \"Ish river country\"?\\n2. Is Olympia, Washington located in \"Ish river country\"?\\n\\nLet\\'s look at the evidence provided:\\n\\nEVIDENCE:\\n1. No evidence is given about \"Ish river country.\"\\n2. No evidence is given about Olympia, Washington\\'s location in relation to \"Ish river country.\"\\n\\nBased on the evidence, we do not have enough information to determine if Olympia, Washington is part of \"Ish river country.\" Therefore, the answer is False.'}\n","\n","__ llama_response __\n","{'query': 'Is Olympia, Washington part of \"Ish river country\"?', 'result': 'True\\n\\nExplanation:\\nThe question asks if Olympia, Washington is part of \"Ish river country\". To answer this question, we need to first determine what \"Ish river country\" refers to. From the decomposition, we can see that the term \"Ish river country\" is not defined in the given facts. Therefore, we cannot answer the question directly from the given information. However, we can estimate based on the context.\\n\\nOlympia is a city located in the state of Washington in the United States. Washington state is located in the western part of the United States. Therefore, we can estimate that \"Ish river country\" refers to the western part of the United States, including Washington state.\\n\\nSince Olympia is located in Washington state, which is in the western part of the United States, we can answer the question with \"True\".\\n\\nIn this case, the decomposition and evidence are not helpful in answering the question directly from the given facts. However, we can use context and estimation to arrive at a conclusion.'}\n","\n","__ gpt_run_time __\n","4.630082607269287\n","\n","__ llama_run_time __\n","26.628178358078003\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","4a974e322e3586af4c2f\n","\n","__ term __\n","Jalapeño\n","\n","__ description __\n","Hot pepper\n","\n","__ question __\n","Can children be hurt by jalapeno peppers?\n","\n","__ facts __\n","['Jalapeno peppers contain capsaicin. ', 'Capsaicin creates a burning sensation in the eyes and can lead to surface injuries. ', 'Small children do not understand how to protect themselves from peppers or how to wash their hands properly.']\n","\n","__ decomposition __\n","['What do Jalapeno peppers contain?', 'Can #1 cause injuries to a child if they are not careful?']\n","\n","__ evidence __\n","[[[['Jalapeño-15']], ['no_evidence']], [[['Capsaicin-1']], [['Capsaicin-17'], 'operation']], [[['Capsaicin-1']], [['Capsaicin-17'], 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can children be hurt by jalapeno peppers?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Can children be hurt by jalapeno peppers?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.5858175754547119\n","\n","__ llama_run_time __\n","6.242039442062378\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","89a19bd8f2bea335bca1\n","\n","__ term __\n","Doctor Strange\n","\n","__ description __\n","Superhero appearing in Marvel Comics publications and related media\n","\n","__ question __\n","Did Doctor Strange creators also make Batman?\n","\n","__ facts __\n","['Doctor Strange is a superhero created by Steve Ditko and Stan Lee.', 'Batman is a DC comics superhero.', 'Stan Lee worked for Marvel comics, the competitor of DC comics.', 'Steve Ditko worked for DC late in his career and worked on Blue Beetle, the Question, the Creeper, Shade the Changing Man, and Hawk and Dove.']\n","\n","__ decomposition __\n","[\"Who were the creators of the fictional character 'Doctor Strange'?\", \"Who were the creators of the fictional character 'Batman'?\", 'Are #1 the same as #2?']\n","\n","__ evidence __\n","[[[['Doctor Strange-1']], [['Batman-1']], ['operation']], [[['Doctor Strange-1']], [['Batman-1']], ['operation']], [[['Doctor Strange-1']], [['Batman-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did Doctor Strange creators also make Batman?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Did Doctor Strange creators also make Batman?', 'result': 'True\\n\\nExplanation:\\nDoctor Strange is a character from the Marvel Cinematic Universe, created by Stan Lee and Steve Ditko in 1963. Batman is a character from the DC Comics universe, created by Bob Kane and Bill Finger in 1939. While both characters have had various creators and writers work on them over the years, they are distinct and separate characters. Therefore, the answer is true.'}\n","\n","__ gpt_run_time __\n","0.6451711654663086\n","\n","__ llama_run_time __\n","15.313626289367676\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","8e073418da1eab499775\n","\n","__ term __\n","Islamophobia\n","\n","__ description __\n","Fear, hatred of, or prejudice against the Islamic religion or Muslims generally,\n","\n","__ question __\n","Is Islamophobia against Cyprus majority religion misdirected?\n","\n","__ facts __\n","['Islamophobia is prejudice and fear against Muslims.', 'Cyprus is a country in the Middle East, which is a predominantly Muslim region.', \"Cyprus is the only Christian majority country in the Middle East, with Christians forming between 76% and 78% of the country's total population, and most of them adhere to Eastern Orthodox Christianity.\"]\n","\n","__ decomposition __\n","['What religion is targeted by Islamophobia?', 'What is the most common religion in Cyprus?', 'Is #1 different than #2?']\n","\n","__ evidence __\n","[[[['Islamophobia-1']], [['Cyprus-100']], ['operation']], [[['Islamophobia-54'], 'no_evidence'], [['Religion in Cyprus-1'], 'operation'], ['no_evidence']], [[['Islamophobia-1']], [['Religion in Cyprus-1']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is Islamophobia against Cyprus majority religion misdirected?', 'result': '{\"qid\": \"e8e8e8e8e8e8e8e8e8e8\", \"term\": \"Cyprus\", \"description\": \"Island country in the Eastern Mediterranean\", \"question\": \"Is Islamophobia against Cyprus majority religion misdirected?\", \"facts\": [\"The majority religion in Cyprus is Christianity.\", \"Islamophobia refers to prejudice, fear, or hatred towards Islam and Muslims.\"], \"decomposition\": [\"What is the majority religion in Cyprus?\", \"What does Islamophobia refer to?\", \"Is #1 the target of Islamophobia in Cyprus?\"], \"evidence\": [[[[\"Cyprus-1\"]], [[\"Islamophobia-2\"]], [\"no_evidence\"]], [[\"Cyprus-1\"], [\"no_evidence\"], [[\"Islamophobia-1\"], \"no_evidence\"]], [[\"Cyprus-1\"], [[\"Islamophobia-1\"], \"no_evidence\"], [\"no_evidence\"]]], \"answer\": false}'}\n","\n","__ llama_response __\n","{'query': 'Is Islamophobia against Cyprus majority religion misdirected?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","5.612886667251587\n","\n","__ llama_run_time __\n","5.389956712722778\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","382571a1ab13a99b1f74\n","\n","__ term __\n","Shrimp\n","\n","__ description __\n","Decapod crustaceans\n","\n","__ question __\n","Is Steve Martin someone who would refuse a dish of shrimp pasta?\n","\n","__ facts __\n","['Steve Martin is allergic to shellfish.', 'Shrimp are one of the many types of shellfish.']\n","\n","__ decomposition __\n","['What types of food is Steve Martin allergic to?', 'What type of food is shrimp?', 'Is #2 included in #1?']\n","\n","__ evidence __\n","[[['no_evidence'], [['Shrimp-36']], ['no_evidence', 'operation']], [[['Steve Martin-1'], 'no_evidence'], [['Shrimp-1', 'Shrimp-34']], ['no_evidence', 'operation']], [['no_evidence'], [['Shrimp-16']], ['no_evidence', 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is Steve Martin someone who would refuse a dish of shrimp pasta?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Is Steve Martin someone who would refuse a dish of shrimp pasta?', 'result': 'True\\n\\nExplanation:\\nThe question asks if Steve Martin would refuse a dish of shrimp pasta. However, the facts provided state that Steve Martin is a vegetarian, which means he does not eat meat, including shrimp. Therefore, the answer is true.'}\n","\n","__ gpt_run_time __\n","0.3488931655883789\n","\n","__ llama_run_time __\n","10.878034830093384\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","49228a8553a4448fa366\n","\n","__ term __\n","Christmas carol\n","\n","__ description __\n","Song or hymn or carol on the theme of Christmas\n","\n","__ question __\n","Did the writer of Christmas carol fast during Ramadan? \n","\n","__ facts __\n","['The writer of Christmas carol is Charles Dickens, who is a Christian. ', 'Christians do not fast during Ramadan. ']\n","\n","__ decomposition __\n","['Which group of people fast during Ramadan?', 'Christmas carols are composed by and for which group of people?', 'Are #2 and #1 the same?']\n","\n","__ evidence __\n","[[[['Ramadan-1']], [['Christmas and holiday season-2', 'Christmas carol-1']], ['operation']], [[['Ramadan-1']], [['Christmas carol-1', 'Christmas-1']], ['operation']], [[['Ramadan-1']], [['Christmas carol-10']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did the writer of Christmas carol fast during Ramadan? ', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Did the writer of Christmas carol fast during Ramadan? ', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.5784034729003906\n","\n","__ llama_run_time __\n","5.727038383483887\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","3ca5966b88394e62271e\n","\n","__ term __\n","University of Pennsylvania\n","\n","__ description __\n","Private Ivy League research university in Philadelphia, Pennsylvania\n","\n","__ question __\n","Could Brooke Shields succeed at University of Pennsylvania?\n","\n","__ facts __\n","['Brooke Shields graduated from Princeton University.', 'Princeton is ranked as the number 1 national college by US news.', 'University of Pennsylvania is ranked as number 6 national college by US news.', 'Princeton only admits around 6 percent of applicants as of 2018.', 'University of Pennsylvania accepts around 9% of applicants as of 2018.']\n","\n","__ decomposition __\n","['What college did Brooke Shields go to?', 'Out of all colleges in the US, how is #1 ranked?', 'Is the ranking of University of Pennsylvania similar to #2?']\n","\n","__ evidence __\n","[[[['Brooke Shields-6']], [['Princeton University-59']], [['University of Pennsylvania-48']]], [[['Brooke Shields-6']], [['Princeton University-59']], [['University of Pennsylvania-48'], 'operation']], [[['Brooke Shields-6']], [['Princeton University-3'], 'operation'], [['University of Pennsylvania-47'], 'no_evidence']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Could Brooke Shields succeed at University of Pennsylvania?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Could Brooke Shields succeed at University of Pennsylvania?', 'result': 'True\\n\\nExplanation:\\nBrooke Shields is an American actress, born in 1943. The University of Pennsylvania is a private Ivy League university located in Philadelphia, Pennsylvania. It is possible that Brooke Shields could have attended the University of Pennsylvania, but there is no evidence to confirm or deny this. Therefore, the answer is True.\\n\\nNote: The decomposition and evidence are not included in this example as they are not relevant to the question.'}\n","\n","__ gpt_run_time __\n","0.55393385887146\n","\n","__ llama_run_time __\n","14.697202682495117\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","e7730031d304759520ba\n","\n","__ term __\n","Prussia\n","\n","__ description __\n","state in Central Europe between 1525–1947\n","\n","__ question __\n","Was the Euro used in Prussia?\n","\n","__ facts __\n","['Prussia was formally abolished in 1947.', 'The Euro was introduced in 1992.']\n","\n","__ decomposition __\n","['When was Prussia formally abolished?', 'When was the Euro introduced?', 'Is #2 before #1?']\n","\n","__ evidence __\n","[[[['Prussia-1']], [['Euro-18']], ['operation']], [[['Monarchies in Europe-27']], [['Euro-23']], ['operation']], [[['Prussia-2']], [['Euro-5']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Was the Euro used in Prussia?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Was the Euro used in Prussia?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.605229377746582\n","\n","__ llama_run_time __\n","5.301485300064087\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","52a0dd337fb870fa3eb8\n","\n","__ term __\n","Oscar Wilde\n","\n","__ description __\n","19th-century Irish poet, playwright and aesthete\n","\n","__ question __\n","Has Oscar Wilde's most famous character ever been in an Eva Green project?\n","\n","__ facts __\n","['Oscar Wilde is most famous for his book The Picture of Dorian Gray.', 'Dorian Gray is a beautiful socialite that is the main character of The Picture of Dorian Gray.', 'Acclaimed actress, Eva Green has starred in numerous films and TV shows including Penny Dreadful.', 'Dorian Gray flirts with Vanessa Ives in the Penny Dreadful episode, Seance.', 'Vanessa Ives is played by Eva Green.']\n","\n","__ decomposition __\n","[\"What is Oscar Wilde's most famous book?\", 'Who is the main character of #1?', 'What episode of Penny Dreadful was #2 in?', 'Is one of the characters in #3 played by Eva Green?']\n","\n","__ evidence __\n","[[[['Oscar Wilde-1']], [['The Picture of Dorian Gray-4']], [['Penny Dreadful (TV series)-2']], [['Eva Green-4']]], [[['Oscar Wilde-1']], [['The Picture of Dorian Gray-4']], [['Penny Dreadful (TV series)-2'], 'no_evidence'], [['Penny Dreadful (TV series)-3']]], [[['Oscar Wilde-1']], [['The Picture of Dorian Gray-4']], [['Penny Dreadful (TV series)-2'], 'no_evidence'], [['Reeve Carney-1', 'Vanessa Ives-1'], 'no_evidence']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Has Oscar Wilde's most famous character ever been in an Eva Green project?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"Has Oscar Wilde's most famous character ever been in an Eva Green project?\", 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.41121339797973633\n","\n","__ llama_run_time __\n","4.6428563594818115\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","f7a32d14efd589015fe1\n","\n","__ term __\n","Herpes simplex virus\n","\n","__ description __\n","Species of virus\n","\n","__ question __\n","Can Herpes simplex virus spread on Venus?\n","\n","__ facts __\n","['Herpes simplex virus is a disease that has the structure of a tiny protein cage.', 'Venus is the hottest planet and its temperature can reach 900°F.', 'Proteins lose their structure and break down at temperatures above 105.8°F.']\n","\n","__ decomposition __\n","['What kind of organism is the Herpes simplex virus?', 'What is the maximum temperature that #1 can withstand?', 'What is the average temperature on Venus?', 'Is #3 less than or equal to #2?']\n","\n","__ evidence __\n","[[[['Herpes simplex virus-1']], [['Virus-18'], 'no_evidence'], [['Venus-2']], ['operation']], [[['Herpes simplex virus-1']], [['Sterilization (microbiology)-14'], 'no_evidence'], [['Venus-2']], ['no_evidence', 'operation']], [[['Herpes simplex virus-1']], ['no_evidence'], [['Venus-2']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can Herpes simplex virus spread on Venus?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can Herpes simplex virus spread on Venus?', 'result': 'False'}\n","\n","__ gpt_run_time __\n","0.38018250465393066\n","\n","__ llama_run_time __\n","5.453433513641357\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","False\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","157e11814d768fe69782\n","\n","__ term __\n","Eighth Amendment to the United States Constitution\n","\n","__ description __\n","prohibits cruel and unusual punishment and excessive bail\n","\n","__ question __\n","Is Eighth Amendment to the United States Constitution popular in court?\n","\n","__ facts __\n","['The Eighth Amendment prohibits cruel and unusual punishment.', 'The Fifth Amendment prevents a person from incriminating themselves.', 'The Fifth Amendment is often invoked in criminal cases.', 'The Fourteenth Amendment regards equal protection under the law and has been in numerous landmark cases.']\n","\n","__ decomposition __\n","['How many cases have involved the 8th amendment?', 'How many cases have involved the other amendments?', 'Is #1 the highest out of #2?']\n","\n","__ evidence __\n","[[[['Eighth Amendment to the United States Constitution-30', 'Eighth Amendment to the United States Constitution-41'], 'no_evidence'], [['Supreme Court of the United States-73'], 'no_evidence'], ['operation']], [[['Eighth Amendment to the United States Constitution-2', 'Eighth Amendment to the United States Constitution-3'], 'no_evidence'], [['First Amendment to the United States Constitution-3', 'First Amendment to the United States Constitution-4'], 'no_evidence'], ['operation']], [[['Eighth Amendment to the United States Constitution-1'], 'no_evidence'], [['American Civil Liberties Union-36'], 'no_evidence'], ['no_evidence', 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is Eighth Amendment to the United States Constitution popular in court?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Is Eighth Amendment to the United States Constitution popular in court?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.6310000419616699\n","\n","__ llama_run_time __\n","5.936276197433472\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","d8eaf52f02c5cfb98bce\n","\n","__ term __\n","Sacrum\n","\n","__ description __\n","Triangular-shaped bone at the bottom of the spine\n","\n","__ question __\n","Do human sacrums have more fused vertebrae than an Alaskan Malamute?\n","\n","__ facts __\n","['The human sacrum consists of five fused vertebrae.', 'An Alaskan Malamute is a large domestic dog breed.', 'Dogs have three fused vertebrae attached to their sacrums.']\n","\n","__ decomposition __\n","['How many vertebrae are found in the human sacrum?', 'What species of animal is an Alaskan Malamute?', \"How many vertebrae are found in a #2's sacrum?\", 'Is #1 greater than #3?']\n","\n","__ evidence __\n","[[[['Sacrum-1']], [['Alaskan Malamute-1']], [['Dog anatomy-54', 'Nuchal ligament-10'], 'no_evidence'], ['no_evidence', 'operation']], [[['Sacrum-1']], [['Alaskan Malamute-1']], [['Sacrum-4']], ['operation']], [[['Sacrum-1']], [['Alaskan Malamute-1']], [['Sacrum-4']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Do human sacrums have more fused vertebrae than an Alaskan Malamute?', 'result': \"To answer this question, we need to compare the number of fused vertebrae in human sacrums and Alaskan Malamute sacrums.\\n\\nFirst, let's find out how many fused vertebrae are in a human sacrum. We don't have this information directly, so we need to estimate or skip this step. Let's assume that the average number of fused vertebrae in a human sacrum is 5.\\n\\nNext, let's find out how many fused vertebrae are in an Alaskan Malamute sacrum. We don't have this information directly, so we need to estimate or skip this step. Let's assume that the average number of fused vertebrae in an Alaskan Malamute sacrum is 3.\\n\\nNow, we can compare the number of fused vertebrae in human sacrums and Alaskan Malamute sacrums. Since we estimated that human sacrums have 5 fused vertebrae and Alaskan Malamute sacrums have 3 fused vertebrae, we can conclude that human sacrums have more fused vertebrae than an Alaskan Malamute.\\n\\nTherefore, the answer is True.\"}\n","\n","__ llama_response __\n","{'query': 'Do human sacrums have more fused vertebrae than an Alaskan Malamute?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","5.824319839477539\n","\n","__ llama_run_time __\n","5.683387756347656\n","\n","__ gpt_one_word_answer __\n","Other\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","08db047c63681c02184f\n","\n","__ term __\n","Basil\n","\n","__ description __\n","species of plant\n","\n","__ question __\n","Would the chef at Carmine's restaurant panic if there was no basil?\n","\n","__ facts __\n","['Carmines is an Italian family-style restaurant.', 'Basil is an essential in Italian cooking.']\n","\n","__ decomposition __\n","[\"What kind of cuisine does Carmine's serve?\", 'Is basil an essential ingredient in #1?']\n","\n","__ evidence __\n","[[[['Carmine Romano-2'], 'no_evidence'], [['Italian cuisine-27'], 'no_evidence', 'operation']], [['no_evidence'], ['no_evidence']], [['no_evidence'], ['no_evidence']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Would the chef at Carmine's restaurant panic if there was no basil?\", 'result': '{\"qid\": \"e8e8e8e8e8e8e8e8e8e8\", \"term\": \"Carmine\\'s restaurant\", \"description\": \"Italian restaurant known for family-style dining\", \"question\": \"Would the chef at Carmine\\'s restaurant panic if there was no basil?\", \"facts\": [\"Basil is commonly used in Italian cuisine.\", \"Carmine\\'s restaurant specializes in Italian cuisine.\"], \"decomposition\": [\"Is basil commonly used in Italian cuisine?\", \"Does Carmine\\'s restaurant specialize in Italian cuisine?\"], \"evidence\": [[[[\"Basil-1\"]], [[\"Italian cuisine-1\"]]], [[[\"Carmine\\'s restaurant-1\"]], [[\"Italian cuisine-1\"]]]], \"answer\": true}'}\n","\n","__ llama_response __\n","{'query': \"Would the chef at Carmine's restaurant panic if there was no basil?\", 'result': 'True'}\n","\n","__ gpt_run_time __\n","4.329980134963989\n","\n","__ llama_run_time __\n","5.285480976104736\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","9a87e2e0f53e5d8689f2\n","\n","__ term __\n","Sulfur\n","\n","__ description __\n","Chemical element with atomic number 16\n","\n","__ question __\n","Would food made with black salt smell of sulfur?\n","\n","__ facts __\n","['Black Salt has is a kiln-fired rock salt that contains sulfur.', 'When black salt is cooked with, it smells similar to rotten eggs. ', 'Rotten eggs smell like sulfur.']\n","\n","__ decomposition __\n","['What does black salt smell like when cooked?', 'Does #1 smell similar to sulfur?']\n","\n","__ evidence __\n","[[[['Kala namak-8']], [['Kala namak-8']]], [[['Kala namak-1']], [['Kala namak-1']]], [[['Sea salt-9'], 'no_evidence'], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would food made with black salt smell of sulfur?', 'result': 'To answer this question, we need to consider the properties of black salt and sulfur. Black salt, also known as kala namak, is a type of rock salt that is commonly used in Indian cuisine. Sulfur, on the other hand, is a chemical element that has a distinct smell of rotten eggs.\\n\\nBased on the given facts and decomposition, we can see that there is no direct evidence or information about the smell of black salt or its similarity to sulfur. Therefore, we cannot make a definitive conclusion about whether food made with black salt would smell of sulfur.\\n\\nAnswer: False'}\n","\n","__ llama_response __\n","{'query': 'Would food made with black salt smell of sulfur?', 'result': 'True\\n\\nExplanation:\\nBlack salt, also known as kala namak, is a type of rock salt that is commonly used in Indian cuisine. It has a distinctive sulfurous smell, which is due to the presence of trace amounts of hydrogen sulfide gas. Therefore, food made with black salt will indeed smell of sulfur.\\n\\nNote: The question is asking about the smell of food made with black salt, not the smell of black salt itself.'}\n","\n","__ gpt_run_time __\n","3.2287018299102783\n","\n","__ llama_run_time __\n","15.005322694778442\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","01786fe2b099fd7fb504\n","\n","__ term __\n","Minor League Baseball\n","\n","__ description __\n","hierarchy of professional baseball leagues affiliated with Major League Baseball\n","\n","__ question __\n","Were weather phenomena avoided when naming minor league baseball teams?\n","\n","__ facts __\n","['Weather phenomena refers to types of weather caused conditions such as cyclones, storms, and tsunamis.', 'Minor league baseball teams include the Brooklyn Cyclones and Lake Elsinore Storm.']\n","\n","__ decomposition __\n","['What are some names of weather phenomena?', 'What are the name of minor league baseball teams?', 'Are any terms in #1 also present in #2?']\n","\n","__ evidence __\n","[[[['Weather-5'], 'no_evidence'], [['Omaha Storm Chasers-1'], 'no_evidence'], ['operation']], [[['Glossary of meteorology-1'], 'no_evidence'], [['Minor League Baseball-40'], 'no_evidence'], ['no_evidence', 'operation']], [[['Thunder-1']], [['Trenton Thunder-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Were weather phenomena avoided when naming minor league baseball teams?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Were weather phenomena avoided when naming minor league baseball teams?', 'result': 'True\\n\\nExplanation:\\nIn this question, we are asked if weather phenomena were avoided when naming minor league baseball teams. To determine the answer, we must follow the decomposition of the question. The decomposition shows us that the answer depends on whether weather phenomena were avoided in the naming of minor league baseball teams. Since the question does not provide any information about weather phenomena being avoided in the naming of minor league baseball teams, the answer must be true. Therefore, the answer is true.'}\n","\n","__ gpt_run_time __\n","0.5547513961791992\n","\n","__ llama_run_time __\n","13.769243240356445\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","9e477711fe01970389d6\n","\n","__ term __\n","Alfred Nobel\n","\n","__ description __\n","Swedish chemist, innovator, and armaments manufacturer (1833–1896)\n","\n","__ question __\n","Did Alfred Nobel write a banned book?\n","\n","__ facts __\n","['Banned books are works which are not available for free access due to government restrictions.', 'Alfred Nobel is the author of Nemesis, a prose tragedy in four acts about Beatrice Cenci', \"The entire stock of Nemesis was destroyed immediately after Nobel's death except for three copies, being regarded as scandalous and blasphemous. \"]\n","\n","__ decomposition __\n","['What literary works did Alfred Nobel write?', 'Have any of the works listed in #1 been banned?']\n","\n","__ evidence __\n","[[[['Alfred Nobel-21']], ['operation']], [[['Alfred Nobel-21']], [['Alfred Nobel-21']]], [[['Alfred Nobel-21']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did Alfred Nobel write a banned book?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Did Alfred Nobel write a banned book?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.6064727306365967\n","\n","__ llama_run_time __\n","5.9295055866241455\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","b35f58b61b53c487d1ab\n","\n","__ term __\n","Polyamory\n","\n","__ description __\n","Practice of or desire for intimate relationships with more than one partner\n","\n","__ question __\n","Is polyamory allowed in the Catholic Church?\n","\n","__ facts __\n","['A central tenet of the Catholic Church is a one-to-one match between man and woman.', 'The ten commandments claim that \"coveting your neighbors wife\" is a sin.']\n","\n","__ decomposition __\n","['What is Polyamory?', 'Is #1 allowed in catholic churches?']\n","\n","__ evidence __\n","[[[['Polyamory-10']], [['Polygamy-34']]], [[['Polyamory-1']], [['Catholic Church-66'], 'operation']], [[['Polyamory-1']], [['Religion and sexuality-16']]]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is polyamory allowed in the Catholic Church?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Is polyamory allowed in the Catholic Church?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.29166460037231445\n","\n","__ llama_run_time __\n","4.783556222915649\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","234e4eccb374a4191c86\n","\n","__ term __\n","Eighth Amendment to the United States Constitution\n","\n","__ description __\n","prohibits cruel and unusual punishment and excessive bail\n","\n","__ question __\n","Would keelhauling be a fair punishment under the Eighth Amendment?\n","\n","__ facts __\n","['Keelhauling was a severe punishment whereby the condemned man was dragged beneath the ship’s keel on a rope.', 'Keelhauling is considered a form of torture.', 'Torture is considered cruel.', 'The Eighth Amendment forbids the use of \"cruel and unusual punishment\".']\n","\n","__ decomposition __\n","['What kind of punishment is keelhauling considered a form of?', 'Does the Eighth Amendment allow #1?']\n","\n","__ evidence __\n","[[[['Keelhauling-1']], [['Eighth Amendment to the United States Constitution-1'], 'operation']], [[['Keelhauling-2']], [['United States constitutional sentencing law-4']]], [[['Keelhauling-6']], [['Eighth Amendment to the United States Constitution-29']]]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would keelhauling be a fair punishment under the Eighth Amendment?', 'result': 'To answer this question, we need to consider the facts and the Eighth Amendment. \\n\\nFacts:\\n- Keelhauling is a historical maritime punishment where a person is dragged underwater from one side of a ship to the other.\\n- The Eighth Amendment of the United States Constitution prohibits cruel and unusual punishment.\\n\\nTought process:\\n1. Is keelhauling a form of punishment? - True\\n2. Does the Eighth Amendment prohibit cruel and unusual punishment? - True\\n3. Is keelhauling considered cruel and unusual punishment? - True\\n\\nBased on the facts and the Eighth Amendment, we can conclude that keelhauling would not be a fair punishment under the Eighth Amendment. \\n\\nAnswer: False'}\n","\n","__ llama_response __\n","{'query': 'Would keelhauling be a fair punishment under the Eighth Amendment?', 'result': 'True\\n\\nExplanation:\\nThe Eighth Amendment to the United States Constitution prohibits the government from imposing excessive or cruel punishments on individuals. Keelhauling, which involves dragging a person behind a ship by a rope or chain, is a form of corporal punishment that can cause serious injury or death. While it may be seen as a form of punishment in some cultures or historical contexts, it does not meet the standard of being a proportionate or non-cruel punishment under the Eighth Amendment. Therefore, the answer is true.'}\n","\n","__ gpt_run_time __\n","4.038856029510498\n","\n","__ llama_run_time __\n","17.098604440689087\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","32c562173099f5c2345f\n","\n","__ term __\n","Goblin shark\n","\n","__ description __\n","Deep-sea shark\n","\n","__ question __\n","Can a Goblin shark hypothetically ride a bike if it had limbs?\n","\n","__ facts __\n","['A Goblin shark weighs around 460 pounds.', 'The weight capacity of the average bike is 300 pounds.']\n","\n","__ decomposition __\n","['What is the average weight of a goblin? ', 'What is the average weight a bike can hold? ', 'Is #1 less than #2?']\n","\n","__ evidence __\n","[[[['Goblin shark-8'], 'no_evidence'], [['Birdy (bicycle)-11'], 'no_evidence'], ['operation']], [[['Goblin shark-1', 'Goblin shark-8']], [['Outline of bicycles-2'], 'no_evidence'], ['no_evidence', 'operation']], [[['Goblin shark-8']], [['Bicycle-26'], 'no_evidence'], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can a Goblin shark hypothetically ride a bike if it had limbs?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can a Goblin shark hypothetically ride a bike if it had limbs?', 'result': \"True\\n\\nExplanation:\\nThe question is asking about a hypothetical scenario where a Goblin shark, which is an aquatic creature, has limbs. This is not a realistic or possible scenario, as Goblin sharks do not have limbs. Therefore, the answer is true.\\n\\nHowever, it's important to note that this question is hypothetical and not based on real-world facts or evidence. It's a thought experiment designed to test your critical thinking skills and ability to reason about hypothetical scenarios.\"}\n","\n","__ gpt_run_time __\n","0.6081333160400391\n","\n","__ llama_run_time __\n","16.666767358779907\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","0b3c9c9aea94adef6e3a\n","\n","__ term __\n","Bitcoin\n","\n","__ description __\n","decentralized cryptocurrency\n","\n","__ question __\n","Was the Louisiana Purchase made with bitcoin?\n","\n","__ facts __\n","['Bitcoin was launched as a currency in 2009.', 'The Louisiana Purchase was in 1803.']\n","\n","__ decomposition __\n","['When was Bitcoin launched?', 'When did the Louisiana Purchase take place?', 'Is #1 prior to #2?']\n","\n","__ evidence __\n","[[[['Bitcoin-2']], [['Louisiana Purchase-1']], ['operation']], [[['Bitcoin-2']], [['Louisiana Purchase-1']], ['operation']], [[['Bitcoin-4']], [['Louisiana Purchase-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Was the Louisiana Purchase made with bitcoin?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Was the Louisiana Purchase made with bitcoin?', 'result': 'True\\n\\nExplanation:\\nThe Louisiana Purchase was made in 1803, and at that time, bitcoin did not exist. Therefore, the answer is true.\\n\\nNote: The decomposition and evidence are not relevant to the answer, as the question is asking about a historical event that occurred before the invention of bitcoin.'}\n","\n","__ gpt_run_time __\n","0.5227293968200684\n","\n","__ llama_run_time __\n","11.957462310791016\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","ac37cfbe97efb67fde55\n","\n","__ term __\n","Silverfish\n","\n","__ description __\n","species of insect\n","\n","__ question __\n","Could a silverfish reach the top of the Empire State Building?\n","\n","__ facts __\n","['Silverfish cannot fly.', 'Animals that cannot fly can only access objects at or near ground level without mechanical assistance.', 'The top of the Empire State Building is \\t1,454 ft high.']\n","\n","__ decomposition __\n","['How high is the Empire State Building?', 'What class of animals do silverfish belong to?', 'Can #2 typically get to heights of #1 without assistance?']\n","\n","__ evidence __\n","[[[['Empire State Building-1']], [['Silverfish-1']], [['Silverfish-1']]], [[['Empire State Building-1']], [['Silverfish-1']], ['operation']], [[['Empire State Building-1']], [['Silverfish-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Could a silverfish reach the top of the Empire State Building?', 'result': 'To answer this question, we need to consider the facts provided. The Empire State Building is a tall skyscraper located in New York City. Silverfish are small insects that are typically found in damp and dark areas. \\n\\nBased on this information, we can make some estimations. The Empire State Building is approximately 1,454 feet tall. Silverfish are small and do not have the ability to fly or climb vertical surfaces like walls. They are more commonly found crawling on the ground or on lower surfaces.\\n\\nGiven these facts, it is highly unlikely that a silverfish could reach the top of the Empire State Building. The height of the building is far beyond the capabilities of a silverfish to climb or reach. Therefore, the answer to the question is most likely false.'}\n","\n","__ llama_response __\n","{'query': 'Could a silverfish reach the top of the Empire State Building?', 'result': 'True\\n\\nExplanation:\\nThe height of the Empire State Building is 1,454 feet. Silverfish are not known to climb or jump, and their maximum height is around 10 cm (4 inches). Therefore, it is unlikely for a silverfish to reach the top of the Empire State Building.\\n\\nIn this case, the question is straightforward, and the answer is obvious. However, if there were additional facts or details, the answer could be different. For example, if there were a secret passage or elevator that only silverfish could use, then the answer could be true. Or, if the silverfish had some extraordinary abilities, such as superpowers or a magical transformation, then the answer could also be true.\\n\\nIn general, when answering questions like this, it is important to consider all the facts and details provided, and to think creatively and critically about the possibilities.'}\n","\n","__ gpt_run_time __\n","4.310399532318115\n","\n","__ llama_run_time __\n","22.85756230354309\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","a18c59e77cc176f748b2\n","\n","__ term __\n","Blue\n","\n","__ description __\n","A primary colour between purple and green\n","\n","__ question __\n","Do some home remedies result in your skin color turning blue?\n","\n","__ facts __\n","['Colloidal silver is a popular alternative treatment/home remedy that is used by some people.', 'Ingestion of colloidal silver in high amounts can tint the skin blue.']\n","\n","__ decomposition __\n","['What can cause skin color to change?', 'Of #1, what changes can be caused by ingestion of something?', 'Of #2, what causes skin color to become blue?', 'Is #3 used in home remedies?']\n","\n","__ evidence __\n","[[[['Argyria-1', 'Argyria-6', 'Carrot juice-3', 'Drug-induced pigmentation-2']], [['Carrot juice-3', 'Drug-induced pigmentation-2', 'Medical uses of silver-21']], [['Argyria-1']], [['Argyria-5'], 'operation']], [[['Human skin color-41', 'Human skin color-56'], 'no_evidence'], ['no_evidence'], ['no_evidence'], ['no_evidence', 'operation']], [[['Cyanosis-1']], [['Methemoglobinemia-2']], [['Methemoglobinemia-6']], [['Benzocaine-5'], 'no_evidence']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Do some home remedies result in your skin color turning blue?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Do some home remedies result in your skin color turning blue?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.5417063236236572\n","\n","__ llama_run_time __\n","5.702566623687744\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","6d14da7484991bf588cf\n","\n","__ term __\n","Royal Air Force\n","\n","__ description __\n","Aerial warfare service branch of the British Armed Forces\n","\n","__ question __\n","Did the Royal Air Force fight in the Boxer Rebellion?\n","\n","__ facts __\n","['The Boxer Rebellion took place from 1899–1901', 'The Royal Air Force was formed on 1 April 1918']\n","\n","__ decomposition __\n","['When was the Royal Air Force formed?', 'In what year did the Boxer Rebellion end?', 'Is #1 before #2?']\n","\n","__ evidence __\n","[[[['Royal Air Force-1']], [['Boxer Rebellion-1']], ['operation']], [[['Royal Air Force-1']], [['Boxer Rebellion-1']], ['operation']], [[['Royal Air Force-1']], [['Boxer Rebellion-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did the Royal Air Force fight in the Boxer Rebellion?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Did the Royal Air Force fight in the Boxer Rebellion?', 'result': 'False'}\n","\n","__ gpt_run_time __\n","0.3283250331878662\n","\n","__ llama_run_time __\n","6.275658130645752\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","False\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","265dd54c248f8b048851\n","\n","__ term __\n","Rede Globo\n","\n","__ description __\n","Brazilian commercial television network\n","\n","__ question __\n","Do the anchors on Rede Globo speak Chinese?\n","\n","__ facts __\n","['Rede Globo is a Brazilian television network.', 'The official language of Brazil is Portuguese.']\n","\n","__ decomposition __\n","['What country broadcasts Rede Globo?', 'What is the official language of #1?', 'Is #2 Chinese?']\n","\n","__ evidence __\n","[[[['Rede Globo-1']], [['Brazil-1']], ['operation']], [[['Rede Globo-1']], [['Brazil-1']], ['operation']], [[['Rede Globo-1']], [['Portuguese language-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Do the anchors on Rede Globo speak Chinese?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Do the anchors on Rede Globo speak Chinese?', 'result': 'False\\n\\nExplanation:\\nThe question is asking if the anchors on Rede Globo, a Brazilian television network, speak Chinese. However, the fact provided states that Cantonese is a dialect of Chinese language used in southern China, and there is no relation to the Japanese language. Therefore, it is unlikely that the anchors on Rede Globo speak Chinese. The decomposition and evidence provided further support this answer.\\n\\nIn this example, the decomposition and evidence are used to help determine the answer to the question. The decomposition breaks down the question into smaller parts, and the evidence provides additional information that can help determine the answer. In this case, the answer is false because the question is asking about the language spoken by anchors on a Brazilian television network, and the fact provided does not mention anything about Chinese language being spoken in Brazil.'}\n","\n","__ gpt_run_time __\n","0.33440327644348145\n","\n","__ llama_run_time __\n","22.29071545600891\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","False\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","3b38e00d8d1da26f7f02\n","\n","__ term __\n","Mario\n","\n","__ description __\n","fictional character from Nintendo's ''Mario'' franchise and the company's mascot\n","\n","__ question __\n","Does Mario use mushrooms to run faster?\n","\n","__ facts __\n","['Mushrooms in the Mario universe are used to provide extra lives and to make Mario grow, providing him an extra hit point. ', 'Mario is made to run faster when he wears bunny ears or uses a starman.']\n","\n","__ decomposition __\n","['In the Mario Universe what abilities do mushrooms give to Mario when collected?', 'Is any of #1 increased speed?']\n","\n","__ evidence __\n","[[[['Super Mario-33', 'Super Mario-35', 'Super Mario-36']], [['Super Mario-33']]], [[['Goomba-1']], ['operation']], [[['Super Mario-33']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Does Mario use mushrooms to run faster?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Does Mario use mushrooms to run faster?', 'result': 'True\\n\\nExplanation:\\nMario uses mushrooms to run faster in the Mario Kart series, specifically in the game Super Mario Kart. The mushrooms give Mario a temporary speed boost, allowing him to move faster and beat his opponents. Therefore, the answer is True.\\n\\nNote: The question and answer are simplified for the sake of explanation. In a real-world tought process, you would need to consider additional information and context to arrive at the correct answer.'}\n","\n","__ gpt_run_time __\n","0.5283873081207275\n","\n","__ llama_run_time __\n","15.786400318145752\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","66a3c0af3141c7c7d215\n","\n","__ term __\n","QWERTY\n","\n","__ description __\n","keyboard layout where the first line is \"QWERTYUIOP\"\n","\n","__ question __\n","Can monkeys use QWERTY keyboards?\n","\n","__ facts __\n","['QWERTY keyboards are an alphabet key layout that were first used on typrwriters. ', 'Monkeys can be trained to push buttons.', \"Typewriter key's are buttons.\", 'Monkeys can press keys on keyboards.']\n","\n","__ decomposition __\n","['What kind of keys are found on QWERTY keyboards?', 'Can #1 be likened to buttons?', 'Can monkeys be trained to push buttons?', 'Are #2 and #3 positive?']\n","\n","__ evidence __\n","[[[['QWERTY-17']], ['operation'], ['no_evidence', 'operation'], ['no_evidence', 'operation']], [[['QWERTY-12']], [['Keyboard layout-3']], [['Pet monkey-4']], ['operation']], [[['QWERTY-16', 'QWERTY-17']], [['Push-button-1'], 'no_evidence'], [['Tool use by animals-21'], 'no_evidence'], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can monkeys use QWERTY keyboards?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can monkeys use QWERTY keyboards?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.6634142398834229\n","\n","__ llama_run_time __\n","5.216222763061523\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","622c71f22ddb683c15a8\n","\n","__ term __\n","Casio\n","\n","__ description __\n","Japanese electronics company\n","\n","__ question __\n","Can you buy Casio products at Petco?\n","\n","__ facts __\n","['Casio is a manufacturer of consumer electronics and watches', 'Petco is a chain store that sells pet supplies like food, bowls, litter, toys, cages and grooming equipment']\n","\n","__ decomposition __\n","['What kind of products does Casio manufacture?', 'What kind of products does Petco sell?', 'Does #1 overlap with #2?']\n","\n","__ evidence __\n","[[[['Casio-1']], [['Petco-1']], ['operation']], [[['Casio-1']], [['Petco-1']], ['operation']], [[['Casio-1']], [['Petco-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can you buy Casio products at Petco?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can you buy Casio products at Petco?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.6743299961090088\n","\n","__ llama_run_time __\n","6.273913145065308\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","722dc38bd849d8b6ec0f\n","\n","__ term __\n","Reproduction\n","\n","__ description __\n","Biological process by which new organisms are generated from one or more parent organisms\n","\n","__ question __\n","Are those incapable of reproduction incapable of parenthood?\n","\n","__ facts __\n","['Surrogates are women who will carry a baby to term for a family seeking to adopt.', 'Many children are put into the adoption and foster system every year and are always available to adopt, independent of the parents reproductive status.']\n","\n","__ decomposition __\n","['What do surrogate mothers do?', 'What purpose do adoption and foster systems serve?', 'Do #1 and #2 fail to help couples incapable of reproduction become parents?']\n","\n","__ evidence __\n","[[[['Mother-11']], [['Adoption-8']], ['operation']], [[['Surrogacy-1', 'Surrogacy-2']], [['Adoption-1', 'Foster care-1']], ['operation']], [[['Surrogacy-1']], [['Adoption-1']], ['no_evidence']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Are those incapable of reproduction incapable of parenthood?', 'result': \"To answer this question, we need to consider the relationship between reproduction and parenthood. \\n\\nFirst, let's define what it means to be incapable of reproduction. This refers to individuals who are unable to conceive or produce offspring naturally.\\n\\nNext, let's consider the concept of parenthood. Parenthood involves the act of raising and caring for a child, regardless of whether the child is biologically related to the parent.\\n\\nBased on these definitions, we can conclude that those who are incapable of reproduction are not necessarily incapable of parenthood. Parenthood is not solely dependent on biological reproduction, as individuals can become parents through adoption, surrogacy, or other means.\\n\\nTherefore, the answer to the question is: False. Those who are incapable of reproduction can still be capable of parenthood.\"}\n","\n","__ llama_response __\n","{'query': 'Are those incapable of reproduction incapable of parenthood?', 'result': 'true\\n\\nExplanation:\\nThe question is asking if those who are incapable of reproduction are also incapable of parenthood. To answer this question, we need to consider the relationship between reproduction and parenthood. Reproduction refers to the biological process of creating offspring, while parenthood refers to the responsibility and care for those offspring.\\n\\nSince those who are incapable of reproduction are not biologically capable of creating offspring, it follows that they are also not capable of fulfilling the responsibilities and care required of parenthood. Therefore, the answer to the question is true.\\n\\nHowever, it is important to note that this answer is based on a narrow definition of reproduction and parenthood. There are many different ways to define these terms, and different cultures and societies may have different definitions and expectations. Therefore, this answer may not be universally applicable, and further investigation and discussion may be necessary to fully understand the relationship between reproduction and parenthood.'}\n","\n","__ gpt_run_time __\n","4.362086296081543\n","\n","__ llama_run_time __\n","27.29975175857544\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","03c467f12c3fcc1d91fe\n","\n","__ term __\n","Clouded leopard\n","\n","__ description __\n","species of mammal found from the Himalayan foothills through mainland Southeast Asia into China\n","\n","__ question __\n","Can Clouded leopards chase down many Pronghorn antelopes?\n","\n","__ facts __\n","['The top speed of a Clouded leopard is 40 MPH.', 'The top speed of a Pronghorn antelope is 61 MPH.']\n","\n","__ decomposition __\n","['What is the top speed for a Clouded leopard ?', 'What is the top speed for a Pronghorn antelope ?', 'Is #1 greater then or equal to #2?']\n","\n","__ evidence __\n","[[[['Clouded leopard-31'], 'no_evidence'], [['Pronghorn-12']], ['operation']], [['no_evidence'], [['Pronghorn-12']], ['operation']], [[['Leopard-4'], 'no_evidence'], [['Pronghorn-12']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can Clouded leopards chase down many Pronghorn antelopes?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can Clouded leopards chase down many Pronghorn antelopes?', 'result': 'True\\n\\nExplanation:\\nClouded leopards are classified as Least Concern on IUCN endangered list, meaning they are not considered to be in immediate danger of extinction. Pronghorn antelopes are classified as Least Concern on IUCN endangered list. While Clouded leopards are known to be agile and powerful predators, they do not have the physical attributes or the prey base to chase down many Pronghorn antelopes.\\n\\nNote: The answer is based on the information provided in the question and the decomposition. If there were additional facts or evidence, the answer might be different.'}\n","\n","__ gpt_run_time __\n","0.5268728733062744\n","\n","__ llama_run_time __\n","18.415552854537964\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","e8b311139f387c983996\n","\n","__ term __\n","Saltwater crocodile\n","\n","__ description __\n","species of reptile\n","\n","__ question __\n","Would you take a photo of a Saltwater crocodile in Memphis?\n","\n","__ facts __\n","[\"The saltwater crocodile is native to saltwater habitats and brackish wetlands from India's east coast across Southeast Asia and the Sundaic region to northern Australia and Micronesia.\", 'Memphis is a city in the United States.']\n","\n","__ decomposition __\n","['Where can saltwater crocodiles be found?', 'Is Memphis located in any of #1?']\n","\n","__ evidence __\n","[[[['Saltwater crocodile-1']], ['operation']], [[['Saltwater crocodile-1']], [['Memphis, Tennessee-1']]], [[['Saltwater crocodile-20']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would you take a photo of a Saltwater crocodile in Memphis?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Would you take a photo of a Saltwater crocodile in Memphis?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.30115294456481934\n","\n","__ llama_run_time __\n","5.3077003955841064\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","4013c96b17809c27699c\n","\n","__ term __\n","National Diet\n","\n","__ description __\n","legislature of Japan\n","\n","__ question __\n","Can Viper Room concert hypothetically be held at National Diet building?\n","\n","__ facts __\n","['The Viper Room has a capacity of 250 people.', 'The National Diet building has two wings with over 700 seats.']\n","\n","__ decomposition __\n","['What is the capacity of the The Viper Room?', 'What is the capacity of the National Diet Building?', 'Is #2 greater than or equal to #1?']\n","\n","__ evidence __\n","[[[['The Viper Room-1'], 'no_evidence'], [['National Diet Building-28']], ['operation']], [[['The Viper Room-1'], 'no_evidence'], [['National Diet Building-11'], 'no_evidence'], ['no_evidence', 'operation']], [['no_evidence'], [['National Diet Building-28']], [['National Diet Building-28'], 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can Viper Room concert hypothetically be held at National Diet building?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can Viper Room concert hypothetically be held at National Diet building?', 'result': 'True\\n\\nExplanation:\\nThe Viper Room is a music venue located in Los Angeles, California, and it is known for hosting various concerts and events. However, the National Diet building is a government building in Tokyo, Japan, and it is not a suitable location for a concert. Therefore, it is unlikely that the Viper Room concert could be held at the National Diet building.\\n\\nIn this example, the question is asking about the hypothetical location of a concert, and the answer is based on the information provided in the question. The question does not provide any facts about the Viper Room or the National Diet building, so the answer is simply based on the assumption that the Viper Room is a music venue and the National Diet building is a government building.'}\n","\n","__ gpt_run_time __\n","604.5200233459473\n","\n","__ llama_run_time __\n","20.719552040100098\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","b0ab236d19fec61c0111\n","\n","__ term __\n","Gorilla\n","\n","__ description __\n","Genus of mammals\n","\n","__ question __\n","Is it expected that Charla Nash would be anxious near a gorilla?\n","\n","__ facts __\n","['In 2009, Charla Nash was attacked and nearly killed by a chimpanzee. ', 'While a different species, Gorillas and Chimpanzees have similar physical appearances and are both primates.']\n","\n","__ decomposition __\n","['Which animal attacked Charla Nash in 2009?', 'Does #1 bear significant similarity to a gorilla?']\n","\n","__ evidence __\n","[[[['Travis (chimpanzee)-8']], ['operation']], [[['Travis (chimpanzee)-8']], [['Hominidae-1']]], [[['Travis (chimpanzee)-8']], [['Gorilla-1'], 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is it expected that Charla Nash would be anxious near a gorilla?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Is it expected that Charla Nash would be anxious near a gorilla?', 'result': 'True\\n\\nExplanation:\\nThe question is asking about the behavior of Charla Nash, a person who was attacked by a gorilla. The facts provided state that Charla Nash was attacked by a gorilla and suffered severe injuries. This information suggests that Charla Nash may have experienced anxiety or fear near gorillas after the attack, which is a reasonable conclusion to draw based on the information provided. Therefore, the answer is \"True\".'}\n","\n","__ gpt_run_time __\n","0.7167000770568848\n","\n","__ llama_run_time __\n","11.824898481369019\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","40b7c34188d5b36bc486\n","\n","__ term __\n","Lamborghini\n","\n","__ description __\n","Italian car manufacturer\n","\n","__ question __\n","Can Lamborghini's fastest model win a race against a Porsche 911?\n","\n","__ facts __\n","[\"Lamborghini's fastest model is the Lamborghini Aventador SVJ Roadster.\", 'The Lamborghini Aventador SVJ Roadster has a top speed of 217 MPH.', 'The Porsche 911 has a top speed of 191 MPH.']\n","\n","__ decomposition __\n","['Which model of Lamborghini is the fastest?', 'What is the top speed of #1?', 'What is the top speed of a Porsche 911?', 'Is #2 greater than #3?']\n","\n","__ evidence __\n","[[[['Lamborghini Veneno-1']], [['Lamborghini Veneno-7']], [['Porsche 911-133']], ['operation']], [[['Lamborghini Aventador-14'], 'no_evidence'], [['Lamborghini Aventador-14']], [['Porsche 911-129']], ['operation']], [[['Fastest Car-1']], [['Lamborghini Aventador-14']], [['Porsche 911-94']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Can Lamborghini's fastest model win a race against a Porsche 911?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"Can Lamborghini's fastest model win a race against a Porsche 911?\", 'result': \"True\\n\\nExplanation:\\nWe don't have all the facts, but we can estimate. The fastest Lamborghini model is the Lamborghini Aventador SVJ, with a top speed of 215 mph. The fastest Porsche 911 model is the Porsche 911 GT3, with a top speed of 197 mph. Based on these speeds, we can estimate that the Lamborghini Aventador SVJ would win a race against a Porsche 911 GT3.\\n\\nNote: The actual race would depend on various factors such as track conditions, driver skill, and other factors that could affect the outcome. This answer is based on estimated speeds and does not take into account any additional information that could affect the outcome of the race.\"}\n","\n","__ gpt_run_time __\n","0.5716149806976318\n","\n","__ llama_run_time __\n","21.044482707977295\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","0cb73f1ccb217757bddf\n","\n","__ term __\n","Steven Spielberg\n","\n","__ description __\n","American film director and screenwriter\n","\n","__ question __\n","Does Steven Spielberg's 1998 film take place in a period after War Horse setting?\n","\n","__ facts __\n","[\"Steven Spielberg's 1998 film, Saving Private Ryan, takes place during World War II.\", 'World War II took place from 1939-1945.', 'The 2011 movie War Horse takes place during World War I.', 'World War I took place from 1914-1918.']\n","\n","__ decomposition __\n","['What time period does War Horse take place in?', 'What years did #1 take place in?', \"What time period does Steven Spielberg's 1998 film take place in?\", 'When years did #3 take place in?', 'Did #4 happen after #2?']\n","\n","__ evidence __\n","[[[['War Horse (film)-2']], [['World War I-1']], [['Saving Private Ryan-1']], [['World War II-1']], ['operation']], [[['War Horse (film)-2']], [['World War I-1']], [['Saving Private Ryan-1']], [['World War II-1']], ['operation']], [[['War Horse (film)-2']], [['War Horse (film)-10', 'War Horse (film)-5']], [['Saving Private Ryan-1']], [['Saving Private Ryan-6']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Does Steven Spielberg's 1998 film take place in a period after War Horse setting?\", 'result': 'To answer this question, we need to determine the following:\\n1. What is the title of Steven Spielberg\\'s 1998 film?\\n2. When does War Horse take place?\\n3. Does Steven Spielberg\\'s 1998 film take place after the setting of War Horse?\\n\\nLet\\'s analyze the evidence provided:\\n- Evidence 1: [[\"Steven Spielberg\\'s 1998 film-1\"]], [[\"War Horse-1\"]], [\"operation\"]]\\nThis evidence suggests that there is a relationship between Steven Spielberg\\'s 1998 film and War Horse.\\n\\nBased on the evidence, we can conclude that Steven Spielberg\\'s 1998 film takes place after the setting of War Horse.\\n\\nAnswer: True'}\n","\n","__ llama_response __\n","{'query': \"Does Steven Spielberg's 1998 film take place in a period after War Horse setting?\", 'result': \"True\\n\\nExplanation:\\nFrom the facts provided, we can see that War Horse is a novel set in the early 20th century, and Disney produced a 1957 TV show featuring Zorro the spanish crime fighter. Therefore, it is unlikely that Steven Spielberg's 1998 film takes place in a period after War Horse setting.\\n\\nIn this case, we can skip steps 2-4 and give a direct answer based on the available facts.\"}\n","\n","__ gpt_run_time __\n","3.322772979736328\n","\n","__ llama_run_time __\n","14.383320093154907\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","347eff30928ba07fa567\n","\n","__ term __\n","Charlemagne\n","\n","__ description __\n","King of the Franks, King of Italy, and Holy Roman Emperor\n","\n","__ question __\n","Was Charlemagne's father instrumental in outcome of the Battle of Tours?\n","\n","__ facts __\n","[\"Charlemagne's father was Pepin the Short.\", \"Pepin the Short's father was Charles Martel.\", 'Charles Martel led an army against the Umayyads at the Battle of Tours.', 'Pepin the Short spent his early years being raised by monks.']\n","\n","__ decomposition __\n","[\"Who was Charlemagne's father?\", 'Was #1 involved in the Battle of Tours?']\n","\n","__ evidence __\n","[[[['Charlemagne-15']], [['Battle of Tours-1', 'Pepin the Short-1'], 'no_evidence', 'operation']], [[['Pepin the Short-5']], [['Battle of Tours-1']]], [[['Pepin the Short-5']], [['Battle of Tours-60']]]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Was Charlemagne's father instrumental in outcome of the Battle of Tours?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"Was Charlemagne's father instrumental in outcome of the Battle of Tours?\", 'result': 'True\\n\\nExplanation:\\nThis question is asking about a historical event, specifically the Battle of Tours, which took place in 734 AD. Charlemagne\\'s father, Pepin the Short, was a prominent figure in the Carolingian dynasty and played a significant role in the battle\\'s outcome.\\n\\nFacts:\\n\\n* Charlemagne\\'s father, Pepin the Short, was a powerful king who ruled over the Carolingian dynasty.\\n* The Battle of Tours was a major military conflict between the Frankish army led by Charles Martel and the Umayyad Caliphate.\\n* The battle was a significant turning point in the Carolingian dynasty\\'s rise to power.\\n* Pepin the Short\\'s leadership during the battle helped to secure a Frankish victory.\\n\\nDecomposition:\\n\\n* What was the significance of the Battle of Tours in the Carolingian dynasty\\'s rise to power?\\n* What role did Pepin the Short play in the Battle of Tours?\\n* How did Pepin the Short\\'s leadership during the battle contribute to the Frankish victory?\\n\\nEvidence:\\n\\n* [[\"Battle of Tours-1\"], [[\"Carolingian dynasty-1\"], [\"Pepin the Short-2\"]], [\"no_evidence\"], [\"operation\"]]\\n* [[\"Battle of Tours-1\"], [[\"Carolingian dynasty-1\"], [\"Pepin the Short-2\"]], [[\"no_evidence\"], [\"operation\"]], [\"no_evidence\", \"operation\"]]\\n* [[\"Battle of Tours-1\"], [[\"Carolingian dynasty-1\"], [\"Pepin the Short-2\"]], [[\"no_evidence\"], [\"operation\"]], [\"no_evidence\", \"operation\"]]\\n\\nAnswer: True\\n\\nExplanation:\\nThe evidence provided supports the answer \"True\". Pepin the Short\\'s leadership during the Battle of Tours helped to secure a Frankish victory, which was a significant turning point in the Carolingian dynasty\\'s rise to power.'}\n","\n","__ gpt_run_time __\n","0.40332937240600586\n","\n","__ llama_run_time __\n","49.752243518829346\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","1af3364389f69c57f600\n","\n","__ term __\n","Vice President of the United States\n","\n","__ description __\n","Second highest executive office in United States\n","\n","__ question __\n","Can Vice President of the United States kill with impunity?\n","\n","__ facts __\n","[' Vice President Aaron Burr fatally wounded Alexander Hamilton in a duel on July 11, 1804.', 'Aaron Burr continued his term as Vice President of the United States after killing Alexander Hamilton.', 'US stand-your-ground laws allow a person to defend themselves even to the point of applying lethal force.']\n","\n","__ decomposition __\n","[\"What was the outcome of Vice President Aaron Burr's duel in July, 1804?\", \"Did#1 lead to loss of his opponent's life and did he continue his term afterwards?\"]\n","\n","__ evidence __\n","[[[['Aaron Burr-1']], [['Aaron Burr-34', 'Aaron Burr-35'], 'operation']], [[['Burr–Hamilton duel-35']], [['Aaron Burr-35', 'Burr–Hamilton duel-35'], 'no_evidence']], [[['Aaron Burr-4']], [['Aaron Burr-35', 'Aaron Burr-4']]]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can Vice President of the United States kill with impunity?', 'result': 'To answer this question, we need to consider the role and powers of the Vice President of the United States. \\n\\nFirst, let\\'s determine if the Vice President has the authority to issue executive orders. Based on the provided evidence, there is no mention of the Vice President having the power to issue executive orders. Therefore, we can conclude that the Vice President does not have the authority to issue executive orders.\\n\\nNext, let\\'s consider if the Vice President has the power to kill with impunity. The question does not provide any specific context or explanation for what \"kill with impunity\" means. However, based on the general understanding of the role of the Vice President, it is unlikely that they have the power to kill with impunity. The Vice President\\'s role is primarily to support the President and fulfill their duties as outlined in the Constitution. Killing with impunity would likely be illegal and go against the principles of the U.S. legal system.\\n\\nBased on the above analysis, we can conclude that the answer to the question \"Can Vice President of the United States kill with impunity?\" is False.'}\n","\n","__ llama_response __\n","{'query': 'Can Vice President of the United States kill with impunity?', 'result': 'True\\n\\nExplanation:\\nThe question asks if the Vice President of the United States can kill with impunity, which implies that the Vice President has the ability to harm or kill someone without facing consequences. However, the facts provided do not support this claim.\\n\\nFirstly, the question asks if the Vice President can kill with impunity, but the facts provided state that the Vice President is a civilian position and does not have the authority to use deadly force or commit any violent act. The Vice President\\'s role is to support the President and assume the office of the President in case of the President\\'s death, resignation, or incapacitation.\\n\\nSecondly, the facts provided do not indicate that the Vice President has any special immunity or protection from the law. While the Vice President is a high-ranking government official, they are still subject to the laws and regulations of the United States.\\n\\nTherefore, based on the provided facts, the answer to the question is \"True\".\\n\\nNote: This answer is based on the information provided in the example and does not reflect the actual capabilities or actions of any real-life Vice President of the United States.'}\n","\n","__ gpt_run_time __\n","6.5633978843688965\n","\n","__ llama_run_time __\n","27.684763193130493\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","a98c29881e1929a25eb4\n","\n","__ term __\n","Giant squid\n","\n","__ description __\n","Deep-ocean dwelling squid in the family Architeuthidae\n","\n","__ question __\n","Could a giant squid fit aboard the deck of the titanic?\n","\n","__ facts __\n","['Decks on the Titanic were as long as 500ft.', 'Giant Squid grow to be around 59ft in length.']\n","\n","__ decomposition __\n","['What is the length of a giant squid?', 'What was the length of a deck on the Titanic?', 'Is #1 less than #2?']\n","\n","__ evidence __\n","[[[['Giant squid-1']], [['RMS Titanic-11']], ['operation']], [[['Giant squid-1']], [['First-class facilities of the RMS Titanic-12']], ['operation']], [[['Giant squid-1']], [['RMS Titanic-11']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Could a giant squid fit aboard the deck of the titanic?', 'result': '{\"qid\": \"e8e8e8e8e8e8e8e8e8e8\", \"term\": \"Giant squid\", \"description\": \"A deep-sea dwelling creature with a large body and tentacles\", \"question\": \"Could a giant squid fit aboard the deck of the titanic?\", \"facts\": [\"The titanic had a length of 882 feet and a width of 92 feet.\", \"Giant squids can grow up to 43 feet in length.\"], \"decomposition\": [\"What were the dimensions of the titanic?\", \"What is the maximum length of a giant squid?\", \"Is #2 less than or equal to #1?\"], \"evidence\": [[[[\"RMS Titanic-2\"]], [[\"Giant squid-2\"]], [\"operation\"]], [[[\"RMS Titanic-3\"]], [[\"Giant squid-2\"]], [\"operation\"]], [[[\"RMS Titanic-3\"]], [[\"Giant squid-2\"]], [\"operation\"]]], \"answer\": true}'}\n","\n","__ llama_response __\n","{'query': 'Could a giant squid fit aboard the deck of the titanic?', 'result': 'True\\n\\nExplanation:\\nThe titanic had a deck size of approximately 100,000 square feet. According to the National Oceanic and Atmospheric Administration, the largest giant squid on record measures 27 feet in length and 19 feet in width. Therefore, the giant squid could fit aboard the deck of the titanic.\\n\\nHowever, it is important to note that giant squids are not typically found in the North Atlantic Ocean, where the titanic sank. They are typically found in the deep waters of the Antarctic and sub-Antarctic regions.\\n\\nTherefore, the answer to the question is true, but with the caveat that the giant squid would not typically be found in the area where the titanic sank.'}\n","\n","__ gpt_run_time __\n","5.709213972091675\n","\n","__ llama_run_time __\n","19.24974751472473\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","660bfdc17b47f42facac\n","\n","__ term __\n","Moose\n","\n","__ description __\n","A genus of mammals belonging to the deer, muntjac, roe deer, reindeer, and moose family of ruminants\n","\n","__ question __\n","Are moose used for work near the kingdom of Arendelle?\n","\n","__ facts __\n","[\"The opening scene of Disney's Frozen shows a group of ice breakers.\", 'They have moose that carry the heavy ice blocks.', 'One of them, Kristoff, becomes separated with his moose Sven.', 'When Queen Elsa flees Arendelle and Princess Anna gives chase, she quickly encounters Kristoff.']\n","\n","__ decomposition __\n","['What show is the kingdom of Arendelle from?', 'In the opening scene of #1, what are a group of men doing?', 'Are moose used to carry #2?']\n","\n","__ evidence __\n","[[[['Arendelle: World of Frozen-1', 'Elsa (Frozen)-26'], 'no_evidence'], ['no_evidence'], ['no_evidence']], [[['Frozen (2013 film)-45']], [['Frozen (2013 film)-44'], 'no_evidence'], [['Moose-73'], 'operation']], [[['Frozen (2013 film)-6']], ['no_evidence'], [['Moose-9'], 'no_evidence', 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Are moose used for work near the kingdom of Arendelle?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Are moose used for work near the kingdom of Arendelle?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.6867904663085938\n","\n","__ llama_run_time __\n","5.038997650146484\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","f378f856bdaff39cdfa3\n","\n","__ term __\n","Cuisine of Hawaii\n","\n","__ description __\n","Cuisine of Hawaii\n","\n","__ question __\n","Is the cuisine of Hawaii suitable for a vegan?\n","\n","__ facts __\n","[' Per capita, Hawaiians are the second largest consumers of Spam in the world, right behind Guam.', 'Kalua pig is another famous cuisine of Hawaii.', 'Fish and seafood are also very common in Hawaii.']\n","\n","__ decomposition __\n","['What are the popular foods in Hawaiian cuisine?', 'Which foods will a vegan exclude from their diet?', 'Are all of #2 excluded from #1?']\n","\n","__ evidence __\n","[[[['Cuisine of Hawaii-2']], [['Veganism-1']], ['operation']], [[['Cuisine of Hawaii-26']], [['Veganism-1']], ['operation']], [[['Haitian cuisine-15'], 'no_evidence'], [['Vegetarian and vegan dog diet-2'], 'no_evidence'], ['no_evidence']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is the cuisine of Hawaii suitable for a vegan?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Is the cuisine of Hawaii suitable for a vegan?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.44443202018737793\n","\n","__ llama_run_time __\n","4.512661933898926\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","b7c2bfdfc96be70f3f60\n","\n","__ term __\n","The Powerpuff Girls\n","\n","__ description __\n","American animated television series\n","\n","__ question __\n","Can the Powerpuff Girls form a complete tag team wrestling match?\n","\n","__ facts __\n","['A tag team wrestling match is contested between at least two teams of at least two wrestlers each', 'There are only three people in the Powerpuff Girls']\n","\n","__ decomposition __\n","['What is the minimum number of people that can participate in a tag team match in professional wrestling?', 'The Powerpuff girls are how many in number?', 'Is #2 greater than or equal to #1?']\n","\n","__ evidence __\n","[[[['Tag team-7']], [['The Powerpuff Girls-1']], ['operation']], [[['Professional wrestling match types-4']], [['The Powerpuff Girls-1']], ['operation']], [[['Tag team-7']], [['The Powerpuff Girls-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can the Powerpuff Girls form a complete tag team wrestling match?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can the Powerpuff Girls form a complete tag team wrestling match?', 'result': 'True\\n\\nExplanation:\\nThe Powerpuff Girls are known for their superpowers and ability to fight crime and monsters in their city of Townsville. However, they have not been shown to have any significant wrestling skills or experience. While they may be able to hold their own against some opponents, they are unlikely to form a complete tag team wrestling match.\\n\\nFacts:\\nThe Powerpuff Girls have superpowers such as flight, super strength, and the ability to shoot energy blasts. They have fought against various monsters and villains in their city, but have not shown any particular skill in wrestling.\\n\\nDecomposition:\\nWhat are the Powerpuff Girls known for? What are their superpowers? Have they shown any wrestling skills?\\n\\nEvidence:\\n[[\"The Powerpuff Girls-1\", \"superpowers-1\", \"fighting crime-2\"], [\"The Powerpuff Girls-1\", \"superpowers-2\", \"energy blasts-3\"], [\"The Powerpuff Girls-1\", \"no_evidence\"], [\"The Powerpuff Girls-2\", \"no_evidence\"]]\\n\\nIn this example, the question is asking if the Powerpuff Girls can form a complete tag team wrestling match. The answer is true, based on the information provided in the facts. The decomposition and evidence are used to help demonstrate the reasoning behind the answer.'}\n","\n","__ gpt_run_time __\n","0.3175067901611328\n","\n","__ llama_run_time __\n","34.33977484703064\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","935002dcfa70239e715f\n","\n","__ term __\n","Firefighter\n","\n","__ description __\n","rescuer trained to extinguish hazardous fires\n","\n","__ question __\n","Would Firefighters be included in a September 11th memorial?\n","\n","__ facts __\n","['September 11th is remembered as a day of mourning for the lives lost during a terrorist attack in NYC.', 'Firefighters were among the first responders to the crisis, and many died. ']\n","\n","__ decomposition __\n","['Who gets remembered on September 11th?', 'Were firefighters among #1?']\n","\n","__ evidence __\n","[[[['9/11 Tribute Museum-1']], [['9/11 Tribute Museum-7'], 'operation']], [[['September 11 attacks-2']], ['operation']], [[['September 11 attacks-118', 'September 11 attacks-63']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would Firefighters be included in a September 11th memorial?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Would Firefighters be included in a September 11th memorial?', 'result': 'True\\n\\nExplanation:\\n\\nThe question asks if firefighters would be included in a September 11th memorial. To answer this question, we must first determine what the question is asking about. The question mentions September 11th, which suggests that the memorial is related to the events of that day. However, the question does not provide enough information to determine which specific event or events the memorial is referring to.\\n\\nTo find the answer, we can use the decomposition method by breaking down the question into smaller parts. The question asks if firefighters would be included in a September 11th memorial, which implies that the memorial is related to the events of September 11, 2001. However, we do not have enough information to determine if firefighters were directly involved in the events of that day.\\n\\nTherefore, we must use the evidence provided to help us find the answer. The evidence mentions that firefighters were involved in the rescue efforts at the World Trade Center on September 11, 2001. This suggests that firefighters may be included in a memorial related to the events of that day.\\n\\nBased on the available information, the answer to the question is true. Firefighters may be included in a September 11th memorial due to their involvement in the rescue efforts at the World Trade Center on that day.'}\n","\n","__ gpt_run_time __\n","0.36865234375\n","\n","__ llama_run_time __\n","31.51851224899292\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","4c088a5366459f2256c6\n","\n","__ term __\n","Mental disorder\n","\n","__ description __\n","Distressing thought or behavior pattern\n","\n","__ question __\n","Did Van Gogh suffer from a mental disorder?\n","\n","__ facts __\n","['Mental disorders can be characterized by psychotic episodes and delusions', 'Van Gogh suffered from psychotic episodes and delusions']\n","\n","__ decomposition __\n","['What are mental disorders characterized as?', 'What issues did Van Gogh suffer from?', 'Is #1 the same as #2?']\n","\n","__ evidence __\n","[[[['Mental disorder-40']], [['Vincent van Gogh-3']], ['operation']], [[['Mental disorder-1']], [['Vincent van Gogh-3']], ['operation']], [[['Causes of mental disorders-58'], 'operation'], [['Van Gogh syndrome-4'], 'no_evidence'], ['no_evidence']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did Van Gogh suffer from a mental disorder?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Did Van Gogh suffer from a mental disorder?', 'result': 'True\\n\\nExplanation:\\nVan Gogh is known to have suffered from depression, anxiety, and other mental health issues throughout his life. There are many accounts of his struggles with mental illness, including his own letters and the accounts of those who knew him. For example, his friend and fellow artist Paul Gauguin described Van Gogh as \"half-crazy\" and \"very excitable.\" Additionally, Van Gogh\\'s artwork often reflects his emotional state, with many paintings depicting scenes of melancholy and despair. Based on these accounts and the available evidence, it is likely that Van Gogh suffered from a mental disorder.'}\n","\n","__ gpt_run_time __\n","0.35988426208496094\n","\n","__ llama_run_time __\n","18.715537548065186\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","3ac14678dd395d41639c\n","\n","__ term __\n","Eleventh grade\n","\n","__ description __\n","educational year\n","\n","__ question __\n","Would an eleventh-grader be eligible for Medicare?\n","\n","__ facts __\n","['Students in the 11th grade are typically between 16-17 years old.', 'The age requirement for most Medicare recipients is 65 or older.']\n","\n","__ decomposition __\n","['What ages are people in eleventh grade?', 'What ages are most medicare recipients?', 'Is there an overlap between #1 and #2?']\n","\n","__ evidence __\n","[[[['Eleventh grade-1']], [['Medicare (United States)-1']], ['operation']], [[['Eleventh grade-1'], 'operation'], [['Medicare Advantage-26'], 'operation'], ['no_evidence']], [[['Eleventh grade-1']], [['Medicare (United States)-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would an eleventh-grader be eligible for Medicare?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Would an eleventh-grader be eligible for Medicare?', 'result': \"True\\n\\nExplanation:\\nEleventh grade is an educational year in high school (Fact #1). Many high schools offer driver's education classes (Fact #2). Drivers education classes can be taken outside of high school by other organizations (Fact #3). One must pass a driving test to obtain a driver's license (Fact #4).\\n\\nSince eleventh graders are in high school, they meet the first criterion for obtaining a driver's license (Fact #5). Therefore, an eleventh-grader would be eligible for Medicare.\"}\n","\n","__ gpt_run_time __\n","0.5359666347503662\n","\n","__ llama_run_time __\n","16.107826232910156\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","6a01b523e0140f21c426\n","\n","__ term __\n","Mediterranean Sea\n","\n","__ description __\n","Sea connected to the Atlantic Ocean between Europe, Africa and Asia\n","\n","__ question __\n","Did a Mediterranean Sea creature kill Steve Irwin?\n","\n","__ facts __\n","['Steve Irwin was killed by a Stingray animal.', 'Batoids are sea ray animals that live in the Mediterranean Sea.', 'Batoids and stingrays are related by sharing a scientific class of Chondrichthyes.']\n","\n","__ decomposition __\n","['Which animal killed Steve Irwin?', 'Is #1 a sea creature']\n","\n","__ evidence __\n","[[[['Steve Irwin-35']], [['Stingray-2']]], [[['Steve Irwin-35']], [['Broad stingray-4', 'Great Barrier Reef-7']]], [[['Steve Irwin-35']], [['Stingray-1']]]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did a Mediterranean Sea creature kill Steve Irwin?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Did a Mediterranean Sea creature kill Steve Irwin?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.2974381446838379\n","\n","__ llama_run_time __\n","5.0634849071502686\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","4ab77024b00c43ab7445\n","\n","__ term __\n","Thesis\n","\n","__ description __\n","document submitted in support of candidature for an academic degree\n","\n","__ question __\n","Could R. Kelly write a college thesis?\n","\n","__ facts __\n","['A college thesis is a long and complicated written document.', 'R. Kelly claims to be illiterate, which means he cannot read and write. ']\n","\n","__ decomposition __\n","['What does writing a college thesis require a person be able to do?', 'What does R. Kelly claim to be?', 'Can someone who is #2 do #1?']\n","\n","__ evidence __\n","[[[['Reading-1']], [['R. Kelly-9']], [['Dyslexia-20']]], [[['Thesis-1'], 'no_evidence'], ['no_evidence'], ['no_evidence', 'operation']], [[['Thesis-1'], 'no_evidence'], [['R. Kelly-9']], [['Dyslexia-1'], 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Could R. Kelly write a college thesis?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Could R. Kelly write a college thesis?', 'result': 'True\\n\\nExplanation:\\nR. Kelly is a singer, songwriter, and producer, not a college student or a scholar. He has not attended or written a thesis for any college or university. Therefore, the answer is True.\\n\\nNote: The decomposition and evidence are not relevant to this question as it is a factual question that requires a simple Yes or No answer.'}\n","\n","__ gpt_run_time __\n","0.2843940258026123\n","\n","__ llama_run_time __\n","12.465633153915405\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","b3443bf3c312c9d144e4\n","\n","__ term __\n","Panthéon\n","\n","__ description __\n","mausoleum in Paris\n","\n","__ question __\n","Is there a full Neptunian orbit between the first two burials of women in the Panthéon?\n","\n","__ facts __\n","['In 1907, Sophie Berthelot is the first woman to be interred in the Panthéon ', 'In 1995, Marie Curie is the second woman to be interred there', 'Neptune takes 165 years to go around the sun']\n","\n","__ decomposition __\n","['In what year was the first woman buried in the Panthéon?', 'In what year was the second woman buried in the Panthéon?', 'How many years are between #1 and #2?', 'How many years does it take for Neptune to orbit the Sun?', 'Is #4 less than or equal to #3?']\n","\n","__ evidence __\n","[[[['Panthéon-34']], [['Panthéon-34']], ['operation'], [['Neptune-1']], ['operation']], [[['Panthéon-34']], [['Panthéon-34']], ['operation'], [['Neptune-1']], ['operation']], [[['Panthéon-34']], [['Panthéon-34']], ['operation'], [['Neptune-1']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is there a full Neptunian orbit between the first two burials of women in the Panthéon?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Is there a full Neptunian orbit between the first two burials of women in the Panthéon?', 'result': 'True\\n\\nExplanation:\\nWe are given two facts:\\n\\n1. The first woman buried in the Panthéon was Marie Curie in 1994.\\n2. The second woman buried in the Panthéon was Simone Veil in 2018.\\n\\nWe are asked if there is a full Neptunian orbit between these two burials. To determine this, we need to find out how long it takes for Neptune to orbit the Sun 16 times (which is the number of years between Marie Curie\\'s burial and Simone Veil\\'s burial).\\n\\nUsing the orbital period of Neptune (which is about 16.1 Earth years), we can calculate that it takes Neptune about 161 years to make one full orbit around the Sun. This means that there is not a full Neptunian orbit between the two burials, as it would take Neptune more than 161 years to make one orbit around the Sun. Therefore, the answer is True.\\n\\nNote: The term \"Neptunian orbit\" refers to the orbit of the planet Neptune around the Sun.'}\n","\n","__ gpt_run_time __\n","0.3160834312438965\n","\n","__ llama_run_time __\n","29.147629261016846\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","ed08e2d4bbe5bbf1b01d\n","\n","__ term __\n","Oprah Winfrey\n","\n","__ description __\n","American businesswoman, talk show host, actress, producer, and philanthropist\n","\n","__ question __\n","Could Oprah Winfrey buy dozens of her staff Bugatti luxury cars?\n","\n","__ facts __\n","['Oprah Winfrey is a billionaire', 'A new Bugatti costs a few million dollars']\n","\n","__ decomposition __\n","['How much is Oprah Winfrey worth?', 'How much does a  Bugatti cost?', 'Is #2 times 2 dozen less than #1?']\n","\n","__ evidence __\n","[[[['Oprah Winfrey-54']], [['Bugatti Chiron-8']], ['operation']], [[['Oprah Winfrey-54']], [['Bugatti Chiron-8']], ['operation']], [[['Oprah Winfrey-54']], [['Bugatti Chiron-8']], ['operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Could Oprah Winfrey buy dozens of her staff Bugatti luxury cars?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Could Oprah Winfrey buy dozens of her staff Bugatti luxury cars?', 'result': 'True\\n\\nExplanation:\\nOprah Winfrey is a media executive, actress, talk show host, and philanthropist. She has a net worth of over $3 billion, making her one of the wealthiest women in the world. While she may not be able to afford dozens of Bugatti luxury cars, she is certainly able to afford a few.\\n\\nFacts:\\n\\n* Oprah Winfrey has a net worth of over $3 billion.\\n* Bugatti is a luxury car brand known for its high-performance and high-priced vehicles.\\n\\nDecomposition:\\n\\n* Could Oprah Winfrey afford Bugatti luxury cars?\\n* Is Oprah Winfrey wealthy enough to afford dozens of Bugatti luxury cars?\\n\\nEvidence:\\n\\n* [[\"Oprah Winfrey-1\"], [[\"Bugatti-1\"]], [\"operation\"]]\\n\\nNote: The evidence provided is a simple statement that Oprah Winfrey is wealthy enough to afford Bugatti luxury cars.'}\n","\n","__ gpt_run_time __\n","0.5502033233642578\n","\n","__ llama_run_time __\n","27.981367826461792\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","9cfdec34fa9bd1ed9d3f\n","\n","__ term __\n","J. P. Morgan\n","\n","__ description __\n","American financier, banker, philanthropist and art collector\n","\n","__ question __\n","Did J. P. Morgan have healthy lungs?\n","\n","__ facts __\n","['J. P. Morgan smoked dozens of cigars per day.', 'Smoking tobacco damages the lungs and increases the risk of lung cancer significantly.']\n","\n","__ decomposition __\n","['What are the causes of unhealthy lungs?', 'Did J. P. Morgan engage in any part of #1?']\n","\n","__ evidence __\n","[[[['Lung-3']], [['J. P. Morgan-29']]], [[['Smoking-5']], ['operation']], [[['Rheumatoid lung disease-6']], [['J. P. Morgan-4'], 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Did J. P. Morgan have healthy lungs?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Did J. P. Morgan have healthy lungs?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.5488381385803223\n","\n","__ llama_run_time __\n","4.444572925567627\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","3e023027bb296245506a\n","\n","__ term __\n","McDonald's\n","\n","__ description __\n","American fast food restaurant chain\n","\n","__ question __\n","If you were on a diet, would you have to skip lunch at McDonald's?\n","\n","__ facts __\n","[\"McDonald's offers low calorie brunch options like parfaits and egg white sandwiches. \", \"McDonald's offers low calorie lunch options including basic hamburgers and salads.\"]\n","\n","__ decomposition __\n","['What is characteristic of food eaten by someone on a diet?', \"Are lunch options characterized by #1 unavailable at McDonald's?\"]\n","\n","__ evidence __\n","[[[['Dieting-1']], [[\"McDonald's-2\"], 'operation']], [[['Healthy diet-2']], [[\"McDonald's-2\"]]], [[['Dieting-21'], 'no_evidence'], [[\"McDonald's-2\"], 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"If you were on a diet, would you have to skip lunch at McDonald's?\", 'result': \"To answer this question, we need to consider whether McDonald's offers any options that would fit within a diet. We also need to determine if skipping lunch altogether is necessary.\\n\\nFirst, let's consider the facts. McDonald's is a fast-food restaurant known for its high-calorie and unhealthy menu options. However, they do offer some healthier choices such as salads, grilled chicken sandwiches, and fruit options. So, it is possible to find options that could fit within a diet.\\n\\nNext, let's think about whether skipping lunch is necessary. It depends on the specific diet and its guidelines. Some diets may allow for a certain number of calories or specific types of food at each meal, while others may recommend intermittent fasting or skipping certain meals altogether.\\n\\nBased on the information provided, we don't have enough specific details about the diet in question. However, it is possible to find options at McDonald's that could fit within a diet, so it is not necessarily required to skip lunch there.\\n\\nTherefore, the answer is False.\"}\n","\n","__ llama_response __\n","{'query': \"If you were on a diet, would you have to skip lunch at McDonald's?\", 'result': 'True'}\n","\n","__ gpt_run_time __\n","4.715925455093384\n","\n","__ llama_run_time __\n","6.521083354949951\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","83717baab39233083d34\n","\n","__ term __\n","Spirit (rover)\n","\n","__ description __\n","NASA Mars rover\n","\n","__ question __\n","Would a broadcast from Spirit make the news in 2020?\n","\n","__ facts __\n","['In 2010, the Spirit rover sent what is recorded as its final transmission.', 'In 2019, another rover made the news with its viral \"final words\"']\n","\n","__ decomposition __\n","[\"When did the martian rover 'Spirit' send its last transmission?\", \"Which rover sent another 'final message' in 2019?\", 'Is #1 before 2020 and did #2 make the news?']\n","\n","__ evidence __\n","[[[['Spirit (rover)-1']], [['Opportunity (rover)-1', 'Opportunity (rover)-15'], 'no_evidence'], ['no_evidence', 'operation']], [[['Spirit (rover)-1']], [['Opportunity (rover)-1']], [['Opportunity (rover)-1', 'Spirit (rover)-1'], 'operation']], [[['Mars Exploration Rover-5']], [['Opportunity (rover)-15']], [['Opportunity (rover)-16'], 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would a broadcast from Spirit make the news in 2020?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Would a broadcast from Spirit make the news in 2020?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","1.5741207599639893\n","\n","__ llama_run_time __\n","6.710076570510864\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","4ba70839df733c61f9a5\n","\n","__ term __\n","Zika virus\n","\n","__ description __\n","Species of virus\n","\n","__ question __\n","Do you need to worry about Zika virus in Antarctica? \n","\n","__ facts __\n","['Mosquitoes cannot survive in the climate of Antarctica.', 'Zika virus is primarily spread through mosquito bites. ']\n","\n","__ decomposition __\n","['What animal spreads the Zika Virus?', 'What is the climate of Antarctica?', 'Can #1 survive in #2?']\n","\n","__ evidence __\n","[[[['Zika virus-10']], [['Antarctica-42']], [['Antarctica-42', 'Mosquito-68'], 'operation']], [[['Zika fever-2']], [['Antarctica-42']], [['Mosquito-61'], 'operation']], [[['Aedes-1', 'Zika fever-2']], [['Antarctica-2']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Do you need to worry about Zika virus in Antarctica? ', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Do you need to worry about Zika virus in Antarctica? ', 'result': 'True\\n\\nExplanation:\\nZika virus is primarily transmitted through the bite of an infected Aedes mosquito. Since Antarctica is a frozen continent with no standing water or vegetation, there are no mosquitoes to transmit the virus. Therefore, there is no need to worry about Zika virus in Antarctica.'}\n","\n","__ gpt_run_time __\n","0.5781450271606445\n","\n","__ llama_run_time __\n","12.2020103931427\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","d05b8ed82dbe1583b16c\n","\n","__ term __\n","Parent\n","\n","__ description __\n","father or mother\n","\n","__ question __\n","Does a person need to be a parent to become a grandparent?\n","\n","__ facts __\n","['Parents care for their children.', 'When the children grow up and have kids of their own, the parents become grandparents to those kids.', 'A person who is not a parent has no kids, therefore nobody to produce grandchildren for them.']\n","\n","__ decomposition __\n","['What must a person have in order to be known as a grandparent?', 'What would the parents of #1 be to the person?', 'Must one be a parent to have #2?']\n","\n","__ evidence __\n","[[[['Grandparent-1']], [['Grandparent-1']], [['Grandparent-1']]], [[['Parent-7'], 'no_evidence'], [['Parent-1']], ['operation']], [[['Grandparent-1']], [['Child-2']], [['Parent-1'], 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Does a person need to be a parent to become a grandparent?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Does a person need to be a parent to become a grandparent?', 'result': \"True\\n\\nExplanation:\\nThe question is asking if a person needs to be a parent to become a grandparent. The answer is true because a person does not need to be a parent to become a grandparent. A person can become a grandparent through their children's children. For example, if a person has two children, and those children have children of their own, then the person is a grandparent. Therefore, the answer is true.\"}\n","\n","__ gpt_run_time __\n","0.7748937606811523\n","\n","__ llama_run_time __\n","13.898239850997925\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","44c59a3ac10f2921a009\n","\n","__ term __\n","Rick and Morty\n","\n","__ description __\n","Animated sitcom\n","\n","__ question __\n","Is Rick and Morty considered an anime?\n","\n","__ facts __\n","['Anime is a genre of animation that is hand drawn and is of Japanese origin.', 'Rick and Morty is an American animated show.']\n","\n","__ decomposition __\n","['What country does anime come from?', 'Rick and Morty is an animated show from which country?', 'Do #1 and #2 have the same answer?']\n","\n","__ evidence __\n","[[[['Anime-1']], [['Rick and Morty-1']], ['operation']], [[['Anime-1']], [['Rick and Morty-1']], ['operation']], [[['Anime-10']], [['Rick and Morty-18']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is Rick and Morty considered an anime?', 'result': '{\"qid\": \"f6cc5e1c7456dd41a094\", \"term\": \"Rick and Morty\", \"description\": \"Animated television series\", \"question\": \"Is Rick and Morty considered an anime?\", \"facts\": [\"Rick and Morty is an American animated television series.\", \"Anime refers to a style of animation that originated in Japan.\"], \"decomposition\": [\"What is the origin of anime?\", \"What is the origin of Rick and Morty?\", \"Are #1 and #2 the same?\"], \"evidence\": [[[[\"Anime-1\"]], [[\"Rick and Morty-1\"]], [\"operation\"]], [[[\"Anime-1\"]], [[\"Rick and Morty-1\"]], [\"operation\"]], [[[\"Anime-1\"]], [[\"Rick and Morty-1\"]], [\"operation\"]]], \"answer\": false}'}\n","\n","__ llama_response __\n","{'query': 'Is Rick and Morty considered an anime?', 'result': 'True\\n\\nExplanation:\\nRick and Morty is an animated television series, but it is not considered an anime. Anime is a style of Japanese animation, typically characterized by colorful, stylized graphics, vibrant characters, and complex storylines. While Rick and Morty has a similar style to anime, it is not produced in Japan and does not conform to the traditional definition of anime. Therefore, the answer is True.'}\n","\n","__ gpt_run_time __\n","4.745347261428833\n","\n","__ llama_run_time __\n","15.486865520477295\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","cc233b6426cb4e8dffb6\n","\n","__ term __\n","James Bond\n","\n","__ description __\n","Media franchise about a British spy\n","\n","__ question __\n","Was the original James Bond actor born near the Washington Monument?\n","\n","__ facts __\n","['The original James Bond actor was Sean Connery.', 'Sean Connery was born in Scotland.', 'The Washington Monument is located in Washington, D.C.', 'Washington, D.C. and Scotland are nearly 3,500 miles apart.']\n","\n","__ decomposition __\n","['Who originally played James Bond?', 'Where was #1 born?', 'Where is the Washington Monument located?', 'What is the distance between #2 and #3?', 'Is #4 a short enough of a distance to be considered \"close\"?']\n","\n","__ evidence __\n","[[[['Portrayal of James Bond in film-3']], [['Barry Nelson-2']], [['Washington Monument-1']], ['no_evidence'], ['no_evidence']], [[['Portrayal of James Bond in film-8']], [['Sean Connery-4']], [['Washington Monument-1']], ['no_evidence'], ['no_evidence']], [[['James Bond-28']], [['Sean Connery-4']], [['Washington Monument-1']], [['Atlantic Ocean-1'], 'no_evidence'], ['no_evidence', 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Was the original James Bond actor born near the Washington Monument?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Was the original James Bond actor born near the Washington Monument?', 'result': 'True\\n\\nExplanation:\\nThe question is asking about the birthplace of Sean Connery, the original James Bond actor. According to the facts provided, Sean Connery was born in Edinburgh, Scotland. The Washington Monument is located in Washington D.C., which is in the United States. Therefore, the answer is true.'}\n","\n","__ gpt_run_time __\n","0.5137968063354492\n","\n","__ llama_run_time __\n","12.65308690071106\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","03caedef50bc6729e9e5\n","\n","__ term __\n","Railroad engineer\n","\n","__ description __\n","person who operates a train on a railroad or railway\n","\n","__ question __\n","Can you find a railroad engineer on TNT?\n","\n","__ facts __\n","['TNT is a cable television network', 'Snowpiercer is a show airing on the TNT network', 'Snowpiercer involves people living on an active train in a postapocalyptic future', 'A railroad engineer is necessary to keep a train running']\n","\n","__ decomposition __\n","['What movies are about trains or railroads?', 'Are any of #1 currently airing on TNT?']\n","\n","__ evidence __\n","[[[['Murder on the Orient Express (2017 film)-1'], 'no_evidence'], ['no_evidence', 'operation']], [[['Snowpiercer-1', 'Snowpiercer-46'], 'no_evidence'], [['Snowpiercer-46'], 'operation']], [[['Planes, Trains and Automobiles-1']], ['no_evidence']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can you find a railroad engineer on TNT?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can you find a railroad engineer on TNT?', 'result': 'True\\n\\nExplanation:\\nThe question asks if a railroad engineer can be found on TNT. TNT is a television network that airs shows such as Family Guy, Teenage Mutant Ninja Turtles, and Daredevil. Radioactive waste is a plot device in many of these shows. James Watson, an American molecular biologist, geneticist, and zoologist, studied the double helix with Francis Crick. Francis Crick passed away in 2004 at 88 years of age, and James Watson is still alive at 92 years old. Therefore, the answer to the question is true.'}\n","\n","__ gpt_run_time __\n","0.2736499309539795\n","\n","__ llama_run_time __\n","19.04572582244873\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","31a82f72b96dd956c6cf\n","\n","__ term __\n","Paratrooper\n","\n","__ description __\n","Military parachutists functioning as part of an airborne force\n","\n","__ question __\n","Can paratroopers be used in a vacuum?\n","\n","__ facts __\n","['Paratroopers use parachutes to glide', 'Parachutes function by creating drag in an atmosphere', 'There is no atmosphere in a vacuum']\n","\n","__ decomposition __\n","['What equipment do paratroopers use?', 'What does #1 need to create in order to function?', 'In what does #1 create #2?', 'Is #3 present in a vacuum?']\n","\n","__ evidence __\n","[[[['Paratrooper-1']], [['Parachute-1']], [['Drag (physics)-1']], [['Vacuum-1'], 'operation']], [[['Parachuting-1', 'Paratrooper-1']], [['Drag (physics)-1']], [['Atmosphere of Earth-1'], 'no_evidence'], [['Vacuum-1'], 'operation']], [[['Paratrooper-1']], [['Parachute-1']], [['Parasitic drag-3']], [['Vacuum-16']]]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can paratroopers be used in a vacuum?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can paratroopers be used in a vacuum?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.5793240070343018\n","\n","__ llama_run_time __\n","5.241016149520874\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","bcc0ba30a471776d64a9\n","\n","__ term __\n","Snoop Dogg\n","\n","__ description __\n","American rapper\n","\n","__ question __\n","Was Snoop Dogg's debut studio album released on the weekend?\n","\n","__ facts __\n","[\"Snoop Dogg's debut studio album was Doggystyle.\", 'Doggystyle was released on November 23, 1993.', 'November 23, 1993 was a Tuesday.', 'In the USA, the weekend consists of Saturday and Sunday.']\n","\n","__ decomposition __\n","[\"What was Snoop Dogg's first studio album?\", 'When was #1 released?', 'What day of the week did #2 occur on?', 'What days are considered the weekend?', 'Is #3 one of the answers in #4?']\n","\n","__ evidence __\n","[[[['Snoop Dogg-2']], [['Doggystyle-1']], ['no_evidence'], [['Workweek and weekend-1']], ['operation']], [[['Doggystyle-1']], [['Doggystyle-1']], ['no_evidence'], [['Workweek and weekend-1']], ['no_evidence', 'operation']], [[['Snoop Dogg-2']], [['Doggystyle-1']], ['no_evidence'], [['Workweek and weekend-1']], ['no_evidence', 'operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Was Snoop Dogg's debut studio album released on the weekend?\", 'result': \"To answer this question, we need to determine if Snoop Dogg's debut studio album was released on the weekend. \\n\\nFirst, we need to find out the name of Snoop Dogg's debut studio album. \\n\\nNext, we need to find out the release date of the album and check if it falls on a weekend. \\n\\nIf we don't have the exact release date, we can estimate or skip this step. \\n\\nFinally, based on the information we have, we can give a true or false answer. \\n\\nSince we don't have the necessary facts or evidence to determine the release date of Snoop Dogg's debut studio album, we cannot give a true or false answer.\"}\n","\n","__ llama_response __\n","{'query': \"Was Snoop Dogg's debut studio album released on the weekend?\", 'result': 'True\\n\\nExplanation:\\nSnoop Dogg\\'s debut studio album, \"Doggystyle\", was released on November 23, 1993. The weekend in question is Saturday and Sunday. Therefore, the answer is True.'}\n","\n","__ gpt_run_time __\n","3.562793731689453\n","\n","__ llama_run_time __\n","10.895381927490234\n","\n","__ gpt_one_word_answer __\n","Other\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","6274bd508f7fbca9332f\n","\n","__ term __\n","Fever\n","\n","__ description __\n","common medical sign characterized by elevated body temperature\n","\n","__ question __\n","Can you get a fever from consuming meat?\n","\n","__ facts __\n","['A fever is a medical symptom that elevates the core body temperature. ', 'Eating under cooked meat can cause food poisoning.', 'One of the symptoms of food poisoning is elevated core body temperature. ']\n","\n","__ decomposition __\n","['What is a fever?', 'What can consuming uncooked meat cause?', 'Is #1 a symptom of #2?']\n","\n","__ evidence __\n","[[[['Fever-1']], [['Raw meat-4']], [['Fever-1']]], [[['Fever-1']], [['Trichinosis-1', 'Trichinosis-2'], 'no_evidence'], ['no_evidence', 'operation']], [[['Fever-1']], [['Raw meat-4']], [['Listeria-14'], 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can you get a fever from consuming meat?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can you get a fever from consuming meat?', 'result': 'True\\n\\nExplanation:\\nThe question asks if consuming meat can cause a fever. The answer is true because the fact \"Meat can carry bacteria and viruses\" implies that consuming meat can lead to illness, which can cause a fever. Therefore, the answer is true.\\n\\nNote: The decomposition process is not necessary in this case as the answer can be determined directly from the facts.'}\n","\n","__ gpt_run_time __\n","0.5099005699157715\n","\n","__ llama_run_time __\n","14.382038831710815\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","29842ce280ccd460dd7e\n","\n","__ term __\n","Bern\n","\n","__ description __\n","Place in Switzerland\n","\n","__ question __\n","Is Bern located east of Paris?\n","\n","__ facts __\n","['Paris is located in France.', 'Bern is located in Switzerland.', 'Switzerland borders France to the east.']\n","\n","__ decomposition __\n","['What country is Paris located in?', 'What country is Bern located in?', 'Is #2 located east of #1?']\n","\n","__ evidence __\n","[[[['Administration of Paris-4']], [['Districts of Switzerland-10']], [['France-1']]], [[['Paris-1']], [['Bern-1']], ['operation']], [[['Paris-1']], [['Bern-1']], [['Switzerland-1']]]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Is Bern located east of Paris?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Is Bern located east of Paris?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.5492763519287109\n","\n","__ llama_run_time __\n","5.773768424987793\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","f815aaa22d608f1dcb84\n","\n","__ term __\n","Eminem\n","\n","__ description __\n","American rapper and actor\n","\n","__ question __\n","Would Eminem perform well at the International Mathematical Olympiad?\n","\n","__ facts __\n","['Eminem dropped out of Lincoln High School at age 17 and disliked math and social studies.', 'Mathematics competitions or mathematical olympiads are competitive events where participants sit a mathematics test.', 'The content on the International Mathematical Olympiad ranges from extremely difficult algebra and pre-calculus problems to problems on branches of mathematics not conventionally covered at school and often not at university level either.']\n","\n","__ decomposition __\n","['What levels of mathematics are covered in the International Mathematical Olympiad?', 'What levels of mathematics is Eminem competent in?', 'Does #2 meet the minimum level in #1?']\n","\n","__ evidence __\n","[[[['International Mathematical Olympiad-2']], [['Eminem-8']], [['Eminem-8', 'International Mathematical Olympiad-2']]], [[['International Mathematical Olympiad-2']], [['Eminem-8']], [['Eminem-8']]], [[['International Mathematical Olympiad-1', 'International Mathematical Olympiad-2']], [['Eminem-8']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would Eminem perform well at the International Mathematical Olympiad?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Would Eminem perform well at the International Mathematical Olympiad?', 'result': 'True\\n\\nExplanation:\\nTo determine if Eminem would perform well at the International Mathematical Olympiad, we need to consider his background and skills. Eminem comes from a poor, uneducated background, and he did not excel in school. He dropped out of high school at the age of 15 and began his career as a rapper. Therefore, it is unlikely that he would perform well at the International Mathematical Olympiad, which requires a strong foundation in mathematics and problem-solving skills.\\n\\nHowever, we must also consider the fact that Eminem is a creative person who can think outside the box and come up with innovative solutions. While he may not have the traditional credentials to excel in mathematics, he has shown time and time again that he can think creatively and come up with unique ideas. Therefore, while it is unlikely that Eminem would perform well at the International Mathematical Olympiad in the classical sense, he may still be able to contribute to the field in his own unique way.\\n\\nIn conclusion, while Eminem may not have the traditional qualifications to excel at the International Mathematical Olympiad, his creativity and unconventional thinking could potentially be an asset in certain areas of mathematics. Therefore, the answer is True.'}\n","\n","__ gpt_run_time __\n","0.3928401470184326\n","\n","__ llama_run_time __\n","31.29681158065796\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","68684152725123d32f4b\n","\n","__ term __\n","Haiku\n","\n","__ description __\n","very short form of Japanese poetry\n","\n","__ question __\n","Are most books written as a Haiku?\n","\n","__ facts __\n","['Haiku is a very short poem', 'Haiku is written with 3 short phrases.']\n","\n","__ decomposition __\n","['What is the format of a haiku?', 'Are chapter books written like #1?']\n","\n","__ evidence __\n","[[[['Haiku-2']], ['operation']], [[['Haiku-2']], [['Chapter book-1']]], [[['Haiku-2']], ['no_evidence']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Are most books written as a Haiku?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Are most books written as a Haiku?', 'result': 'True\\n\\nExplanation:\\nThe question asks if most books are written as a Haiku, which is a type of poem. However, the factual information provided in the question does not support this claim. The question mentions that the center of a papaya contains a cluster of seeds, which is not related to the topic of books or Haiku poetry. Therefore, the answer is True.\\n\\nNote: The decomposition and evidence sections are not provided in this example, but they are important components of the desirable thought process. The decomposition section helps to break down the question into smaller parts, while the evidence section provides additional information that can help to support the answer.'}\n","\n","__ gpt_run_time __\n","0.5289168357849121\n","\n","__ llama_run_time __\n","17.26971435546875\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","8fe1b7912f41e5653e88\n","\n","__ term __\n","Tonsure\n","\n","__ description __\n","hairstyle related to religious devotion\n","\n","__ question __\n","Would Christopher Hitchens be very unlikely to engage in tonsure?\n","\n","__ facts __\n","['Tonsure is the practice of cutting or shaving some or all of the hair on the scalp as a sign of religious devotion or humility.', 'Christopher Hitchens was an anti-theist, and he regarded all religions as false, harmful, and authoritarian.']\n","\n","__ decomposition __\n","[\"What were Christopher Hitchens' views on religion?\", 'What is the purpose of tonsure?', 'Would a proponent of #1 have a negative opinion of #2?']\n","\n","__ evidence __\n","[[[['Christopher Hitchens-2']], [['Tonsure-1']], ['operation']], [[['Christopher Hitchens-2']], [['Tonsure-1']], ['operation']], [[['Christopher Hitchens-32']], [['Tonsure-5']], [['Christopher Hitchens-33']]]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would Christopher Hitchens be very unlikely to engage in tonsure?', 'result': \"To answer this question, we need to understand who Christopher Hitchens is and what tonsure is. \\n\\nChristopher Hitchens was a British-American author, journalist, and public intellectual known for his criticism of religion and support for atheism. Tonsure, on the other hand, is a practice in some religious traditions where a person's hair is partially or completely shaved off.\\n\\nBased on the information provided, there is no direct evidence or mention of Christopher Hitchens and tonsure. Therefore, we cannot definitively say whether he would be likely or unlikely to engage in tonsure. \\n\\nAnswer: False\"}\n","\n","__ llama_response __\n","{'query': 'Would Christopher Hitchens be very unlikely to engage in tonsure?', 'result': \"true\\n\\nExplanation:\\nChristopher Hitchens was a British-American author, journalist, and public intellectual. He was known for his outspoken and controversial views on religion, politics, and culture. Tonsure is the practice of shaving or cutting the hair on the top of the head, usually as a form of punishment or humiliation. Given Hitchens' outspoken and controversial nature, it is unlikely that he would engage in such a humiliating practice.\\n\\nHowever, it is important to note that this answer is based on the information provided in the factual statement. If additional information were provided that contradicts the answer, it would be necessary to reconsider the answer.\"}\n","\n","__ gpt_run_time __\n","3.329756021499634\n","\n","__ llama_run_time __\n","19.33024001121521\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","False\n","\n","__ is_gpt_correct __\n","False\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","00f951d01196c2e77fe6\n","\n","__ term __\n","Presidency of Richard Nixon\n","\n","__ description __\n","American cabinet\n","\n","__ question __\n","Would the high school class of 2010 have lived through the Presidency of Richard Nixon?\n","\n","__ facts __\n","['People in the high school class of 2010 were born between 1991 and 1993.', 'Richard Nixon was President of the United States until 1974.']\n","\n","__ decomposition __\n","['When was Richard Nixon president of the US until?', 'What year range would the high school class of 2010 be born in?', 'Is #1 in #2?']\n","\n","__ evidence __\n","[[[['Richard Nixon-1']], [['Secondary education in the United States-36'], 'no_evidence'], ['operation']], [[['Richard Nixon-1']], [['Secondary education-1'], 'no_evidence'], ['operation']], [[['Richard Nixon-46']], ['no_evidence'], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would the high school class of 2010 have lived through the Presidency of Richard Nixon?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Would the high school class of 2010 have lived through the Presidency of Richard Nixon?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","604.5153770446777\n","\n","__ llama_run_time __\n","4.874683856964111\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","a0eb7bcaa09e2ede2c1e\n","\n","__ term __\n","Central Park Zoo\n","\n","__ description __\n","Zoo in Central Park, Manhattan, New York City\n","\n","__ question __\n","Would it be wise to bring a robusto into Central Park Zoo?\n","\n","__ facts __\n","['A robusto is a short, fat cigar that is very popular in America.', 'The Central Park Zoo has several rules including: no feeding the animals and no smoking.', \"NYPD's 19th precinct is only an 11 minute walk away from the Central Park Zoo.\"]\n","\n","__ decomposition __\n","['What is a robusto?', 'According to the rules, what can you not bring into The Central Park Zoo?', 'Is #1 not in #2?']\n","\n","__ evidence __\n","[[[['Cigar-1']], [['Central Park Zoo-1', 'Smoking ban-10'], 'no_evidence'], ['operation']], [[['Cigar-1'], 'no_evidence'], ['no_evidence'], ['operation']], [[['Cigar-1'], 'no_evidence'], [['Passive smoking-61'], 'no_evidence'], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Would it be wise to bring a robusto into Central Park Zoo?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Would it be wise to bring a robusto into Central Park Zoo?', 'result': 'True\\n\\nExplanation:\\nThe question is asking whether it would be wise to bring a giant panda into Central Park Zoo. The facts provided state that giant pandas are species of mammal and are not typically found in zoos. Additionally, the decomposition process leads to the conclusion that bringing a giant panda into Central Park Zoo would not be wise. Therefore, the answer is true.'}\n","\n","__ gpt_run_time __\n","0.5401873588562012\n","\n","__ llama_run_time __\n","11.912430047988892\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","16338eaba71f146a0c40\n","\n","__ term __\n","Central processing unit\n","\n","__ description __\n","Central component of any computer system which executes input/output, arithmetical, and logical operations\n","\n","__ question __\n","Does the central processing unit usually have a dedicated fan?\n","\n","__ facts __\n","[\"The CPU is the main chip on a computer's board, and generates a lot of heat.\", 'Computer manufacturers generally include a dedicated cooling system over the CPU in addition to the main board fans.']\n","\n","__ decomposition __\n","['What do CPUs generate as they work over time?', 'Do manufacturers incorporate fans specifically for removing #1 into computer systems?']\n","\n","__ evidence __\n","[[[['Central processing unit-53']], ['no_evidence', 'operation']], [[['CPU core voltage-14']], [['Computer fan-7']]], [[['Central processing unit-46']], [['Computer cooling-15']]]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Does the central processing unit usually have a dedicated fan?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Does the central processing unit usually have a dedicated fan?', 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.5484941005706787\n","\n","__ llama_run_time __\n","5.128769159317017\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","30fcf62f58849cb4ab05\n","\n","__ term __\n","Theocracy\n","\n","__ description __\n","Form of government with religious leaders\n","\n","__ question __\n","Were the Great Pyramids built by a theocratic government?\n","\n","__ facts __\n","['The Great Pyramids were built by the Ancient Egyptians.', 'A theocracy is a government that is led by religious leaders or who worships their leader as a god.', 'The Pharaohs of Ancient Egypt were worshipped as children of the Sun god Ra.']\n","\n","__ decomposition __\n","['Who were the builders of the Great Pyramids?', 'How did #1 serve their leaders?', 'Could #2 be described as a theocracy?']\n","\n","__ evidence __\n","[[[['Great Pyramid of Giza-8']], ['no_evidence'], [['Theocracy-1']]], [[['Giza pyramid complex-17']], [['Ancient Egypt-73'], 'no_evidence'], [['Theocracy-1'], 'operation']], [[['Giza pyramid complex-1']], [['Giza pyramid complex-17']], [['Ancient Egypt-3'], 'operation']]]\n","\n","__ answer __\n","True\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Were the Great Pyramids built by a theocratic government?', 'result': 'True'}\n","\n","__ llama_response __\n","{'query': 'Were the Great Pyramids built by a theocratic government?', 'result': 'True\\n\\nExplanation:\\nThe question asks if the Great Pyramids were built by a theocratic government. The fact that the pyramids were built in ancient Egypt supports this answer. The term \"theocratic government\" refers to a form of government where the ruler or ruling class are considered to be divinely appointed or inspired. This is supported by the fact that the pyramids were built during the Old Kingdom period of ancient Egypt, when the pharaohs were believed to be gods on earth. Therefore, the answer is True.'}\n","\n","__ gpt_run_time __\n","0.27002644538879395\n","\n","__ llama_run_time __\n","15.421528816223145\n","\n","__ gpt_one_word_answer __\n","True\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","True\n","\n","__ qid __\n","076f3f72b7e6d17073eb\n","\n","__ term __\n","Amtrak\n","\n","__ description __\n","Intercity rail operator in the United States\n","\n","__ question __\n","Can Amtrak's Acela Express break the sound barrier?\n","\n","__ facts __\n","[\"Amtrak's Acela Express is the fastest train in the Western Hemisphere and can reach 150 mph.\", 'A US Navy plane would need to travel 770 mph to break the sound barrier.']\n","\n","__ decomposition __\n","[\"What is the maximum speed of Amtrak's Acela Express?\", 'What is the minimum speed needed to break the sound barrier?', 'Is #1 greater than or equal to #2?']\n","\n","__ evidence __\n","[[[['Acela Express-1']], [['Sound barrier-2']], ['operation']], [[['Acela Express-1']], [['Sound barrier-2']], ['operation']], [[['Acela Express-20']], [['Sonic boom-5']], [['Counting-14']]]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': \"Can Amtrak's Acela Express break the sound barrier?\", 'result': 'False'}\n","\n","__ llama_response __\n","{'query': \"Can Amtrak's Acela Express break the sound barrier?\", 'result': 'True'}\n","\n","__ gpt_run_time __\n","0.2939872741699219\n","\n","__ llama_run_time __\n","5.416854381561279\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","be42f2f3008b22766d2b\n","\n","__ term __\n","Celery\n","\n","__ description __\n","species of plant\n","\n","__ question __\n","Can eating your weight in celery prevent diabetes?\n","\n","__ facts __\n","['Diabetes is a disease in which the body cannot process sugar.', 'Celery is known as a healthy snack and has 1 gram of sugar per serving.', 'The recommended daily intake of sugar to prevent diabetes is less than 36 grams per day for an adult male.', 'The average weight of an adult male is 197 pounds.']\n","\n","__ decomposition __\n","['If a person has diabetes, what is there body unable to process?', 'To prevent diabetes, what is the average amount of #1 an adult man should eat daily in grams?', 'How much does the average male weigh in pounds?', 'How many grams of sugar does a pound of celery have?', 'Is #3 times #4 less than #2?']\n","\n","__ evidence __\n","[[[['Diabetes-27', 'Diabetes-28']], [['Diabetic diet-4'], 'no_evidence'], [['Human-46']], ['no_evidence'], [['Celery-28'], 'operation']], [[['Diabetes-1'], 'no_evidence'], [['Prevention of type 2 diabetes-2'], 'no_evidence'], [['Man-6'], 'no_evidence'], [['Celery-41'], 'no_evidence'], ['no_evidence', 'operation']], [[['Diabetes-2', 'Outline of diabetes-2']], [['Diabetes-36']], [['Human-46']], [['Celery-28']], ['operation']]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Can eating your weight in celery prevent diabetes?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Can eating your weight in celery prevent diabetes?', 'result': 'True\\n\\nExplanation:\\n\\nThe question is asking if eating your weight in celery can prevent diabetes. The factual information provided states that 3% of the β-carotene in raw celery is released during digestion, which can be improved to 39% by pulping, cooking, and adding cooking oil. Retinal is a form of Vitamin A. However, the question does not provide any information about the absorption of Vitamin A from celery. Therefore, based on the given information, it is uncertain whether eating your weight in celery can prevent diabetes. Therefore, the answer is set to True.\\n\\nExplanation for the decomposition:\\n\\nWhen answering the question, I broke it down into smaller parts to help me understand the question better. I first asked myself what the question was asking about. Then, I looked at the provided facts to see if they provided any information related to the question. I noticed that the provided facts mentioned β-carotene and retinal, but they did not provide any information about the absorption of Vitamin A from celery. Therefore, I concluded that the question was uncertain, and the answer was set to True.\\n\\nExplanation for the evidence:\\n\\nThe evidence provided includes three sets of information. The first set includes the fact that 3% of the β-carotene in raw celery is released during digestion, which can be improved to 39% by pulping, cooking, and adding cooking oil. The second set includes the fact that Retinal is a form of Vitamin A. The third set includes the fact that it was probably written between 1587 and 1593. None of these sets of information provide any information about the absorption of Vitamin A from celery. Therefore, the evidence does not support the claim that eating your weight in celery can prevent diabetes. Therefore, the answer is set to True.'}\n","\n","__ gpt_run_time __\n","0.321765661239624\n","\n","__ llama_run_time __\n","44.774582386016846\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n","\n","__ qid __\n","b257b34db67a10038f18\n","\n","__ term __\n","Human overpopulation\n","\n","__ description __\n","The condition where human numbers exceed the short or long-term carrying capacity of the environment\n","\n","__ question __\n","Does Rusev have to worry about human overpopulation in his homeland?\n","\n","__ facts __\n","['Human overpopulation results from the birthrate exceeding the death rate in a country.', 'Rusev is a professional wrestler who was born in Bulgaria.', 'The population of Bulgaria decreased by .7% in 2018.']\n","\n","__ decomposition __\n","['Who is Rusev?', 'What is the homeland of #1?', 'Is #2 overpopulated?']\n","\n","__ evidence __\n","[[[['Rusev (wrestler)-1']], [['Rusev (wrestler)-3']], [['Population decline-50'], 'operation']], [[['Rusev (wrestler)-2']], [['Rusev (wrestler)-3']], [['Plovdiv-42']]], [[['Rusev (wrestler)-1']], [['Rusev (wrestler)-3']], [['Demographics of Bulgaria-4']]]]\n","\n","__ answer __\n","False\n","\n","__ gpt_source_documents_number __\n","4\n","\n","__ llama_source_documents_number __\n","4\n","\n","__ gpt_response __\n","{'query': 'Does Rusev have to worry about human overpopulation in his homeland?', 'result': 'False'}\n","\n","__ llama_response __\n","{'query': 'Does Rusev have to worry about human overpopulation in his homeland?', 'result': \"True\\n\\nExplanation:\\nRusev is a fictional character, so he doesn't have to worry about human overpopulation in his homeland. However, in real life, human overpopulation is a serious issue that affects many countries around the world. As the global population continues to grow, it puts increasing pressure on resources such as food, water, and energy, leading to issues such as deforestation, habitat destruction, and climate change. To address these challenges, many countries are implementing policies to slow population growth, such as improving access to education and family planning resources.\"}\n","\n","__ gpt_run_time __\n","0.5302770137786865\n","\n","__ llama_run_time __\n","17.478546619415283\n","\n","__ gpt_one_word_answer __\n","False\n","\n","__ llama_one_word_answer __\n","True\n","\n","__ is_gpt_correct __\n","True\n","\n","__ is_llama_correct __\n","False\n"]}],"source":["# Monitoring\n","for d in answered_data[:1]:\n","  for key in d:\n","    print(f\"\\n__ {key} __\")\n","    print(str(d[key]))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"JA5X4-B-FmxH","executionInfo":{"status":"ok","timestamp":1699291889256,"user_tz":-120,"elapsed":1,"user":{"displayName":"Omri Fahn","userId":"00420413350689848307"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"17eRXQGPsnJ_-UvHavCH1PnDfUxZZv0w3","timestamp":1699292249437},{"file_id":"11ooxuabA1l0kmNJTfqlBVB2Y99jnzRKw","timestamp":1699278335086},{"file_id":"1PSBCEmx2l32inJT2xtZenaw1GMz4w1Jn","timestamp":1699259845873},{"file_id":"1eaIhh6shrNLnVZE9jdzocs_IBqOIAQ4_","timestamp":1699093377374},{"file_id":"1HPYVZ9GOLu8ZiYyGrvqHLQ_TSMmLDQ2s","timestamp":1698507659163},{"file_id":"1v4NadwfqkxAtoECpi38EjJFZNNT5ZZuY","timestamp":1698091856860},{"file_id":"1CduadXiu4a73nY24q5rMZWc3-ivmhxK8","timestamp":1698091779661},{"file_id":"1IemZ26obNa3EzodBscSf-B9ndaNqCEVz","timestamp":1697989464319},{"file_id":"1ibiyKNdPwdY9XHMBCQkcsNTDy_3eJ4q3","timestamp":1697910455935},{"file_id":"1Eqoy9I7IPoPvMd0v4yBopRSEtHpTgZF-","timestamp":1697910354667},{"file_id":"1zZ_WiKhBHfnTHK2EKXgJr7ej4gqIzCge","timestamp":1697909970107},{"file_id":"1hNW9qIWCuAmK_q2krK-vw-sK6edFJ2Cx","timestamp":1697909112261},{"file_id":"1VmpfvaTC7sk3XsJOAClxcS78ShJ_48P_","timestamp":1697908980596},{"file_id":"1pX_CE7J0DtAFIW61-5fEUV1mu1ZnmpKT","timestamp":1697902442311}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c01d0ab30f484bb7b397543aa2cb767f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99baf23dd4ce457a80ba8494056824e7","IPY_MODEL_2af6bf870ebe4219825cbb288529bfb9","IPY_MODEL_3a65088a04d6434baa869117d6a54824"],"layout":"IPY_MODEL_f4bbff288c82495c96cc49f5bf869d7d"}},"99baf23dd4ce457a80ba8494056824e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46b726bee2d44f0b8f7464504f164977","placeholder":"​","style":"IPY_MODEL_53d5d852e4b54ec1ab13cc92a115dfcb","value":"Downloading (…)okenizer_config.json: 100%"}},"2af6bf870ebe4219825cbb288529bfb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea4ba3912d6e4119aaf896d8af53fead","max":1618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f9d655ea9e14102ad288c73cd652ed0","value":1618}},"3a65088a04d6434baa869117d6a54824":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f01681c44e464e41956a061994e685d3","placeholder":"​","style":"IPY_MODEL_384ce5efba3449e1b8e5a7c0def6a987","value":" 1.62k/1.62k [00:00&lt;00:00, 40.8kB/s]"}},"f4bbff288c82495c96cc49f5bf869d7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b726bee2d44f0b8f7464504f164977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d5d852e4b54ec1ab13cc92a115dfcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea4ba3912d6e4119aaf896d8af53fead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f9d655ea9e14102ad288c73cd652ed0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f01681c44e464e41956a061994e685d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"384ce5efba3449e1b8e5a7c0def6a987":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d56174aad2fa4bf28440d59ec1f0043e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b85c95a435146008ef323fe605b407c","IPY_MODEL_87835ce96f7b4745bdc7f1a3251de755","IPY_MODEL_40e35bb6a1794234a8fe99418c3d5013"],"layout":"IPY_MODEL_921bf95568d2497bbddd27f68e25903a"}},"1b85c95a435146008ef323fe605b407c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd89a747bbaf4f918af01d51b9afa307","placeholder":"​","style":"IPY_MODEL_ec2f6328e10446e798636a954ae1183c","value":"Downloading tokenizer.model: 100%"}},"87835ce96f7b4745bdc7f1a3251de755":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57602de6d3004c7093469d02cc27bf08","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd64e8e094ed46a1839f3f41f6d42ba2","value":499723}},"40e35bb6a1794234a8fe99418c3d5013":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98aebbda25ac4aa5ab383bcab7bc386f","placeholder":"​","style":"IPY_MODEL_e2da280ef7fd4e59bc5f3b49a0aa3c82","value":" 500k/500k [00:00&lt;00:00, 4.41MB/s]"}},"921bf95568d2497bbddd27f68e25903a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd89a747bbaf4f918af01d51b9afa307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec2f6328e10446e798636a954ae1183c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57602de6d3004c7093469d02cc27bf08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd64e8e094ed46a1839f3f41f6d42ba2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98aebbda25ac4aa5ab383bcab7bc386f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2da280ef7fd4e59bc5f3b49a0aa3c82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01db80512751403d95c4529022bf9223":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd405a3f8f184d50a9ae75bfee10ede8","IPY_MODEL_6405a531d79449e3a327d2d7d00f3e96","IPY_MODEL_7fa47a730a7d424ca16824c3aa0fad0f"],"layout":"IPY_MODEL_aa1bf652c95b4362b6c59ad3a57ed55f"}},"bd405a3f8f184d50a9ae75bfee10ede8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e968ea6701d34f8f8c653db1628060b1","placeholder":"​","style":"IPY_MODEL_d22a900d5ca4485a8f6c99b4176a1079","value":"Downloading (…)/main/tokenizer.json: 100%"}},"6405a531d79449e3a327d2d7d00f3e96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c79416bd6af143b29527e89ad28250aa","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a783c4b1e70b49398b3b557520b25a04","value":1842767}},"7fa47a730a7d424ca16824c3aa0fad0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4ac908a079744d1bb6085250d7a345e","placeholder":"​","style":"IPY_MODEL_b5b0d110819645e984cd8beed0c339c9","value":" 1.84M/1.84M [00:00&lt;00:00, 8.06MB/s]"}},"aa1bf652c95b4362b6c59ad3a57ed55f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e968ea6701d34f8f8c653db1628060b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d22a900d5ca4485a8f6c99b4176a1079":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c79416bd6af143b29527e89ad28250aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a783c4b1e70b49398b3b557520b25a04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4ac908a079744d1bb6085250d7a345e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5b0d110819645e984cd8beed0c339c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db1d909dcce14863a18ec2783e3db7f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd80e9dddd0d4ac2aed3ce8b88616182","IPY_MODEL_29c85ff0f75e4218baf3f3108ee9ae86","IPY_MODEL_da661989f698413abaef66d152705e01"],"layout":"IPY_MODEL_e8718496651347d69ef74dc496dca0c0"}},"cd80e9dddd0d4ac2aed3ce8b88616182":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fdc6520a77a48569f196de68fd7214e","placeholder":"​","style":"IPY_MODEL_0ca7c81f57f94ab1a0d579862cd4aee6","value":"Downloading (…)cial_tokens_map.json: 100%"}},"29c85ff0f75e4218baf3f3108ee9ae86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e6c4fe363c345fca3998cdcfedec92c","max":414,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c1d790d8ec2417882fb30e1ecb42151","value":414}},"da661989f698413abaef66d152705e01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da9704893abb433d888e3897f3740d3b","placeholder":"​","style":"IPY_MODEL_31814c8b519f4288b41b90d1370b47da","value":" 414/414 [00:00&lt;00:00, 33.8kB/s]"}},"e8718496651347d69ef74dc496dca0c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fdc6520a77a48569f196de68fd7214e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ca7c81f57f94ab1a0d579862cd4aee6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e6c4fe363c345fca3998cdcfedec92c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c1d790d8ec2417882fb30e1ecb42151":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da9704893abb433d888e3897f3740d3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31814c8b519f4288b41b90d1370b47da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50663fe62cab4958ace71d849bc60952":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5e862d394c74ae0b5a8d2bb7e2312ab","IPY_MODEL_179523d834bf48d18522b7319802c488","IPY_MODEL_e5d7fc6dd10449ff8abe6835b8a9fb35"],"layout":"IPY_MODEL_98f49f506f1244919a45d4eb254e70f1"}},"f5e862d394c74ae0b5a8d2bb7e2312ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45e9753bd6f840c4bc3aa44271da0b35","placeholder":"​","style":"IPY_MODEL_a6abf6ea24744848ac770f27133b65b3","value":"Downloading (…)lve/main/config.json: 100%"}},"179523d834bf48d18522b7319802c488":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce55cd4404af494e8e9f5601a7338a9c","max":614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12d497570651401a899778130729eb5e","value":614}},"e5d7fc6dd10449ff8abe6835b8a9fb35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4711072a2364e719aa890972d6e6e33","placeholder":"​","style":"IPY_MODEL_db87640fc94f4897b37bcfcb62afefd3","value":" 614/614 [00:00&lt;00:00, 30.7kB/s]"}},"98f49f506f1244919a45d4eb254e70f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45e9753bd6f840c4bc3aa44271da0b35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6abf6ea24744848ac770f27133b65b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce55cd4404af494e8e9f5601a7338a9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12d497570651401a899778130729eb5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4711072a2364e719aa890972d6e6e33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db87640fc94f4897b37bcfcb62afefd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d1ce13887664542b54fadb51c958c4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24b4f93c3b8f4dc18763f1caa0c428b0","IPY_MODEL_556f2853e3504cbb8884ee948716020f","IPY_MODEL_b8eb3163257949b3b83757c5dd9dd580"],"layout":"IPY_MODEL_dab7031f82d74b4892ed2ead5e132a73"}},"24b4f93c3b8f4dc18763f1caa0c428b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_414a3d37574a46cf8e49ef3238a1935b","placeholder":"​","style":"IPY_MODEL_299427f6edbb49c585ba547f3cbb9a06","value":"Downloading (…)fetensors.index.json: 100%"}},"556f2853e3504cbb8884ee948716020f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dfa830dd3f04e6ca291791cacdee427","max":26788,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e88ffa3fad5d4bea87cbdc5487fd4808","value":26788}},"b8eb3163257949b3b83757c5dd9dd580":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9308a425e5e04fdc83e0eddcbdd66e6f","placeholder":"​","style":"IPY_MODEL_5d501ffe17234a2aaf12894a3069a07d","value":" 26.8k/26.8k [00:00&lt;00:00, 1.77MB/s]"}},"dab7031f82d74b4892ed2ead5e132a73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"414a3d37574a46cf8e49ef3238a1935b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"299427f6edbb49c585ba547f3cbb9a06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dfa830dd3f04e6ca291791cacdee427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e88ffa3fad5d4bea87cbdc5487fd4808":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9308a425e5e04fdc83e0eddcbdd66e6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d501ffe17234a2aaf12894a3069a07d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d880b70c33694da2947238f1f07fcf6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99758a64420640e191e7f1cae3c3a886","IPY_MODEL_ae82e0700ef74a26b214130adde26ba1","IPY_MODEL_f73697a1871541099adb2ae703a04200"],"layout":"IPY_MODEL_a440a4921a4645e99cd29df4d4c76c28"}},"99758a64420640e191e7f1cae3c3a886":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a521b38e14f43b7bcda416c7a129ec3","placeholder":"​","style":"IPY_MODEL_38ddce78f9634a4f849b691117ee89f9","value":"Downloading shards: 100%"}},"ae82e0700ef74a26b214130adde26ba1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_446be38f0f4a4597b4dd8623cd05deac","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b35aee9d8224933829c8f8512c0c5e5","value":2}},"f73697a1871541099adb2ae703a04200":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d33b1f9e112d486e981decd5e6ee65b2","placeholder":"​","style":"IPY_MODEL_42b3fd138137428c86e5a5b9c472dad7","value":" 2/2 [01:56&lt;00:00, 53.05s/it]"}},"a440a4921a4645e99cd29df4d4c76c28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a521b38e14f43b7bcda416c7a129ec3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38ddce78f9634a4f849b691117ee89f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"446be38f0f4a4597b4dd8623cd05deac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b35aee9d8224933829c8f8512c0c5e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d33b1f9e112d486e981decd5e6ee65b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42b3fd138137428c86e5a5b9c472dad7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f89a7a57ea1e4d519fde466ad7e2e935":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c561d15bff0f4506bbc40ae057fd7a2e","IPY_MODEL_4dbca8d2a51a40d8abb3e6b340abd1c9","IPY_MODEL_bcbce01cba45496a9e4573cc6cdd1002"],"layout":"IPY_MODEL_6fdc80d7023b4c2b962b71f86ab9c761"}},"c561d15bff0f4506bbc40ae057fd7a2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b79893d5b810428d9acaed326042f7a2","placeholder":"​","style":"IPY_MODEL_157e394b4ea943fba8ae3fd73d72cac2","value":"Downloading (…)of-00002.safetensors: 100%"}},"4dbca8d2a51a40d8abb3e6b340abd1c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2139bdad93d7433ab55b1e26baf457b0","max":9976576152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73508070de3d4ea0ba99322038603059","value":9976576152}},"bcbce01cba45496a9e4573cc6cdd1002":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d49e3565d77422a821e2e77808a3702","placeholder":"​","style":"IPY_MODEL_60044a02a2bf46d486a3700b915d2738","value":" 9.98G/9.98G [01:28&lt;00:00, 129MB/s]"}},"6fdc80d7023b4c2b962b71f86ab9c761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b79893d5b810428d9acaed326042f7a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"157e394b4ea943fba8ae3fd73d72cac2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2139bdad93d7433ab55b1e26baf457b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73508070de3d4ea0ba99322038603059":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d49e3565d77422a821e2e77808a3702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60044a02a2bf46d486a3700b915d2738":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82e6060feb5c44ae92637799b4014d04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a68405317643473aa51fd1a30589d733","IPY_MODEL_2eac502716284f2f898686d778af628d","IPY_MODEL_e651c6a9f8b24f5aa4998246b3995025"],"layout":"IPY_MODEL_89123b60e7094b9b8a793d15f79bb559"}},"a68405317643473aa51fd1a30589d733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_869f86a490254ac68b4d086a1a235a3b","placeholder":"​","style":"IPY_MODEL_efea0d249f2f4b3a9f2a55149cfb6754","value":"Downloading (…)of-00002.safetensors: 100%"}},"2eac502716284f2f898686d778af628d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e557a4a03c274976bcdf0a4d966b6c1e","max":3500296424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_667bb17e07f246e2b9a196eb9a04374b","value":3500296424}},"e651c6a9f8b24f5aa4998246b3995025":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99734ff902e5416584e7ab25bc7cf991","placeholder":"​","style":"IPY_MODEL_929f3d7d3bcc4fea9daaea73a8d271e4","value":" 3.50G/3.50G [00:27&lt;00:00, 172MB/s]"}},"89123b60e7094b9b8a793d15f79bb559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869f86a490254ac68b4d086a1a235a3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efea0d249f2f4b3a9f2a55149cfb6754":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e557a4a03c274976bcdf0a4d966b6c1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667bb17e07f246e2b9a196eb9a04374b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99734ff902e5416584e7ab25bc7cf991":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"929f3d7d3bcc4fea9daaea73a8d271e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbc146df5e2943d181d494ce46ef38cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6160cada928450bb3a9af78ce25ee58","IPY_MODEL_bc1f8854cf5e4375b53ec44e95e90d1b","IPY_MODEL_8ff81e80ba284da6aa08cb7bfa71f982"],"layout":"IPY_MODEL_f6c06e5fe5ff48be84bc316d6f2d8a6d"}},"d6160cada928450bb3a9af78ce25ee58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bca5240e8364d16817a1d2592f012ca","placeholder":"​","style":"IPY_MODEL_d7673841aeda4a938d3911eb9d553a5a","value":"Loading checkpoint shards: 100%"}},"bc1f8854cf5e4375b53ec44e95e90d1b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b749c130215640c6a38b564042bff5cf","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd94b41cb76340f7a9c3574e59c88aa0","value":2}},"8ff81e80ba284da6aa08cb7bfa71f982":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77ecb855ea184d9ea5f3d270d1ba63e7","placeholder":"​","style":"IPY_MODEL_f5b476c5a4bd42a388c798de76f884de","value":" 2/2 [01:06&lt;00:00, 30.25s/it]"}},"f6c06e5fe5ff48be84bc316d6f2d8a6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bca5240e8364d16817a1d2592f012ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7673841aeda4a938d3911eb9d553a5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b749c130215640c6a38b564042bff5cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd94b41cb76340f7a9c3574e59c88aa0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77ecb855ea184d9ea5f3d270d1ba63e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b476c5a4bd42a388c798de76f884de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de2e2147e1b54c1f8f7e02084f480115":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc2f8559378945ffa9a19ab103776aab","IPY_MODEL_6fc0b5acd8404d598331a4e03843df9f","IPY_MODEL_1843bea0b05c47208492d4a5d57b0087"],"layout":"IPY_MODEL_35675dd701e6485094828e252449e758"}},"cc2f8559378945ffa9a19ab103776aab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41d0b001392f42c9881eba76dc6e049a","placeholder":"​","style":"IPY_MODEL_a2e42f0ee69e433ea8c6191ec7e55c21","value":"Downloading (…)neration_config.json: 100%"}},"6fc0b5acd8404d598331a4e03843df9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8db824f33234468b99af30f79c125512","max":188,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1363c47ccf584d88a4b21f7f7b151ba5","value":188}},"1843bea0b05c47208492d4a5d57b0087":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc59606ec5c14ba8b5b270bdeb381c8c","placeholder":"​","style":"IPY_MODEL_9a772472266240449702068661ec455b","value":" 188/188 [00:00&lt;00:00, 10.4kB/s]"}},"35675dd701e6485094828e252449e758":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41d0b001392f42c9881eba76dc6e049a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2e42f0ee69e433ea8c6191ec7e55c21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8db824f33234468b99af30f79c125512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1363c47ccf584d88a4b21f7f7b151ba5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc59606ec5c14ba8b5b270bdeb381c8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a772472266240449702068661ec455b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bc64f25f624444b92fc71d2f5d8e88d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29dc5c1b6d7644a3a122f19a6b619f81","IPY_MODEL_8414e6a531ee45c0b4ea30cdb41abef4","IPY_MODEL_36f3d9b38f9b47b698140e77287f3ebc"],"layout":"IPY_MODEL_7f0a6b6ad8be4c168fdc31d20da79b18"}},"29dc5c1b6d7644a3a122f19a6b619f81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f91fdb8cd63425b8fc02463bf496fbb","placeholder":"​","style":"IPY_MODEL_80e3d1757ee64405a35896b540f79804","value":"Downloading (…)e9125/.gitattributes: 100%"}},"8414e6a531ee45c0b4ea30cdb41abef4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fad60ca30b7e430a98db8bab65fc8167","max":1175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b99cc499af0b4f1e97238d742bc22e63","value":1175}},"36f3d9b38f9b47b698140e77287f3ebc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e20c9c2eb26545aab5335800031454e5","placeholder":"​","style":"IPY_MODEL_cdb8a2819fc847eb85e3c94c576bb550","value":" 1.18k/1.18k [00:00&lt;00:00, 55.7kB/s]"}},"7f0a6b6ad8be4c168fdc31d20da79b18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f91fdb8cd63425b8fc02463bf496fbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80e3d1757ee64405a35896b540f79804":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fad60ca30b7e430a98db8bab65fc8167":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b99cc499af0b4f1e97238d742bc22e63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e20c9c2eb26545aab5335800031454e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdb8a2819fc847eb85e3c94c576bb550":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c15079df56445b3b79d33034a867458":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b550fcfbb4664163bc0d3edc06e4edc2","IPY_MODEL_25b8aa5a331349a6b7b3a320fef4bfdd","IPY_MODEL_1623cfc020de4ec992d6134d160a0971"],"layout":"IPY_MODEL_6242074f0fdf467aa6ca4462ee5780f5"}},"b550fcfbb4664163bc0d3edc06e4edc2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a695a8ab02b64719b31b30e915f1c02f","placeholder":"​","style":"IPY_MODEL_d54b53c7fa304dfba602bbb41f730c71","value":"Downloading (…)_Pooling/config.json: 100%"}},"25b8aa5a331349a6b7b3a320fef4bfdd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aac4a9cb31b4b50942ded8c8d339f6f","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e896dfc31eb4a439db4fe78b8d5128b","value":190}},"1623cfc020de4ec992d6134d160a0971":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fec560598aa4dbfa262e5428c2f7df3","placeholder":"​","style":"IPY_MODEL_87ae9f443bd547c2adeabdf8944af611","value":" 190/190 [00:00&lt;00:00, 10.5kB/s]"}},"6242074f0fdf467aa6ca4462ee5780f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a695a8ab02b64719b31b30e915f1c02f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d54b53c7fa304dfba602bbb41f730c71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6aac4a9cb31b4b50942ded8c8d339f6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e896dfc31eb4a439db4fe78b8d5128b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3fec560598aa4dbfa262e5428c2f7df3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87ae9f443bd547c2adeabdf8944af611":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3535d656d63143d4a5ccdd051307adff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8e11f12bc41467cbdc33d8bad469055","IPY_MODEL_522b1bc6373c446f865cbac9cacd3676","IPY_MODEL_7177611eeb074900b062b1a25eed6db8"],"layout":"IPY_MODEL_3deaa5e8569a4ca6b37f738a45e3e511"}},"d8e11f12bc41467cbdc33d8bad469055":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68e546377d2d4363a1d19079bb9fa6c2","placeholder":"​","style":"IPY_MODEL_270191dae1fc438994ff2a5dbe41a466","value":"Downloading (…)7e55de9125/README.md: 100%"}},"522b1bc6373c446f865cbac9cacd3676":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77c97cc09f6d43ae88d0b9f0e6385709","max":10610,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3fac855af5a4ba391be8a61bf082d59","value":10610}},"7177611eeb074900b062b1a25eed6db8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecdc8e75d3224eabbda81d2935d85130","placeholder":"​","style":"IPY_MODEL_a4729d53f60b433582a6320139f11bac","value":" 10.6k/10.6k [00:00&lt;00:00, 583kB/s]"}},"3deaa5e8569a4ca6b37f738a45e3e511":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68e546377d2d4363a1d19079bb9fa6c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"270191dae1fc438994ff2a5dbe41a466":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77c97cc09f6d43ae88d0b9f0e6385709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3fac855af5a4ba391be8a61bf082d59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecdc8e75d3224eabbda81d2935d85130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4729d53f60b433582a6320139f11bac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cc806e11864499ab732f8b0c03a0973":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b980ae561a14856b478ae6980641628","IPY_MODEL_24786a1c760d4a4b9a437f07a8f60383","IPY_MODEL_a284798a790c48bf9dfc7c35e319805a"],"layout":"IPY_MODEL_c435e6de23e44b03a96aa24b2b4f4c5c"}},"1b980ae561a14856b478ae6980641628":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc5e4493e41c4f14a65063f56fc55dbc","placeholder":"​","style":"IPY_MODEL_5a7f9797bd9540eeb8c3409733287939","value":"Downloading (…)55de9125/config.json: 100%"}},"24786a1c760d4a4b9a437f07a8f60383":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_114465f9906749e087f7604e84df02f2","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a6c3444aacc4c93a6451adbc652f514","value":612}},"a284798a790c48bf9dfc7c35e319805a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35350df0ae1041d1b88f579a02240ea2","placeholder":"​","style":"IPY_MODEL_765dcde89a254b408ec41d1381077a7d","value":" 612/612 [00:00&lt;00:00, 30.5kB/s]"}},"c435e6de23e44b03a96aa24b2b4f4c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc5e4493e41c4f14a65063f56fc55dbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a7f9797bd9540eeb8c3409733287939":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"114465f9906749e087f7604e84df02f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a6c3444aacc4c93a6451adbc652f514":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35350df0ae1041d1b88f579a02240ea2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"765dcde89a254b408ec41d1381077a7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46052f777c0845e58778ca2524e99aa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70a90c765296473db44255d0c2c0c678","IPY_MODEL_bf9880a56e0d4004949c3c3c7a4dc108","IPY_MODEL_09185a9b149b44058b5dabd72c80d091"],"layout":"IPY_MODEL_2b776fccadd6488a96919605f07f5fc4"}},"70a90c765296473db44255d0c2c0c678":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c423dcb4e314acfa6b8791fd4986d0d","placeholder":"​","style":"IPY_MODEL_bbfd862377554cdd947070068d82cc96","value":"Downloading (…)ce_transformers.json: 100%"}},"bf9880a56e0d4004949c3c3c7a4dc108":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c3e95a7fd474c80a17eb493a19b7e06","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1663bf8ab8744edea59438b38d3f2665","value":116}},"09185a9b149b44058b5dabd72c80d091":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65d3f0887f8c490b95aec45aad5e861d","placeholder":"​","style":"IPY_MODEL_0868850e16cc464084c7c39cb7cedc68","value":" 116/116 [00:00&lt;00:00, 6.29kB/s]"}},"2b776fccadd6488a96919605f07f5fc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c423dcb4e314acfa6b8791fd4986d0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbfd862377554cdd947070068d82cc96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c3e95a7fd474c80a17eb493a19b7e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1663bf8ab8744edea59438b38d3f2665":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65d3f0887f8c490b95aec45aad5e861d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0868850e16cc464084c7c39cb7cedc68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83292382f2f74ad5a7010c5652c0a983":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d429d3152f44b798e980c85d7f5eb7b","IPY_MODEL_3e485347dc7645c5911747ba2d2bba75","IPY_MODEL_f5945a2294c446e4883cf68449380a17"],"layout":"IPY_MODEL_63e3711e3bff452dbbdd105d8143b8ee"}},"5d429d3152f44b798e980c85d7f5eb7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7d72427b5e642568cee2713bd7f1413","placeholder":"​","style":"IPY_MODEL_ab8ff475a874406e9935991fd7cea086","value":"Downloading (…)125/data_config.json: 100%"}},"3e485347dc7645c5911747ba2d2bba75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_510244b18087490bbd7206d248f191fa","max":39265,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7745d138f4f49bebab6601b396ab968","value":39265}},"f5945a2294c446e4883cf68449380a17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5380e6e656364da8af2fbf726071ce50","placeholder":"​","style":"IPY_MODEL_9e577bf6473e4ea0ba5944b45c16a9f1","value":" 39.3k/39.3k [00:00&lt;00:00, 1.72MB/s]"}},"63e3711e3bff452dbbdd105d8143b8ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7d72427b5e642568cee2713bd7f1413":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab8ff475a874406e9935991fd7cea086":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"510244b18087490bbd7206d248f191fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7745d138f4f49bebab6601b396ab968":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5380e6e656364da8af2fbf726071ce50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e577bf6473e4ea0ba5944b45c16a9f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b00bf01129ee40e8b8071c07f211c922":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0c7cfe1c6c543a797e303e383fc2e43","IPY_MODEL_271c2e611bbe4f3dadad3280a7039289","IPY_MODEL_3ae17005262542d3bee7d7ea4cfba214"],"layout":"IPY_MODEL_0f20019daa3640229c03f52ac9f26f97"}},"b0c7cfe1c6c543a797e303e383fc2e43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c26aad75b554f3aa39662f260795826","placeholder":"​","style":"IPY_MODEL_8fa9f24979774452bac041037095b916","value":"Downloading pytorch_model.bin: 100%"}},"271c2e611bbe4f3dadad3280a7039289":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7a154494c9b484bbe498e9586c1b4cf","max":90888945,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a618d2b94c94f0f8bd4a67b3202822a","value":90888945}},"3ae17005262542d3bee7d7ea4cfba214":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6bf434911fe418188e1550195c25957","placeholder":"​","style":"IPY_MODEL_39fce2dd4a9749bc9e847813d4426bf7","value":" 90.9M/90.9M [00:00&lt;00:00, 153MB/s]"}},"0f20019daa3640229c03f52ac9f26f97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c26aad75b554f3aa39662f260795826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fa9f24979774452bac041037095b916":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7a154494c9b484bbe498e9586c1b4cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a618d2b94c94f0f8bd4a67b3202822a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6bf434911fe418188e1550195c25957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39fce2dd4a9749bc9e847813d4426bf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35ea0c22ba83412a9de390a1364c6d10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f7120937daf43bba9a1f91e6073058c","IPY_MODEL_e620b969bbbd472b97c111538fdc3695","IPY_MODEL_d43e68afa3344c8cbd0b1d9de17d6519"],"layout":"IPY_MODEL_8e69a7872752430b8098cf4dc2281def"}},"2f7120937daf43bba9a1f91e6073058c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dceaa513c4d44f39023f3d19f0ad2c7","placeholder":"​","style":"IPY_MODEL_40bf332984fc42059ddc15046898bebb","value":"Downloading (…)nce_bert_config.json: 100%"}},"e620b969bbbd472b97c111538fdc3695":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5951d9de5c6a452aa25f98c57ee74187","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba3e6a8329c849fb9d40529d78d3e5f6","value":53}},"d43e68afa3344c8cbd0b1d9de17d6519":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb41e1cdc5504fed963ed70f410917e9","placeholder":"​","style":"IPY_MODEL_ccfe920ff2b34144a832b33caf0b4284","value":" 53.0/53.0 [00:00&lt;00:00, 3.47kB/s]"}},"8e69a7872752430b8098cf4dc2281def":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dceaa513c4d44f39023f3d19f0ad2c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40bf332984fc42059ddc15046898bebb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5951d9de5c6a452aa25f98c57ee74187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba3e6a8329c849fb9d40529d78d3e5f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb41e1cdc5504fed963ed70f410917e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccfe920ff2b34144a832b33caf0b4284":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bfb2703057d42b0bd2fa11f96c65b2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7aac820170c42ff99b180939ac2f4bf","IPY_MODEL_ff7a058ec0564b3c90da979e740ceef4","IPY_MODEL_1901185ece954615bb2d87eba33c79b2"],"layout":"IPY_MODEL_05b1415b5f654fd5a02f3c8c9d3b4cef"}},"d7aac820170c42ff99b180939ac2f4bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_088360720cb241ecbe277cdb1386225f","placeholder":"​","style":"IPY_MODEL_6d5c208211064169b7f9058568765209","value":"Downloading (…)cial_tokens_map.json: 100%"}},"ff7a058ec0564b3c90da979e740ceef4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cafd6cec0cbc45348b725b64d5d20e33","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e71aac140b164b4e826c59a94b10ff63","value":112}},"1901185ece954615bb2d87eba33c79b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_681742da1e044e93a01633f0c4135c39","placeholder":"​","style":"IPY_MODEL_dea7f3dea1574d63b42c89f2a27cf6ed","value":" 112/112 [00:00&lt;00:00, 7.01kB/s]"}},"05b1415b5f654fd5a02f3c8c9d3b4cef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"088360720cb241ecbe277cdb1386225f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d5c208211064169b7f9058568765209":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cafd6cec0cbc45348b725b64d5d20e33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e71aac140b164b4e826c59a94b10ff63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"681742da1e044e93a01633f0c4135c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dea7f3dea1574d63b42c89f2a27cf6ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0242e7274e874f00ad4f248a87918e42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1b837b43f944471b9f35d755eac2e5d","IPY_MODEL_d71e32cf5c9643188e521b8bb4b73cb1","IPY_MODEL_d50caf94ee1345029dea69fffda28e5a"],"layout":"IPY_MODEL_352c76bb646f42598ec9e968aeba2d1d"}},"a1b837b43f944471b9f35d755eac2e5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40689fcfac6d4765aa935bd867616cd9","placeholder":"​","style":"IPY_MODEL_8964861ada9047efbe0f91308c2d5439","value":"Downloading (…)e9125/tokenizer.json: 100%"}},"d71e32cf5c9643188e521b8bb4b73cb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_825f4568a32649858bf1ccb210585e1f","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_037849438d5543fe875a64f74200541f","value":466247}},"d50caf94ee1345029dea69fffda28e5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b60952d1390c48119d9409fa988021f2","placeholder":"​","style":"IPY_MODEL_4599588cd18c4033a52ed208b9b83a35","value":" 466k/466k [00:00&lt;00:00, 14.6MB/s]"}},"352c76bb646f42598ec9e968aeba2d1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40689fcfac6d4765aa935bd867616cd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8964861ada9047efbe0f91308c2d5439":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"825f4568a32649858bf1ccb210585e1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"037849438d5543fe875a64f74200541f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b60952d1390c48119d9409fa988021f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4599588cd18c4033a52ed208b9b83a35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70139978676b43008e8961a1ed7cbc74":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_feaa10d44367460ea50c902c65b00080","IPY_MODEL_35df66066b7649f38b117f73341a728e","IPY_MODEL_e7f15ea8ad3548ce9498085df44dceb0"],"layout":"IPY_MODEL_e6f74247184e4fe9bd1b57145229cacd"}},"feaa10d44367460ea50c902c65b00080":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92dbfeab3b69426197a48841ec929e42","placeholder":"​","style":"IPY_MODEL_a6d26b15d307433696dd5f0b6d831218","value":"Downloading (…)okenizer_config.json: 100%"}},"35df66066b7649f38b117f73341a728e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61649588ffb0412dba8a9afe7100f42f","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d04dd7cdf8fd49fc921642692ed5c762","value":350}},"e7f15ea8ad3548ce9498085df44dceb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d895c3db70e49d9b64ce50f34c614c5","placeholder":"​","style":"IPY_MODEL_5c6065c7681f4233a1c13cd3fac57986","value":" 350/350 [00:00&lt;00:00, 20.0kB/s]"}},"e6f74247184e4fe9bd1b57145229cacd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92dbfeab3b69426197a48841ec929e42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6d26b15d307433696dd5f0b6d831218":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61649588ffb0412dba8a9afe7100f42f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d04dd7cdf8fd49fc921642692ed5c762":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d895c3db70e49d9b64ce50f34c614c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c6065c7681f4233a1c13cd3fac57986":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbb16f33ef824b07b446606e39c45d86":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9347957e0fb43afb093a13b6f50902d","IPY_MODEL_9e9234cd90464df38f0817c5ad2f0842","IPY_MODEL_bb57e838336c4701957e832aaf793e5f"],"layout":"IPY_MODEL_e50e9537e5c6405f8a9ea65b6a1b8de0"}},"a9347957e0fb43afb093a13b6f50902d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80aaa2558eaa476aa62a312895a84072","placeholder":"​","style":"IPY_MODEL_c018f51287d841e9ab2e4a54e75a764f","value":"Downloading (…)9125/train_script.py: 100%"}},"9e9234cd90464df38f0817c5ad2f0842":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e976d874b2843409cfbbd4f6b4a0076","max":13156,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66ed436b656d450d92ec2cf152dd6654","value":13156}},"bb57e838336c4701957e832aaf793e5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_869247fb2201430386756b009fe47704","placeholder":"​","style":"IPY_MODEL_3bb64fc9762f4ca48707ca2b0301b22b","value":" 13.2k/13.2k [00:00&lt;00:00, 944kB/s]"}},"e50e9537e5c6405f8a9ea65b6a1b8de0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80aaa2558eaa476aa62a312895a84072":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c018f51287d841e9ab2e4a54e75a764f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e976d874b2843409cfbbd4f6b4a0076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ed436b656d450d92ec2cf152dd6654":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"869247fb2201430386756b009fe47704":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb64fc9762f4ca48707ca2b0301b22b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef87716a2084448c987b69bb9c0ff594":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_913198da8a4d4798be467888131d0775","IPY_MODEL_047c2a01687a49cb9abb8f75c1eba886","IPY_MODEL_79de0cd65e50425e87607735cdf8fb99"],"layout":"IPY_MODEL_14f539a808da4abba00e73499d03d5fe"}},"913198da8a4d4798be467888131d0775":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9685864dc4cc40a3b10b189657f5064e","placeholder":"​","style":"IPY_MODEL_c3d763d1bfd04d1387692b5153cf1a49","value":"Downloading (…)7e55de9125/vocab.txt: 100%"}},"047c2a01687a49cb9abb8f75c1eba886":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4f29b75396c46d98dae44c8e30d780f","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c86a17643f0d4a0caee7494ea4218865","value":231508}},"79de0cd65e50425e87607735cdf8fb99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80b89b203b4f4ef1a99e68e7df80bf11","placeholder":"​","style":"IPY_MODEL_9902ca7e89bb4a1fac6a87394b25e2fb","value":" 232k/232k [00:00&lt;00:00, 5.62MB/s]"}},"14f539a808da4abba00e73499d03d5fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9685864dc4cc40a3b10b189657f5064e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3d763d1bfd04d1387692b5153cf1a49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4f29b75396c46d98dae44c8e30d780f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c86a17643f0d4a0caee7494ea4218865":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80b89b203b4f4ef1a99e68e7df80bf11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9902ca7e89bb4a1fac6a87394b25e2fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98410f91241f4c1ba6255c9bb12d1467":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3d236473f07405fb41da58c240842b4","IPY_MODEL_ff57a17d882e4308ae8431bdb5d1d3d0","IPY_MODEL_c055d39213b340f9b68aaf26565ff8ef"],"layout":"IPY_MODEL_45335251de604fac97d39281e6e2b043"}},"b3d236473f07405fb41da58c240842b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_762308f4484a41e6a43cf64c79f71898","placeholder":"​","style":"IPY_MODEL_f4fe1f77f2f3405187368c0eaaeeb6ac","value":"Downloading (…)5de9125/modules.json: 100%"}},"ff57a17d882e4308ae8431bdb5d1d3d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce8f3f667758478c82b8d9077482f556","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43dfa7fc965c4c0bb42f5efe36ef2884","value":349}},"c055d39213b340f9b68aaf26565ff8ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acbf3356a19c4bccbb9f6e0f35ca5a2b","placeholder":"​","style":"IPY_MODEL_0adb0e13120149439730f1a900a65106","value":" 349/349 [00:00&lt;00:00, 13.1kB/s]"}},"45335251de604fac97d39281e6e2b043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"762308f4484a41e6a43cf64c79f71898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4fe1f77f2f3405187368c0eaaeeb6ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce8f3f667758478c82b8d9077482f556":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43dfa7fc965c4c0bb42f5efe36ef2884":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"acbf3356a19c4bccbb9f6e0f35ca5a2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0adb0e13120149439730f1a900a65106":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}